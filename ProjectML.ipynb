{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectML.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/Mikky-sout/MachineLearningOnly/blob/main/ProjectML.ipynb",
      "authorship_tag": "ABX9TyNYYinrEgwF9KCYtHAhjDFd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mikky-sout/MachineLearningOnly/blob/main/ProjectML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Heart Disease Prediction"
      ],
      "metadata": {
        "id": "UbpEb0eR2o2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Librarys**"
      ],
      "metadata": {
        "id": "RECdgzda2xAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVR\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "import pandas_datareader.data as web\n",
        "import pandas\n",
        "from pandas_datareader import data as pdr\n",
        "import datetime\n",
        "import math\n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from imblearn.under_sampling import RandomUnderSampler \n",
        "from imblearn.over_sampling import RandomOverSampler "
      ],
      "metadata": {
        "id": "uv4CkWoq2qIE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare Dataset**"
      ],
      "metadata": {
        "id": "p6UgZhSX4Tvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/heart_2020_cleaned.csv\")\n",
        "df.head()\n",
        "Y = pd.DataFrame(df['HeartDisease'])\n",
        "df = df.drop(df[['HeartDisease']],axis=1)\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "gCcPteEn21Te",
        "outputId": "fcbbe4bc-a225-41e0-a33e-876b90dd57aa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       HeartDisease\n",
              "0                No\n",
              "1                No\n",
              "2                No\n",
              "3                No\n",
              "4                No\n",
              "...             ...\n",
              "319790          Yes\n",
              "319791           No\n",
              "319792           No\n",
              "319793           No\n",
              "319794           No\n",
              "\n",
              "[319795 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7cda6e5-4421-4344-853a-6c87ee88322d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HeartDisease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319790</th>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319791</th>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319792</th>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319793</th>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319794</th>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>319795 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7cda6e5-4421-4344-853a-6c87ee88322d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7cda6e5-4421-4344-853a-6c87ee88322d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7cda6e5-4421-4344-853a-6c87ee88322d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_featureX = df.select_dtypes(include=['object']).columns\n",
        "df = pd.get_dummies(df,columns=categorical_featureX,drop_first=True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "xn-eKJdq6GQF",
        "outputId": "2c1de83f-4f0f-4bb6-c2e1-2b54f2ce74fb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     BMI  PhysicalHealth  MentalHealth  SleepTime  Smoking_Yes  \\\n",
              "0  16.60             3.0          30.0        5.0            1   \n",
              "1  20.34             0.0           0.0        7.0            0   \n",
              "2  26.58            20.0          30.0        8.0            1   \n",
              "3  24.21             0.0           0.0        6.0            0   \n",
              "4  23.71            28.0           0.0        8.0            0   \n",
              "\n",
              "   AlcoholDrinking_Yes  Stroke_Yes  DiffWalking_Yes  Sex_Male  \\\n",
              "0                    0           0                0         0   \n",
              "1                    0           1                0         0   \n",
              "2                    0           0                0         1   \n",
              "3                    0           0                0         0   \n",
              "4                    0           0                1         0   \n",
              "\n",
              "   AgeCategory_25-29  ...  Diabetic_Yes  Diabetic_Yes (during pregnancy)  \\\n",
              "0                  0  ...             1                                0   \n",
              "1                  0  ...             0                                0   \n",
              "2                  0  ...             1                                0   \n",
              "3                  0  ...             0                                0   \n",
              "4                  0  ...             0                                0   \n",
              "\n",
              "   PhysicalActivity_Yes  GenHealth_Fair  GenHealth_Good  GenHealth_Poor  \\\n",
              "0                     1               0               0               0   \n",
              "1                     1               0               0               0   \n",
              "2                     1               1               0               0   \n",
              "3                     0               0               1               0   \n",
              "4                     1               0               0               0   \n",
              "\n",
              "   GenHealth_Very good  Asthma_Yes  KidneyDisease_Yes  SkinCancer_Yes  \n",
              "0                    1           1                  0               1  \n",
              "1                    1           0                  0               0  \n",
              "2                    0           1                  0               0  \n",
              "3                    0           0                  0               1  \n",
              "4                    1           0                  0               0  \n",
              "\n",
              "[5 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f77681d-bca7-4258-add9-61cc2453e39b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BMI</th>\n",
              "      <th>PhysicalHealth</th>\n",
              "      <th>MentalHealth</th>\n",
              "      <th>SleepTime</th>\n",
              "      <th>Smoking_Yes</th>\n",
              "      <th>AlcoholDrinking_Yes</th>\n",
              "      <th>Stroke_Yes</th>\n",
              "      <th>DiffWalking_Yes</th>\n",
              "      <th>Sex_Male</th>\n",
              "      <th>AgeCategory_25-29</th>\n",
              "      <th>...</th>\n",
              "      <th>Diabetic_Yes</th>\n",
              "      <th>Diabetic_Yes (during pregnancy)</th>\n",
              "      <th>PhysicalActivity_Yes</th>\n",
              "      <th>GenHealth_Fair</th>\n",
              "      <th>GenHealth_Good</th>\n",
              "      <th>GenHealth_Poor</th>\n",
              "      <th>GenHealth_Very good</th>\n",
              "      <th>Asthma_Yes</th>\n",
              "      <th>KidneyDisease_Yes</th>\n",
              "      <th>SkinCancer_Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16.60</td>\n",
              "      <td>3.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.58</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24.21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23.71</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f77681d-bca7-4258-add9-61cc2453e39b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f77681d-bca7-4258-add9-61cc2453e39b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f77681d-bca7-4258-add9-61cc2453e39b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(Y)\n",
        "labels = to_categorical(labels)\n",
        "Y = np.array(labels)"
      ],
      "metadata": {
        "id": "_UOnTMGc7gVl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = pd.DataFrame(Y)\n",
        "Y.columns = ['HeartDisease_No','HeartDisease_Yes']\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Xro42wiO8Rn6",
        "outputId": "61b0a011-1243-4658-8466-112d359474d0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        HeartDisease_No  HeartDisease_Yes\n",
              "0                   1.0               0.0\n",
              "1                   1.0               0.0\n",
              "2                   1.0               0.0\n",
              "3                   1.0               0.0\n",
              "4                   1.0               0.0\n",
              "...                 ...               ...\n",
              "319790              0.0               1.0\n",
              "319791              1.0               0.0\n",
              "319792              1.0               0.0\n",
              "319793              1.0               0.0\n",
              "319794              1.0               0.0\n",
              "\n",
              "[319795 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2b4e9ac-1c26-4b24-a501-72a6547335d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HeartDisease_No</th>\n",
              "      <th>HeartDisease_Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319790</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319791</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319792</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319793</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319794</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>319795 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2b4e9ac-1c26-4b24-a501-72a6547335d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2b4e9ac-1c26-4b24-a501-72a6547335d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2b4e9ac-1c26-4b24-a501-72a6547335d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "standard_scaler = preprocessing.StandardScaler();\n",
        "X = pd.DataFrame(standard_scaler.fit_transform(df.values),index = df.index, columns=df.columns)\n",
        "# Y = pd.DataFrame(standard_scaler.fit_transform(Y.values),index = X2.index, columns=X2.columns)\n"
      ],
      "metadata": {
        "id": "zVQ0D4716Bem"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_Corr = X.corr()\n",
        "lower = pd.DataFrame(np.tril(data_Corr,-1),columns=data_Corr.columns)\n",
        "\n",
        "to_drop = [column for column in lower if any(abs(lower[column]) > 0.8)]\n",
        "X.drop(to_drop,inplace=True,axis = 1)\n",
        "print(to_drop)"
      ],
      "metadata": {
        "id": "_7SlKe7kLz2l",
        "outputId": "75700ad5-c2a4-407e-c025-cb3f99ce862f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "HJIpOGUj92b7",
        "outputId": "38835d96-52f5-4144-cd42-22ce1a37d772"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        BMI  PhysicalHealth  MentalHealth  SleepTime  Smoking_Yes  \\\n",
              "0 -1.844750       -0.046751      3.281069  -1.460354     1.193474   \n",
              "1 -1.256338       -0.424070     -0.490039  -0.067601    -0.837890   \n",
              "2 -0.274603        2.091388      3.281069   0.628776     1.193474   \n",
              "3 -0.647473       -0.424070     -0.490039  -0.763977    -0.837890   \n",
              "4 -0.726138        3.097572     -0.490039   0.628776    -0.837890   \n",
              "\n",
              "   AlcoholDrinking_Yes  Stroke_Yes  DiffWalking_Yes  Sex_Male  \\\n",
              "0             -0.27032   -0.198040        -0.401578 -0.951711   \n",
              "1             -0.27032    5.049478        -0.401578 -0.951711   \n",
              "2             -0.27032   -0.198040        -0.401578  1.050739   \n",
              "3             -0.27032   -0.198040        -0.401578 -0.951711   \n",
              "4             -0.27032   -0.198040         2.490174 -0.951711   \n",
              "\n",
              "   AgeCategory_25-29  ...  Diabetic_Yes  Diabetic_Yes (during pregnancy)  \\\n",
              "0          -0.236615  ...      2.614905                        -0.089814   \n",
              "1          -0.236615  ...     -0.382423                        -0.089814   \n",
              "2          -0.236615  ...      2.614905                        -0.089814   \n",
              "3          -0.236615  ...     -0.382423                        -0.089814   \n",
              "4          -0.236615  ...     -0.382423                        -0.089814   \n",
              "\n",
              "   PhysicalActivity_Yes  GenHealth_Fair  GenHealth_Good  GenHealth_Poor  \\\n",
              "0              0.538256       -0.348745       -0.640987       -0.191292   \n",
              "1              0.538256       -0.348745       -0.640987       -0.191292   \n",
              "2              0.538256        2.867422       -0.640987       -0.191292   \n",
              "3             -1.857852       -0.348745        1.560094       -0.191292   \n",
              "4              0.538256       -0.348745       -0.640987       -0.191292   \n",
              "\n",
              "   GenHealth_Very good  Asthma_Yes  KidneyDisease_Yes  SkinCancer_Yes  \n",
              "0             1.344886    2.541515          -0.195554        3.118419  \n",
              "1             1.344886   -0.393466          -0.195554       -0.320675  \n",
              "2            -0.743558    2.541515          -0.195554       -0.320675  \n",
              "3            -0.743558   -0.393466          -0.195554        3.118419  \n",
              "4             1.344886   -0.393466          -0.195554       -0.320675  \n",
              "\n",
              "[5 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33cb4094-fae6-4489-938b-6e5c74fa8be4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BMI</th>\n",
              "      <th>PhysicalHealth</th>\n",
              "      <th>MentalHealth</th>\n",
              "      <th>SleepTime</th>\n",
              "      <th>Smoking_Yes</th>\n",
              "      <th>AlcoholDrinking_Yes</th>\n",
              "      <th>Stroke_Yes</th>\n",
              "      <th>DiffWalking_Yes</th>\n",
              "      <th>Sex_Male</th>\n",
              "      <th>AgeCategory_25-29</th>\n",
              "      <th>...</th>\n",
              "      <th>Diabetic_Yes</th>\n",
              "      <th>Diabetic_Yes (during pregnancy)</th>\n",
              "      <th>PhysicalActivity_Yes</th>\n",
              "      <th>GenHealth_Fair</th>\n",
              "      <th>GenHealth_Good</th>\n",
              "      <th>GenHealth_Poor</th>\n",
              "      <th>GenHealth_Very good</th>\n",
              "      <th>Asthma_Yes</th>\n",
              "      <th>KidneyDisease_Yes</th>\n",
              "      <th>SkinCancer_Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.844750</td>\n",
              "      <td>-0.046751</td>\n",
              "      <td>3.281069</td>\n",
              "      <td>-1.460354</td>\n",
              "      <td>1.193474</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>-0.951711</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>2.614905</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>1.344886</td>\n",
              "      <td>2.541515</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>3.118419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.256338</td>\n",
              "      <td>-0.424070</td>\n",
              "      <td>-0.490039</td>\n",
              "      <td>-0.067601</td>\n",
              "      <td>-0.837890</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>5.049478</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>-0.951711</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>1.344886</td>\n",
              "      <td>-0.393466</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>-0.320675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.274603</td>\n",
              "      <td>2.091388</td>\n",
              "      <td>3.281069</td>\n",
              "      <td>0.628776</td>\n",
              "      <td>1.193474</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>1.050739</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>2.614905</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>2.867422</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>-0.743558</td>\n",
              "      <td>2.541515</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>-0.320675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.647473</td>\n",
              "      <td>-0.424070</td>\n",
              "      <td>-0.490039</td>\n",
              "      <td>-0.763977</td>\n",
              "      <td>-0.837890</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>-0.951711</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>-1.857852</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>1.560094</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>-0.743558</td>\n",
              "      <td>-0.393466</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>3.118419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.726138</td>\n",
              "      <td>3.097572</td>\n",
              "      <td>-0.490039</td>\n",
              "      <td>0.628776</td>\n",
              "      <td>-0.837890</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>2.490174</td>\n",
              "      <td>-0.951711</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>1.344886</td>\n",
              "      <td>-0.393466</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>-0.320675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33cb4094-fae6-4489-938b-6e5c74fa8be4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33cb4094-fae6-4489-938b-6e5c74fa8be4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33cb4094-fae6-4489-938b-6e5c74fa8be4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2STvERS89-R4",
        "outputId": "61b4790f-969c-457a-e4bb-0a7cb062f9fd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   HeartDisease_No  HeartDisease_Yes\n",
              "0              1.0               0.0\n",
              "1              1.0               0.0\n",
              "2              1.0               0.0\n",
              "3              1.0               0.0\n",
              "4              1.0               0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa149478-b563-4d5f-85cc-6bd808432ac3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HeartDisease_No</th>\n",
              "      <th>HeartDisease_Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa149478-b563-4d5f-85cc-6bd808432ac3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa149478-b563-4d5f-85cc-6bd808432ac3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa149478-b563-4d5f-85cc-6bd808432ac3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Under Sampling (For imbalance dataset)**"
      ],
      "metadata": {
        "id": "NiQ7NuN8QLR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
        "ros = RandomOverSampler(random_state=23)\n",
        "X_us,Y_us = undersample.fit_resample(np.asarray(X), np.asarray(Y))\n",
        "X_os,Y_os = ros.fit_resample(np.asarray(X), np.asarray(Y))"
      ],
      "metadata": {
        "id": "rxaB179rMow2"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_us = pd.DataFrame(X_us)\n",
        "X_us.columns = X.columns\n",
        "Y_us = pd.DataFrame(Y_us)\n",
        "\n",
        "X_os = pd.DataFrame(X_os)\n",
        "X_os.columns = X.columns\n",
        "Y_os = pd.DataFrame(Y_os)\n"
      ],
      "metadata": {
        "id": "BNGb_JyqNMnq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(Y_us)\n",
        "labels = to_categorical(labels)\n",
        "Y_us = np.array(labels)\n",
        "Y_us = pd.DataFrame(Y_us)\n",
        "Y_us.columns = ['HeartDisease_No','HeartDisease_Yes']\n",
        "\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(Y_os)\n",
        "labels = to_categorical(labels)\n",
        "Y_os = np.array(labels)\n",
        "Y_os = pd.DataFrame(Y_os)\n",
        "Y_os.columns = ['HeartDisease_No','HeartDisease_Yes']"
      ],
      "metadata": {
        "id": "r9CnCPsNNt2A"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "DvKyUWw1N8IQ",
        "outputId": "46e62d4b-4b1f-43e0-a43b-4cb4dc5faf47"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             BMI  PhysicalHealth  MentalHealth  SleepTime  Smoking_Yes  \\\n",
              "0      -1.844750       -0.046751      3.281069  -1.460354     1.193474   \n",
              "1      -1.256338       -0.424070     -0.490039  -0.067601    -0.837890   \n",
              "2      -0.274603        2.091388      3.281069   0.628776     1.193474   \n",
              "3      -0.647473       -0.424070     -0.490039  -0.763977    -0.837890   \n",
              "4      -0.726138        3.097572     -0.490039   0.628776    -0.837890   \n",
              "...          ...             ...           ...        ...          ...   \n",
              "584839 -0.136153       -0.298297     -0.490039   0.628776    -0.837890   \n",
              "584840 -0.622301       -0.424070      0.138479  -0.067601    -0.837890   \n",
              "584841  1.352184       -0.046751     -0.364335  -0.067601     1.193474   \n",
              "584842 -0.324948        1.336751      2.024033  -0.763977    -0.837890   \n",
              "584843 -0.257296       -0.424070     -0.490039  -1.460354     1.193474   \n",
              "\n",
              "        AlcoholDrinking_Yes  Stroke_Yes  DiffWalking_Yes  Sex_Male  \\\n",
              "0                  -0.27032   -0.198040        -0.401578 -0.951711   \n",
              "1                  -0.27032    5.049478        -0.401578 -0.951711   \n",
              "2                  -0.27032   -0.198040        -0.401578  1.050739   \n",
              "3                  -0.27032   -0.198040        -0.401578 -0.951711   \n",
              "4                  -0.27032   -0.198040         2.490174 -0.951711   \n",
              "...                     ...         ...              ...       ...   \n",
              "584839             -0.27032   -0.198040        -0.401578 -0.951711   \n",
              "584840             -0.27032    5.049478        -0.401578 -0.951711   \n",
              "584841             -0.27032   -0.198040         2.490174  1.050739   \n",
              "584842             -0.27032   -0.198040         2.490174 -0.951711   \n",
              "584843             -0.27032    5.049478         2.490174  1.050739   \n",
              "\n",
              "        AgeCategory_25-29  ...  Diabetic_Yes  Diabetic_Yes (during pregnancy)  \\\n",
              "0               -0.236615  ...      2.614905                        -0.089814   \n",
              "1               -0.236615  ...     -0.382423                        -0.089814   \n",
              "2               -0.236615  ...      2.614905                        -0.089814   \n",
              "3               -0.236615  ...     -0.382423                        -0.089814   \n",
              "4               -0.236615  ...     -0.382423                        -0.089814   \n",
              "...                   ...  ...           ...                              ...   \n",
              "584839          -0.236615  ...     -0.382423                        -0.089814   \n",
              "584840          -0.236615  ...     -0.382423                        -0.089814   \n",
              "584841          -0.236615  ...     -0.382423                        -0.089814   \n",
              "584842          -0.236615  ...      2.614905                        -0.089814   \n",
              "584843          -0.236615  ...     -0.382423                        -0.089814   \n",
              "\n",
              "        PhysicalActivity_Yes  GenHealth_Fair  GenHealth_Good  GenHealth_Poor  \\\n",
              "0                   0.538256       -0.348745       -0.640987       -0.191292   \n",
              "1                   0.538256       -0.348745       -0.640987       -0.191292   \n",
              "2                   0.538256        2.867422       -0.640987       -0.191292   \n",
              "3                  -1.857852       -0.348745        1.560094       -0.191292   \n",
              "4                   0.538256       -0.348745       -0.640987       -0.191292   \n",
              "...                      ...             ...             ...             ...   \n",
              "584839              0.538256       -0.348745        1.560094       -0.191292   \n",
              "584840              0.538256       -0.348745        1.560094       -0.191292   \n",
              "584841             -1.857852        2.867422       -0.640987       -0.191292   \n",
              "584842              0.538256       -0.348745       -0.640987        5.227621   \n",
              "584843              0.538256        2.867422       -0.640987       -0.191292   \n",
              "\n",
              "        GenHealth_Very good  Asthma_Yes  KidneyDisease_Yes  SkinCancer_Yes  \n",
              "0                  1.344886    2.541515          -0.195554        3.118419  \n",
              "1                  1.344886   -0.393466          -0.195554       -0.320675  \n",
              "2                 -0.743558    2.541515          -0.195554       -0.320675  \n",
              "3                 -0.743558   -0.393466          -0.195554        3.118419  \n",
              "4                  1.344886   -0.393466          -0.195554       -0.320675  \n",
              "...                     ...         ...                ...             ...  \n",
              "584839            -0.743558   -0.393466          -0.195554       -0.320675  \n",
              "584840            -0.743558   -0.393466          -0.195554        3.118419  \n",
              "584841            -0.743558    2.541515          -0.195554       -0.320675  \n",
              "584842            -0.743558    2.541515          -0.195554        3.118419  \n",
              "584843            -0.743558   -0.393466          -0.195554       -0.320675  \n",
              "\n",
              "[584844 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63a75ef7-e0d7-4ce5-a3f4-052af5a726ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BMI</th>\n",
              "      <th>PhysicalHealth</th>\n",
              "      <th>MentalHealth</th>\n",
              "      <th>SleepTime</th>\n",
              "      <th>Smoking_Yes</th>\n",
              "      <th>AlcoholDrinking_Yes</th>\n",
              "      <th>Stroke_Yes</th>\n",
              "      <th>DiffWalking_Yes</th>\n",
              "      <th>Sex_Male</th>\n",
              "      <th>AgeCategory_25-29</th>\n",
              "      <th>...</th>\n",
              "      <th>Diabetic_Yes</th>\n",
              "      <th>Diabetic_Yes (during pregnancy)</th>\n",
              "      <th>PhysicalActivity_Yes</th>\n",
              "      <th>GenHealth_Fair</th>\n",
              "      <th>GenHealth_Good</th>\n",
              "      <th>GenHealth_Poor</th>\n",
              "      <th>GenHealth_Very good</th>\n",
              "      <th>Asthma_Yes</th>\n",
              "      <th>KidneyDisease_Yes</th>\n",
              "      <th>SkinCancer_Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.844750</td>\n",
              "      <td>-0.046751</td>\n",
              "      <td>3.281069</td>\n",
              "      <td>-1.460354</td>\n",
              "      <td>1.193474</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>-0.951711</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>2.614905</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>1.344886</td>\n",
              "      <td>2.541515</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>3.118419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.256338</td>\n",
              "      <td>-0.424070</td>\n",
              "      <td>-0.490039</td>\n",
              "      <td>-0.067601</td>\n",
              "      <td>-0.837890</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>5.049478</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>-0.951711</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>1.344886</td>\n",
              "      <td>-0.393466</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>-0.320675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.274603</td>\n",
              "      <td>2.091388</td>\n",
              "      <td>3.281069</td>\n",
              "      <td>0.628776</td>\n",
              "      <td>1.193474</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>1.050739</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>2.614905</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>2.867422</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>-0.743558</td>\n",
              "      <td>2.541515</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>-0.320675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.647473</td>\n",
              "      <td>-0.424070</td>\n",
              "      <td>-0.490039</td>\n",
              "      <td>-0.763977</td>\n",
              "      <td>-0.837890</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>-0.951711</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>-1.857852</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>1.560094</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>-0.743558</td>\n",
              "      <td>-0.393466</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>3.118419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.726138</td>\n",
              "      <td>3.097572</td>\n",
              "      <td>-0.490039</td>\n",
              "      <td>0.628776</td>\n",
              "      <td>-0.837890</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>2.490174</td>\n",
              "      <td>-0.951711</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>1.344886</td>\n",
              "      <td>-0.393466</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>-0.320675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584839</th>\n",
              "      <td>-0.136153</td>\n",
              "      <td>-0.298297</td>\n",
              "      <td>-0.490039</td>\n",
              "      <td>0.628776</td>\n",
              "      <td>-0.837890</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>-0.951711</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>1.560094</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>-0.743558</td>\n",
              "      <td>-0.393466</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>-0.320675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584840</th>\n",
              "      <td>-0.622301</td>\n",
              "      <td>-0.424070</td>\n",
              "      <td>0.138479</td>\n",
              "      <td>-0.067601</td>\n",
              "      <td>-0.837890</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>5.049478</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>-0.951711</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>1.560094</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>-0.743558</td>\n",
              "      <td>-0.393466</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>3.118419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584841</th>\n",
              "      <td>1.352184</td>\n",
              "      <td>-0.046751</td>\n",
              "      <td>-0.364335</td>\n",
              "      <td>-0.067601</td>\n",
              "      <td>1.193474</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>2.490174</td>\n",
              "      <td>1.050739</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>-1.857852</td>\n",
              "      <td>2.867422</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>-0.743558</td>\n",
              "      <td>2.541515</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>-0.320675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584842</th>\n",
              "      <td>-0.324948</td>\n",
              "      <td>1.336751</td>\n",
              "      <td>2.024033</td>\n",
              "      <td>-0.763977</td>\n",
              "      <td>-0.837890</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>2.490174</td>\n",
              "      <td>-0.951711</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>2.614905</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>5.227621</td>\n",
              "      <td>-0.743558</td>\n",
              "      <td>2.541515</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>3.118419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584843</th>\n",
              "      <td>-0.257296</td>\n",
              "      <td>-0.424070</td>\n",
              "      <td>-0.490039</td>\n",
              "      <td>-1.460354</td>\n",
              "      <td>1.193474</td>\n",
              "      <td>-0.27032</td>\n",
              "      <td>5.049478</td>\n",
              "      <td>2.490174</td>\n",
              "      <td>1.050739</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>2.867422</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>-0.743558</td>\n",
              "      <td>-0.393466</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>-0.320675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>584844 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63a75ef7-e0d7-4ce5-a3f4-052af5a726ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63a75ef7-e0d7-4ce5-a3f4-052af5a726ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63a75ef7-e0d7-4ce5-a3f4-052af5a726ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_os.info()"
      ],
      "metadata": {
        "id": "CAdaj9_oMZqy",
        "outputId": "82f50561-36b3-44e9-ef77-42e409150df5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 584844 entries, 0 to 584843\n",
            "Data columns (total 37 columns):\n",
            " #   Column                            Non-Null Count   Dtype  \n",
            "---  ------                            --------------   -----  \n",
            " 0   BMI                               584844 non-null  float64\n",
            " 1   PhysicalHealth                    584844 non-null  float64\n",
            " 2   MentalHealth                      584844 non-null  float64\n",
            " 3   SleepTime                         584844 non-null  float64\n",
            " 4   Smoking_Yes                       584844 non-null  float64\n",
            " 5   AlcoholDrinking_Yes               584844 non-null  float64\n",
            " 6   Stroke_Yes                        584844 non-null  float64\n",
            " 7   DiffWalking_Yes                   584844 non-null  float64\n",
            " 8   Sex_Male                          584844 non-null  float64\n",
            " 9   AgeCategory_25-29                 584844 non-null  float64\n",
            " 10  AgeCategory_30-34                 584844 non-null  float64\n",
            " 11  AgeCategory_35-39                 584844 non-null  float64\n",
            " 12  AgeCategory_40-44                 584844 non-null  float64\n",
            " 13  AgeCategory_45-49                 584844 non-null  float64\n",
            " 14  AgeCategory_50-54                 584844 non-null  float64\n",
            " 15  AgeCategory_55-59                 584844 non-null  float64\n",
            " 16  AgeCategory_60-64                 584844 non-null  float64\n",
            " 17  AgeCategory_65-69                 584844 non-null  float64\n",
            " 18  AgeCategory_70-74                 584844 non-null  float64\n",
            " 19  AgeCategory_75-79                 584844 non-null  float64\n",
            " 20  AgeCategory_80 or older           584844 non-null  float64\n",
            " 21  Race_Asian                        584844 non-null  float64\n",
            " 22  Race_Black                        584844 non-null  float64\n",
            " 23  Race_Hispanic                     584844 non-null  float64\n",
            " 24  Race_Other                        584844 non-null  float64\n",
            " 25  Race_White                        584844 non-null  float64\n",
            " 26  Diabetic_No, borderline diabetes  584844 non-null  float64\n",
            " 27  Diabetic_Yes                      584844 non-null  float64\n",
            " 28  Diabetic_Yes (during pregnancy)   584844 non-null  float64\n",
            " 29  PhysicalActivity_Yes              584844 non-null  float64\n",
            " 30  GenHealth_Fair                    584844 non-null  float64\n",
            " 31  GenHealth_Good                    584844 non-null  float64\n",
            " 32  GenHealth_Poor                    584844 non-null  float64\n",
            " 33  GenHealth_Very good               584844 non-null  float64\n",
            " 34  Asthma_Yes                        584844 non-null  float64\n",
            " 35  KidneyDisease_Yes                 584844 non-null  float64\n",
            " 36  SkinCancer_Yes                    584844 non-null  float64\n",
            "dtypes: float64(37)\n",
            "memory usage: 165.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_os.describe()"
      ],
      "metadata": {
        "id": "ueoJhpRM5P8y",
        "outputId": "84757910-fad9-4816-b7f3-d437a479b138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 BMI  PhysicalHealth   MentalHealth      SleepTime  \\\n",
              "count  584844.000000   584844.000000  584844.000000  584844.000000   \n",
              "mean        0.076505        0.254084       0.044355       0.010679   \n",
              "std         1.021064        1.254174       1.075435       1.113783   \n",
              "min        -2.565319       -0.424070      -0.490039      -4.245859   \n",
              "25%        -0.619154       -0.424070      -0.490039      -0.763977   \n",
              "50%        -0.088954       -0.424070      -0.490039      -0.067601   \n",
              "75%         0.590709        0.204795      -0.112928       0.628776   \n",
              "max        10.466277        3.349118       3.281069      11.770800   \n",
              "\n",
              "         Smoking_Yes  AlcoholDrinking_Yes     Stroke_Yes  DiffWalking_Yes  \\\n",
              "count  584844.000000        584844.000000  584844.000000    584844.000000   \n",
              "mean        0.159939            -0.047085       0.295098         0.298803   \n",
              "std         1.015526             0.914511       1.531199         1.238870   \n",
              "min        -0.837890            -0.270320      -0.198040        -0.401578   \n",
              "25%        -0.837890            -0.270320      -0.198040        -0.401578   \n",
              "50%        -0.837890            -0.270320      -0.198040        -0.401578   \n",
              "75%         1.193474            -0.270320      -0.198040        -0.401578   \n",
              "max         1.193474             3.699323       5.049478         2.490174   \n",
              "\n",
              "            Sex_Male  AgeCategory_25-29  ...   Diabetic_Yes  \\\n",
              "count  584844.000000      584844.000000  ...  584844.000000   \n",
              "mean        0.104081          -0.097244  ...       0.270784   \n",
              "std         0.999738           0.776256  ...       1.237417   \n",
              "min        -0.951711          -0.236615  ...      -0.382423   \n",
              "25%        -0.951711          -0.236615  ...      -0.382423   \n",
              "50%         1.050739          -0.236615  ...      -0.382423   \n",
              "75%         1.050739          -0.236615  ...      -0.382423   \n",
              "max         1.050739           4.226275  ...       2.614905   \n",
              "\n",
              "       Diabetic_Yes (during pregnancy)  PhysicalActivity_Yes  GenHealth_Fair  \\\n",
              "count                    584844.000000         584844.000000   584844.000000   \n",
              "mean                         -0.021013             -0.146734        0.218886   \n",
              "std                           0.876062              1.082636        1.226130   \n",
              "min                          -0.089814             -1.857852       -0.348745   \n",
              "25%                          -0.089814             -1.857852       -0.348745   \n",
              "50%                          -0.089814              0.538256       -0.348745   \n",
              "75%                          -0.089814              0.538256       -0.348745   \n",
              "max                          11.134125              0.538256        2.867422   \n",
              "\n",
              "       GenHealth_Good  GenHealth_Poor  GenHealth_Very good     Asthma_Yes  \\\n",
              "count   584844.000000   584844.000000        584844.000000  584844.000000   \n",
              "mean         0.057277        0.261276            -0.151292       0.061818   \n",
              "std          1.024385        1.499203             0.941348       1.062529   \n",
              "min         -0.640987       -0.191292            -0.743558      -0.393466   \n",
              "25%         -0.640987       -0.191292            -0.743558      -0.393466   \n",
              "50%         -0.640987       -0.191292            -0.743558      -0.393466   \n",
              "75%          1.560094       -0.191292             1.344886      -0.393466   \n",
              "max          1.560094        5.227621             1.344886       2.541515   \n",
              "\n",
              "       KidneyDisease_Yes  SkinCancer_Yes  \n",
              "count      584844.000000   584844.000000  \n",
              "mean            0.212148        0.137170  \n",
              "std             1.413636        1.168312  \n",
              "min            -0.195554       -0.320675  \n",
              "25%            -0.195554       -0.320675  \n",
              "50%            -0.195554       -0.320675  \n",
              "75%            -0.195554       -0.320675  \n",
              "max             5.113667        3.118419  \n",
              "\n",
              "[8 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5445890f-e3b2-4684-a134-6d8aa4198017\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BMI</th>\n",
              "      <th>PhysicalHealth</th>\n",
              "      <th>MentalHealth</th>\n",
              "      <th>SleepTime</th>\n",
              "      <th>Smoking_Yes</th>\n",
              "      <th>AlcoholDrinking_Yes</th>\n",
              "      <th>Stroke_Yes</th>\n",
              "      <th>DiffWalking_Yes</th>\n",
              "      <th>Sex_Male</th>\n",
              "      <th>AgeCategory_25-29</th>\n",
              "      <th>...</th>\n",
              "      <th>Diabetic_Yes</th>\n",
              "      <th>Diabetic_Yes (during pregnancy)</th>\n",
              "      <th>PhysicalActivity_Yes</th>\n",
              "      <th>GenHealth_Fair</th>\n",
              "      <th>GenHealth_Good</th>\n",
              "      <th>GenHealth_Poor</th>\n",
              "      <th>GenHealth_Very good</th>\n",
              "      <th>Asthma_Yes</th>\n",
              "      <th>KidneyDisease_Yes</th>\n",
              "      <th>SkinCancer_Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "      <td>584844.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.076505</td>\n",
              "      <td>0.254084</td>\n",
              "      <td>0.044355</td>\n",
              "      <td>0.010679</td>\n",
              "      <td>0.159939</td>\n",
              "      <td>-0.047085</td>\n",
              "      <td>0.295098</td>\n",
              "      <td>0.298803</td>\n",
              "      <td>0.104081</td>\n",
              "      <td>-0.097244</td>\n",
              "      <td>...</td>\n",
              "      <td>0.270784</td>\n",
              "      <td>-0.021013</td>\n",
              "      <td>-0.146734</td>\n",
              "      <td>0.218886</td>\n",
              "      <td>0.057277</td>\n",
              "      <td>0.261276</td>\n",
              "      <td>-0.151292</td>\n",
              "      <td>0.061818</td>\n",
              "      <td>0.212148</td>\n",
              "      <td>0.137170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.021064</td>\n",
              "      <td>1.254174</td>\n",
              "      <td>1.075435</td>\n",
              "      <td>1.113783</td>\n",
              "      <td>1.015526</td>\n",
              "      <td>0.914511</td>\n",
              "      <td>1.531199</td>\n",
              "      <td>1.238870</td>\n",
              "      <td>0.999738</td>\n",
              "      <td>0.776256</td>\n",
              "      <td>...</td>\n",
              "      <td>1.237417</td>\n",
              "      <td>0.876062</td>\n",
              "      <td>1.082636</td>\n",
              "      <td>1.226130</td>\n",
              "      <td>1.024385</td>\n",
              "      <td>1.499203</td>\n",
              "      <td>0.941348</td>\n",
              "      <td>1.062529</td>\n",
              "      <td>1.413636</td>\n",
              "      <td>1.168312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.565319</td>\n",
              "      <td>-0.424070</td>\n",
              "      <td>-0.490039</td>\n",
              "      <td>-4.245859</td>\n",
              "      <td>-0.837890</td>\n",
              "      <td>-0.270320</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>-0.951711</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>-1.857852</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>-0.743558</td>\n",
              "      <td>-0.393466</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>-0.320675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.619154</td>\n",
              "      <td>-0.424070</td>\n",
              "      <td>-0.490039</td>\n",
              "      <td>-0.763977</td>\n",
              "      <td>-0.837890</td>\n",
              "      <td>-0.270320</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>-0.951711</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>-1.857852</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>-0.743558</td>\n",
              "      <td>-0.393466</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>-0.320675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.088954</td>\n",
              "      <td>-0.424070</td>\n",
              "      <td>-0.490039</td>\n",
              "      <td>-0.067601</td>\n",
              "      <td>-0.837890</td>\n",
              "      <td>-0.270320</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>1.050739</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>-0.640987</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>-0.743558</td>\n",
              "      <td>-0.393466</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>-0.320675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.590709</td>\n",
              "      <td>0.204795</td>\n",
              "      <td>-0.112928</td>\n",
              "      <td>0.628776</td>\n",
              "      <td>1.193474</td>\n",
              "      <td>-0.270320</td>\n",
              "      <td>-0.198040</td>\n",
              "      <td>-0.401578</td>\n",
              "      <td>1.050739</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.382423</td>\n",
              "      <td>-0.089814</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>-0.348745</td>\n",
              "      <td>1.560094</td>\n",
              "      <td>-0.191292</td>\n",
              "      <td>1.344886</td>\n",
              "      <td>-0.393466</td>\n",
              "      <td>-0.195554</td>\n",
              "      <td>-0.320675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.466277</td>\n",
              "      <td>3.349118</td>\n",
              "      <td>3.281069</td>\n",
              "      <td>11.770800</td>\n",
              "      <td>1.193474</td>\n",
              "      <td>3.699323</td>\n",
              "      <td>5.049478</td>\n",
              "      <td>2.490174</td>\n",
              "      <td>1.050739</td>\n",
              "      <td>4.226275</td>\n",
              "      <td>...</td>\n",
              "      <td>2.614905</td>\n",
              "      <td>11.134125</td>\n",
              "      <td>0.538256</td>\n",
              "      <td>2.867422</td>\n",
              "      <td>1.560094</td>\n",
              "      <td>5.227621</td>\n",
              "      <td>1.344886</td>\n",
              "      <td>2.541515</td>\n",
              "      <td>5.113667</td>\n",
              "      <td>3.118419</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5445890f-e3b2-4684-a134-6d8aa4198017')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5445890f-e3b2-4684-a134-6d8aa4198017 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5445890f-e3b2-4684-a134-6d8aa4198017');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split"
      ],
      "metadata": {
        "id": "fQb4X3hz-TPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "qrLhrtG0-j9h"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(X_us,Y_us,test_size=0.3,random_state=23)\n",
        "x_train1,x_test1,y_train1,y_test1 = train_test_split(X,Y,test_size=0.3,random_state=23)\n",
        "x_train2,x_test2,y_train2,y_test2 = train_test_split(X_os,Y_os,test_size=0.3,random_state=23)"
      ],
      "metadata": {
        "id": "ib21we9W-WQa"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN Training"
      ],
      "metadata": {
        "id": "8-mv87Rw-sZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define parameter and Create Model**"
      ],
      "metadata": {
        "id": "NP9MGInT-6a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "kqohRP7T_K5l"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3\n",
        "\n",
        "modelKNN = KNeighborsClassifier(n_neighbors=k,p=2)\n",
        "modelKNN.fit(x_train1,y_train1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyep2dyq-z0z",
        "outputId": "db5042e0-10d6-46d1-bf3b-1348c7885a4d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = modelKNN.predict(x_test1)\n",
        "KNNScore = accuracy_score(y_test1,pred)"
      ],
      "metadata": {
        "id": "brD8dFwh_fR2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('KNN Accuracy :',KNNScore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aExenlQB9_6",
        "outputId": "2dc0816e-dbcf-444a-d65d-41426c31b928"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy : 0.8997800685852468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = pd.DataFrame(pred)\n",
        "y_pred = df_pred.idxmax(axis=1)"
      ],
      "metadata": {
        "id": "pKhkllroGygv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.asarray(y_test1)\n",
        "df_true = pd.DataFrame(y_true)\n",
        "y_true = df_true.idxmax(axis=1)"
      ],
      "metadata": {
        "id": "3FXJtOPTImn6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('--------- Confusion matrix-----------')\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print('--------- Classification Report matrix -----------')\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m85_6N53CUOF",
        "outputId": "98b32aff-8a97-4630-c87b-1faa8577d08a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- Confusion matrix-----------\n",
            "[[84890  2963]\n",
            " [ 6652  1434]]\n",
            "--------- Classification Report matrix -----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95     87853\n",
            "           1       0.33      0.18      0.23      8086\n",
            "\n",
            "    accuracy                           0.90     95939\n",
            "   macro avg       0.63      0.57      0.59     95939\n",
            "weighted avg       0.88      0.90      0.89     95939\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN Training With Oversampling"
      ],
      "metadata": {
        "id": "Bkb88S7jWmZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3\n",
        "\n",
        "modelKNN = KNeighborsClassifier(n_neighbors=k,p=2)\n",
        "modelKNN.fit(x_train2,y_train2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUlNtqwpZPIa",
        "outputId": "7b87134c-afab-4cd5-a957-679661922f8c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_us = modelKNN.predict(x_test2)\n",
        "KNNScore_us = accuracy_score(y_test2,pred_us)"
      ],
      "metadata": {
        "id": "iVFJd7e1ZSIU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('KNN Accuracy :',KNNScore_us)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU2KhshVZXFH",
        "outputId": "58dff0f2-dac4-46a6-b099-5f120d8fa10d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy : 0.9160634696273667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred_us = pd.DataFrame(pred_us)\n",
        "y_pred_us = df_pred_us.idxmax(axis=1)"
      ],
      "metadata": {
        "id": "0LhworS_ZaUO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_us = np.asarray(y_test2)\n",
        "df_true_us = pd.DataFrame(y_true_us)\n",
        "y_true_us = df_true_us.idxmax(axis=1)"
      ],
      "metadata": {
        "id": "rwUI5srQZsDr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('--------- Confusion matrix-----------')\n",
        "print(confusion_matrix(y_true_us, y_pred_us))\n",
        "print('--------- Classification Report matrix -----------')\n",
        "print(classification_report(y_true_us, y_pred_us))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OKMb1peZxmi",
        "outputId": "1d3426d9-864a-482a-d761-3bc50be45a2f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- Confusion matrix-----------\n",
            "[[73403 14404]\n",
            " [  323 87324]]\n",
            "--------- Classification Report matrix -----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.84      0.91     87807\n",
            "           1       0.86      1.00      0.92     87647\n",
            "\n",
            "    accuracy                           0.92    175454\n",
            "   macro avg       0.93      0.92      0.92    175454\n",
            "weighted avg       0.93      0.92      0.92    175454\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NeuralNetwork Training with Oversampling\n",
        "\n"
      ],
      "metadata": {
        "id": "wG90K3VobPxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "metadata": {
        "id": "IMzaCcOubTtM"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelNN = Sequential()\n",
        "modelNN.add(Dense(128, input_dim=37, activation='relu'))\n",
        "modelNN.add(Dense(128, activation='sigmoid'))\n",
        "modelNN.add(Dense(128, activation='sigmoid'))\n",
        "modelNN.add(Dropout(0.5))\n",
        "modelNN.add(Dense(2, activation='softmax'))\n",
        "modelNN.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Jh2JEWxGdNLi"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84kcGAh6fvJT",
        "outputId": "88320210-a3e7-4d4f-d6cc-15b0c4fa803c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 128)               4864      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,146\n",
            "Trainable params: 38,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = modelNN.fit(x_train2, y_train2, epochs=150, batch_size=32,verbose=1,validation_data=(x_test2,y_test2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXbr6E5YgEUw",
        "outputId": "14cb330d-0d6a-4e4d-e792-e6ce077196eb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.4938 - accuracy: 0.7651 - val_loss: 0.4837 - val_accuracy: 0.7693\n",
            "Epoch 2/150\n",
            "12794/12794 [==============================] - 35s 3ms/step - loss: 0.4854 - accuracy: 0.7697 - val_loss: 0.4802 - val_accuracy: 0.7698\n",
            "Epoch 3/150\n",
            "12794/12794 [==============================] - 35s 3ms/step - loss: 0.4805 - accuracy: 0.7712 - val_loss: 0.4752 - val_accuracy: 0.7729\n",
            "Epoch 4/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.4728 - accuracy: 0.7738 - val_loss: 0.4685 - val_accuracy: 0.7749\n",
            "Epoch 5/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.4630 - accuracy: 0.7781 - val_loss: 0.4567 - val_accuracy: 0.7798\n",
            "Epoch 6/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.4514 - accuracy: 0.7838 - val_loss: 0.4482 - val_accuracy: 0.7844\n",
            "Epoch 7/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.4396 - accuracy: 0.7904 - val_loss: 0.4385 - val_accuracy: 0.7900\n",
            "Epoch 8/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.4279 - accuracy: 0.7972 - val_loss: 0.4289 - val_accuracy: 0.7956\n",
            "Epoch 9/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.4174 - accuracy: 0.8032 - val_loss: 0.4226 - val_accuracy: 0.8008\n",
            "Epoch 10/150\n",
            "12794/12794 [==============================] - 35s 3ms/step - loss: 0.4088 - accuracy: 0.8084 - val_loss: 0.4165 - val_accuracy: 0.8039\n",
            "Epoch 11/150\n",
            "12794/12794 [==============================] - 35s 3ms/step - loss: 0.4006 - accuracy: 0.8133 - val_loss: 0.4099 - val_accuracy: 0.8093\n",
            "Epoch 12/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.3932 - accuracy: 0.8175 - val_loss: 0.4123 - val_accuracy: 0.8073\n",
            "Epoch 13/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.3872 - accuracy: 0.8215 - val_loss: 0.3992 - val_accuracy: 0.8162\n",
            "Epoch 14/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.3815 - accuracy: 0.8242 - val_loss: 0.3946 - val_accuracy: 0.8185\n",
            "Epoch 15/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3768 - accuracy: 0.8273 - val_loss: 0.3931 - val_accuracy: 0.8198\n",
            "Epoch 16/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3723 - accuracy: 0.8296 - val_loss: 0.3920 - val_accuracy: 0.8216\n",
            "Epoch 17/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3672 - accuracy: 0.8323 - val_loss: 0.3829 - val_accuracy: 0.8252\n",
            "Epoch 18/150\n",
            "12794/12794 [==============================] - 35s 3ms/step - loss: 0.3642 - accuracy: 0.8346 - val_loss: 0.3834 - val_accuracy: 0.8248\n",
            "Epoch 19/150\n",
            "12794/12794 [==============================] - 35s 3ms/step - loss: 0.3612 - accuracy: 0.8361 - val_loss: 0.3836 - val_accuracy: 0.8259\n",
            "Epoch 20/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.3574 - accuracy: 0.8382 - val_loss: 0.3778 - val_accuracy: 0.8275\n",
            "Epoch 21/150\n",
            "12794/12794 [==============================] - 35s 3ms/step - loss: 0.3545 - accuracy: 0.8397 - val_loss: 0.3821 - val_accuracy: 0.8286\n",
            "Epoch 22/150\n",
            "12794/12794 [==============================] - 35s 3ms/step - loss: 0.3519 - accuracy: 0.8416 - val_loss: 0.3732 - val_accuracy: 0.8315\n",
            "Epoch 23/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.3483 - accuracy: 0.8431 - val_loss: 0.3725 - val_accuracy: 0.8329\n",
            "Epoch 24/150\n",
            "12794/12794 [==============================] - 35s 3ms/step - loss: 0.3464 - accuracy: 0.8446 - val_loss: 0.3695 - val_accuracy: 0.8338\n",
            "Epoch 25/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3446 - accuracy: 0.8462 - val_loss: 0.3643 - val_accuracy: 0.8373\n",
            "Epoch 26/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3414 - accuracy: 0.8473 - val_loss: 0.3681 - val_accuracy: 0.8361\n",
            "Epoch 27/150\n",
            "12794/12794 [==============================] - 35s 3ms/step - loss: 0.3403 - accuracy: 0.8479 - val_loss: 0.3678 - val_accuracy: 0.8362\n",
            "Epoch 28/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.3383 - accuracy: 0.8489 - val_loss: 0.3634 - val_accuracy: 0.8374\n",
            "Epoch 29/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.3369 - accuracy: 0.8500 - val_loss: 0.3641 - val_accuracy: 0.8386\n",
            "Epoch 30/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.3347 - accuracy: 0.8511 - val_loss: 0.3624 - val_accuracy: 0.8383\n",
            "Epoch 31/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3332 - accuracy: 0.8521 - val_loss: 0.3648 - val_accuracy: 0.8374\n",
            "Epoch 32/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3316 - accuracy: 0.8531 - val_loss: 0.3607 - val_accuracy: 0.8402\n",
            "Epoch 33/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.3301 - accuracy: 0.8539 - val_loss: 0.3614 - val_accuracy: 0.8420\n",
            "Epoch 34/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.3295 - accuracy: 0.8540 - val_loss: 0.3620 - val_accuracy: 0.8405\n",
            "Epoch 35/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.3274 - accuracy: 0.8552 - val_loss: 0.3592 - val_accuracy: 0.8419\n",
            "Epoch 36/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3259 - accuracy: 0.8563 - val_loss: 0.3576 - val_accuracy: 0.8415\n",
            "Epoch 37/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.3254 - accuracy: 0.8562 - val_loss: 0.3577 - val_accuracy: 0.8419\n",
            "Epoch 38/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3238 - accuracy: 0.8567 - val_loss: 0.3535 - val_accuracy: 0.8453\n",
            "Epoch 39/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3232 - accuracy: 0.8575 - val_loss: 0.3527 - val_accuracy: 0.8461\n",
            "Epoch 40/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.3219 - accuracy: 0.8580 - val_loss: 0.3605 - val_accuracy: 0.8404\n",
            "Epoch 41/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.3212 - accuracy: 0.8587 - val_loss: 0.3553 - val_accuracy: 0.8454\n",
            "Epoch 42/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.3194 - accuracy: 0.8593 - val_loss: 0.3539 - val_accuracy: 0.8442\n",
            "Epoch 43/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.3191 - accuracy: 0.8595 - val_loss: 0.3546 - val_accuracy: 0.8472\n",
            "Epoch 44/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.3184 - accuracy: 0.8600 - val_loss: 0.3479 - val_accuracy: 0.8467\n",
            "Epoch 45/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3172 - accuracy: 0.8606 - val_loss: 0.3518 - val_accuracy: 0.8460\n",
            "Epoch 46/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3166 - accuracy: 0.8609 - val_loss: 0.3511 - val_accuracy: 0.8469\n",
            "Epoch 47/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.3150 - accuracy: 0.8620 - val_loss: 0.3505 - val_accuracy: 0.8486\n",
            "Epoch 48/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3154 - accuracy: 0.8616 - val_loss: 0.3480 - val_accuracy: 0.8490\n",
            "Epoch 49/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3142 - accuracy: 0.8621 - val_loss: 0.3501 - val_accuracy: 0.8488\n",
            "Epoch 50/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3134 - accuracy: 0.8624 - val_loss: 0.3471 - val_accuracy: 0.8488\n",
            "Epoch 51/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.3117 - accuracy: 0.8633 - val_loss: 0.3464 - val_accuracy: 0.8507\n",
            "Epoch 52/150\n",
            "12794/12794 [==============================] - 35s 3ms/step - loss: 0.3119 - accuracy: 0.8636 - val_loss: 0.3513 - val_accuracy: 0.8479\n",
            "Epoch 53/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.3109 - accuracy: 0.8638 - val_loss: 0.3504 - val_accuracy: 0.8490\n",
            "Epoch 54/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3101 - accuracy: 0.8643 - val_loss: 0.3489 - val_accuracy: 0.8489\n",
            "Epoch 55/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3093 - accuracy: 0.8651 - val_loss: 0.3477 - val_accuracy: 0.8481\n",
            "Epoch 56/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3083 - accuracy: 0.8657 - val_loss: 0.3480 - val_accuracy: 0.8507\n",
            "Epoch 57/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3090 - accuracy: 0.8656 - val_loss: 0.3463 - val_accuracy: 0.8515\n",
            "Epoch 58/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.3079 - accuracy: 0.8656 - val_loss: 0.3452 - val_accuracy: 0.8503\n",
            "Epoch 59/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3073 - accuracy: 0.8663 - val_loss: 0.3462 - val_accuracy: 0.8508\n",
            "Epoch 60/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3076 - accuracy: 0.8664 - val_loss: 0.3421 - val_accuracy: 0.8523\n",
            "Epoch 61/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3065 - accuracy: 0.8665 - val_loss: 0.3408 - val_accuracy: 0.8530\n",
            "Epoch 62/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3060 - accuracy: 0.8669 - val_loss: 0.3404 - val_accuracy: 0.8519\n",
            "Epoch 63/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3056 - accuracy: 0.8670 - val_loss: 0.3407 - val_accuracy: 0.8525\n",
            "Epoch 64/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3051 - accuracy: 0.8672 - val_loss: 0.3490 - val_accuracy: 0.8506\n",
            "Epoch 65/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3040 - accuracy: 0.8679 - val_loss: 0.3414 - val_accuracy: 0.8547\n",
            "Epoch 66/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3042 - accuracy: 0.8680 - val_loss: 0.3447 - val_accuracy: 0.8522\n",
            "Epoch 67/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3039 - accuracy: 0.8681 - val_loss: 0.3438 - val_accuracy: 0.8531\n",
            "Epoch 68/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.3032 - accuracy: 0.8687 - val_loss: 0.3397 - val_accuracy: 0.8544\n",
            "Epoch 69/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3027 - accuracy: 0.8685 - val_loss: 0.3405 - val_accuracy: 0.8534\n",
            "Epoch 70/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3011 - accuracy: 0.8694 - val_loss: 0.3418 - val_accuracy: 0.8532\n",
            "Epoch 71/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3016 - accuracy: 0.8690 - val_loss: 0.3399 - val_accuracy: 0.8533\n",
            "Epoch 72/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3017 - accuracy: 0.8692 - val_loss: 0.3401 - val_accuracy: 0.8541\n",
            "Epoch 73/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3007 - accuracy: 0.8695 - val_loss: 0.3388 - val_accuracy: 0.8531\n",
            "Epoch 74/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3006 - accuracy: 0.8694 - val_loss: 0.3382 - val_accuracy: 0.8556\n",
            "Epoch 75/150\n",
            "12794/12794 [==============================] - 36s 3ms/step - loss: 0.3000 - accuracy: 0.8698 - val_loss: 0.3386 - val_accuracy: 0.8551\n",
            "Epoch 76/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.3004 - accuracy: 0.8698 - val_loss: 0.3412 - val_accuracy: 0.8563\n",
            "Epoch 77/150\n",
            "12794/12794 [==============================] - 43s 3ms/step - loss: 0.2991 - accuracy: 0.8706 - val_loss: 0.3401 - val_accuracy: 0.8550\n",
            "Epoch 78/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2997 - accuracy: 0.8707 - val_loss: 0.3363 - val_accuracy: 0.8552\n",
            "Epoch 79/150\n",
            "12794/12794 [==============================] - 38s 3ms/step - loss: 0.2989 - accuracy: 0.8703 - val_loss: 0.3429 - val_accuracy: 0.8540\n",
            "Epoch 80/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2993 - accuracy: 0.8707 - val_loss: 0.3378 - val_accuracy: 0.8551\n",
            "Epoch 81/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2984 - accuracy: 0.8711 - val_loss: 0.3416 - val_accuracy: 0.8532\n",
            "Epoch 82/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2980 - accuracy: 0.8714 - val_loss: 0.3364 - val_accuracy: 0.8567\n",
            "Epoch 83/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2976 - accuracy: 0.8716 - val_loss: 0.3363 - val_accuracy: 0.8560\n",
            "Epoch 84/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2963 - accuracy: 0.8720 - val_loss: 0.3352 - val_accuracy: 0.8574\n",
            "Epoch 85/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2972 - accuracy: 0.8722 - val_loss: 0.3370 - val_accuracy: 0.8567\n",
            "Epoch 86/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.2973 - accuracy: 0.8718 - val_loss: 0.3374 - val_accuracy: 0.8566\n",
            "Epoch 87/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2960 - accuracy: 0.8727 - val_loss: 0.3346 - val_accuracy: 0.8566\n",
            "Epoch 88/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2945 - accuracy: 0.8726 - val_loss: 0.3409 - val_accuracy: 0.8572\n",
            "Epoch 89/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2957 - accuracy: 0.8727 - val_loss: 0.3336 - val_accuracy: 0.8578\n",
            "Epoch 90/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2957 - accuracy: 0.8727 - val_loss: 0.3345 - val_accuracy: 0.8565\n",
            "Epoch 91/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2960 - accuracy: 0.8727 - val_loss: 0.3357 - val_accuracy: 0.8584\n",
            "Epoch 92/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2938 - accuracy: 0.8731 - val_loss: 0.3367 - val_accuracy: 0.8572\n",
            "Epoch 93/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2949 - accuracy: 0.8725 - val_loss: 0.3359 - val_accuracy: 0.8583\n",
            "Epoch 94/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2946 - accuracy: 0.8731 - val_loss: 0.3331 - val_accuracy: 0.8579\n",
            "Epoch 95/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2935 - accuracy: 0.8736 - val_loss: 0.3357 - val_accuracy: 0.8584\n",
            "Epoch 96/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2938 - accuracy: 0.8737 - val_loss: 0.3327 - val_accuracy: 0.8584\n",
            "Epoch 97/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2935 - accuracy: 0.8740 - val_loss: 0.3331 - val_accuracy: 0.8580\n",
            "Epoch 98/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2929 - accuracy: 0.8739 - val_loss: 0.3353 - val_accuracy: 0.8583\n",
            "Epoch 99/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.2931 - accuracy: 0.8737 - val_loss: 0.3373 - val_accuracy: 0.8549\n",
            "Epoch 100/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2932 - accuracy: 0.8738 - val_loss: 0.3325 - val_accuracy: 0.8591\n",
            "Epoch 101/150\n",
            "12794/12794 [==============================] - 38s 3ms/step - loss: 0.2924 - accuracy: 0.8739 - val_loss: 0.3336 - val_accuracy: 0.8593\n",
            "Epoch 102/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2928 - accuracy: 0.8736 - val_loss: 0.3372 - val_accuracy: 0.8578\n",
            "Epoch 103/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2920 - accuracy: 0.8742 - val_loss: 0.3331 - val_accuracy: 0.8597\n",
            "Epoch 104/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2921 - accuracy: 0.8741 - val_loss: 0.3311 - val_accuracy: 0.8591\n",
            "Epoch 105/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2923 - accuracy: 0.8747 - val_loss: 0.3356 - val_accuracy: 0.8587\n",
            "Epoch 106/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2917 - accuracy: 0.8751 - val_loss: 0.3340 - val_accuracy: 0.8595\n",
            "Epoch 107/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.2917 - accuracy: 0.8746 - val_loss: 0.3333 - val_accuracy: 0.8584\n",
            "Epoch 108/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2912 - accuracy: 0.8747 - val_loss: 0.3289 - val_accuracy: 0.8600\n",
            "Epoch 109/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2914 - accuracy: 0.8752 - val_loss: 0.3316 - val_accuracy: 0.8584\n",
            "Epoch 110/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2914 - accuracy: 0.8752 - val_loss: 0.3358 - val_accuracy: 0.8586\n",
            "Epoch 111/150\n",
            "12794/12794 [==============================] - 38s 3ms/step - loss: 0.2909 - accuracy: 0.8749 - val_loss: 0.3363 - val_accuracy: 0.8592\n",
            "Epoch 112/150\n",
            "12794/12794 [==============================] - 38s 3ms/step - loss: 0.2903 - accuracy: 0.8754 - val_loss: 0.3332 - val_accuracy: 0.8604\n",
            "Epoch 113/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2913 - accuracy: 0.8746 - val_loss: 0.3332 - val_accuracy: 0.8584\n",
            "Epoch 114/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2910 - accuracy: 0.8751 - val_loss: 0.3335 - val_accuracy: 0.8582\n",
            "Epoch 115/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2912 - accuracy: 0.8751 - val_loss: 0.3307 - val_accuracy: 0.8597\n",
            "Epoch 116/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2909 - accuracy: 0.8752 - val_loss: 0.3302 - val_accuracy: 0.8593\n",
            "Epoch 117/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2902 - accuracy: 0.8755 - val_loss: 0.3334 - val_accuracy: 0.8589\n",
            "Epoch 118/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2907 - accuracy: 0.8751 - val_loss: 0.3313 - val_accuracy: 0.8594\n",
            "Epoch 119/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2903 - accuracy: 0.8754 - val_loss: 0.3276 - val_accuracy: 0.8609\n",
            "Epoch 120/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2896 - accuracy: 0.8756 - val_loss: 0.3304 - val_accuracy: 0.8600\n",
            "Epoch 121/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2908 - accuracy: 0.8755 - val_loss: 0.3377 - val_accuracy: 0.8582\n",
            "Epoch 122/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2896 - accuracy: 0.8758 - val_loss: 0.3310 - val_accuracy: 0.8599\n",
            "Epoch 123/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2890 - accuracy: 0.8758 - val_loss: 0.3325 - val_accuracy: 0.8602\n",
            "Epoch 124/150\n",
            "12794/12794 [==============================] - 38s 3ms/step - loss: 0.2895 - accuracy: 0.8758 - val_loss: 0.3312 - val_accuracy: 0.8577\n",
            "Epoch 125/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2893 - accuracy: 0.8761 - val_loss: 0.3305 - val_accuracy: 0.8596\n",
            "Epoch 126/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.2885 - accuracy: 0.8761 - val_loss: 0.3260 - val_accuracy: 0.8631\n",
            "Epoch 127/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2886 - accuracy: 0.8761 - val_loss: 0.3362 - val_accuracy: 0.8592\n",
            "Epoch 128/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2894 - accuracy: 0.8758 - val_loss: 0.3342 - val_accuracy: 0.8595\n",
            "Epoch 129/150\n",
            "12794/12794 [==============================] - 40s 3ms/step - loss: 0.2885 - accuracy: 0.8763 - val_loss: 0.3329 - val_accuracy: 0.8591\n",
            "Epoch 130/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2882 - accuracy: 0.8767 - val_loss: 0.3318 - val_accuracy: 0.8615\n",
            "Epoch 131/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2882 - accuracy: 0.8762 - val_loss: 0.3324 - val_accuracy: 0.8594\n",
            "Epoch 132/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2885 - accuracy: 0.8766 - val_loss: 0.3289 - val_accuracy: 0.8607\n",
            "Epoch 133/150\n",
            "12794/12794 [==============================] - 42s 3ms/step - loss: 0.2883 - accuracy: 0.8769 - val_loss: 0.3283 - val_accuracy: 0.8615\n",
            "Epoch 134/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2889 - accuracy: 0.8763 - val_loss: 0.3326 - val_accuracy: 0.8603\n",
            "Epoch 135/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2886 - accuracy: 0.8765 - val_loss: 0.3286 - val_accuracy: 0.8607\n",
            "Epoch 136/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2884 - accuracy: 0.8768 - val_loss: 0.3289 - val_accuracy: 0.8614\n",
            "Epoch 137/150\n",
            "12794/12794 [==============================] - 37s 3ms/step - loss: 0.2880 - accuracy: 0.8767 - val_loss: 0.3316 - val_accuracy: 0.8597\n",
            "Epoch 138/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2879 - accuracy: 0.8773 - val_loss: 0.3319 - val_accuracy: 0.8607\n",
            "Epoch 139/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2882 - accuracy: 0.8763 - val_loss: 0.3281 - val_accuracy: 0.8617\n",
            "Epoch 140/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2881 - accuracy: 0.8767 - val_loss: 0.3262 - val_accuracy: 0.8636\n",
            "Epoch 141/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2876 - accuracy: 0.8771 - val_loss: 0.3274 - val_accuracy: 0.8622\n",
            "Epoch 142/150\n",
            "12794/12794 [==============================] - 39s 3ms/step - loss: 0.2881 - accuracy: 0.8765 - val_loss: 0.3282 - val_accuracy: 0.8609\n",
            "Epoch 143/150\n",
            "12794/12794 [==============================] - 38s 3ms/step - loss: 0.2871 - accuracy: 0.8771 - val_loss: 0.3272 - val_accuracy: 0.8619\n",
            "Epoch 144/150\n",
            "12794/12794 [==============================] - 38s 3ms/step - loss: 0.2868 - accuracy: 0.8769 - val_loss: 0.3290 - val_accuracy: 0.8625\n",
            "Epoch 145/150\n",
            "12794/12794 [==============================] - 42s 3ms/step - loss: 0.2875 - accuracy: 0.8767 - val_loss: 0.3285 - val_accuracy: 0.8622\n",
            "Epoch 146/150\n",
            "12794/12794 [==============================] - 41s 3ms/step - loss: 0.2884 - accuracy: 0.8768 - val_loss: 0.3295 - val_accuracy: 0.8600\n",
            "Epoch 147/150\n",
            "12794/12794 [==============================] - 42s 3ms/step - loss: 0.2877 - accuracy: 0.8767 - val_loss: 0.3385 - val_accuracy: 0.8587\n",
            "Epoch 148/150\n",
            "12794/12794 [==============================] - 42s 3ms/step - loss: 0.2872 - accuracy: 0.8771 - val_loss: 0.3268 - val_accuracy: 0.8618\n",
            "Epoch 149/150\n",
            "12794/12794 [==============================] - 38s 3ms/step - loss: 0.2867 - accuracy: 0.8776 - val_loss: 0.3303 - val_accuracy: 0.8604\n",
            "Epoch 150/150\n",
            "12794/12794 [==============================] - 42s 3ms/step - loss: 0.2865 - accuracy: 0.8778 - val_loss: 0.3282 - val_accuracy: 0.8599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predNN = modelNN.predict(x_test2)\n"
      ],
      "metadata": {
        "id": "cK7j9gB6g_zC"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predNN"
      ],
      "metadata": {
        "id": "vpdYwFhL5zU7",
        "outputId": "6ebde254-a8fa-4f24-b092-ca64ad8c4872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0             1\n",
              "0       0.502496  4.975041e-01\n",
              "1       0.704326  2.956743e-01\n",
              "2       0.372732  6.272685e-01\n",
              "3       0.999977  2.260396e-05\n",
              "4       0.015501  9.844993e-01\n",
              "...          ...           ...\n",
              "175449  1.000000  8.589006e-21\n",
              "175450  0.000582  9.994181e-01\n",
              "175451  0.346831  6.531695e-01\n",
              "175452  0.269543  7.304568e-01\n",
              "175453  0.083198  9.168019e-01\n",
              "\n",
              "[175454 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e6afce1-564b-4d37-9903-2b2d4dddb6db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.502496</td>\n",
              "      <td>4.975041e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.704326</td>\n",
              "      <td>2.956743e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.372732</td>\n",
              "      <td>6.272685e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.999977</td>\n",
              "      <td>2.260396e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.015501</td>\n",
              "      <td>9.844993e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175449</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.589006e-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175450</th>\n",
              "      <td>0.000582</td>\n",
              "      <td>9.994181e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175451</th>\n",
              "      <td>0.346831</td>\n",
              "      <td>6.531695e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175452</th>\n",
              "      <td>0.269543</td>\n",
              "      <td>7.304568e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175453</th>\n",
              "      <td>0.083198</td>\n",
              "      <td>9.168019e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>175454 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e6afce1-564b-4d37-9903-2b2d4dddb6db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e6afce1-564b-4d37-9903-2b2d4dddb6db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e6afce1-564b-4d37-9903-2b2d4dddb6db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: total number of rows (175454) exceeds max_rows (20000). Limiting to first (20000) rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predNN = pd.DataFrame(predNN)\n",
        "y_predNN = predNN.idxmax(axis=1)\n",
        "\n",
        "\n",
        "y_trueNN = np.asarray(y_test2)\n",
        "y_trueNN = pd.DataFrame(y_trueNN)\n",
        "y_trueNN= y_trueNN.idxmax(axis=1)"
      ],
      "metadata": {
        "id": "-EfG0lDbhesl"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NNScore = accuracy_score(y_trueNN,y_predNN)"
      ],
      "metadata": {
        "id": "RIMliakxoKRC"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(NNScore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYBAU1hxoNzQ",
        "outputId": "217a4262-21c7-4d22-86c6-b8e03eb4a6cc"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8598778027289204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('--------- Confusion matrix -> NN-----------')\n",
        "print(confusion_matrix(y_trueNN,y_predNN))\n",
        "print('--------- Classification Report matrix -> NN-----------')\n",
        "print(classification_report(y_trueNN,y_predNN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg_FIKMlhaBU",
        "outputId": "ea7dc90d-7ff1-4ce9-9e59-aabed628de95"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- Confusion matrix -> NN-----------\n",
            "[[67471 20336]\n",
            " [ 4249 83398]]\n",
            "--------- Classification Report matrix -> NN-----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.77      0.85     87807\n",
            "           1       0.80      0.95      0.87     87647\n",
            "\n",
            "    accuracy                           0.86    175454\n",
            "   macro avg       0.87      0.86      0.86    175454\n",
            "weighted avg       0.87      0.86      0.86    175454\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25, 10), dpi=60)\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('Accuracy')\n",
        "plt.plot(history.history[\"accuracy\"], label=\"Train_acc\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"Validate_acc\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label=\"Train_loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Validate_loss\")"
      ],
      "metadata": {
        "id": "_s68XchapUH8",
        "outputId": "6dc09fcc-714f-4600-a191-432f91f06756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5e8cda8a10>]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P7TOdWng0t9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NeuralNetwork Training "
      ],
      "metadata": {
        "id": "KbPho_t60t-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "metadata": {
        "id": "NGmBpj2X1N5A"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelNN1 = Sequential()\n",
        "modelNN1.add(Dense(128, input_dim=37, activation='relu'))\n",
        "modelNN1.add(Dense(128, activation='sigmoid'))\n",
        "modelNN1.add(Dense(128, activation='sigmoid'))\n",
        "modelNN1.add(Dropout(0.5))\n",
        "modelNN1.add(Dense(2, activation='softmax'))\n",
        "modelNN1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-3kEvBLa00R8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = modelNN1.fit(x_train1, y_train1, epochs=150, batch_size=32,verbose=1,validation_data=(x_test1,y_test1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPzNHQNg4qTy",
        "outputId": "7fa3aa9d-8990-4dc9-de95-5e10140f1db4"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2195 - accuracy: 0.9171 - val_loss: 0.2295 - val_accuracy: 0.9171\n",
            "Epoch 2/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2184 - accuracy: 0.9174 - val_loss: 0.2310 - val_accuracy: 0.9153\n",
            "Epoch 3/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2174 - accuracy: 0.9174 - val_loss: 0.2391 - val_accuracy: 0.9158\n",
            "Epoch 4/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2166 - accuracy: 0.9180 - val_loss: 0.2341 - val_accuracy: 0.9163\n",
            "Epoch 5/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2156 - accuracy: 0.9181 - val_loss: 0.2322 - val_accuracy: 0.9156\n",
            "Epoch 6/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2148 - accuracy: 0.9184 - val_loss: 0.2358 - val_accuracy: 0.9151\n",
            "Epoch 7/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2134 - accuracy: 0.9189 - val_loss: 0.2401 - val_accuracy: 0.9159\n",
            "Epoch 8/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2126 - accuracy: 0.9192 - val_loss: 0.2429 - val_accuracy: 0.9128\n",
            "Epoch 9/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2117 - accuracy: 0.9196 - val_loss: 0.2393 - val_accuracy: 0.9139\n",
            "Epoch 10/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2107 - accuracy: 0.9200 - val_loss: 0.2482 - val_accuracy: 0.9118\n",
            "Epoch 11/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2097 - accuracy: 0.9205 - val_loss: 0.2471 - val_accuracy: 0.9153\n",
            "Epoch 12/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2088 - accuracy: 0.9205 - val_loss: 0.2529 - val_accuracy: 0.9135\n",
            "Epoch 13/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2079 - accuracy: 0.9210 - val_loss: 0.2479 - val_accuracy: 0.9141\n",
            "Epoch 14/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2074 - accuracy: 0.9213 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
            "Epoch 15/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2063 - accuracy: 0.9213 - val_loss: 0.2585 - val_accuracy: 0.9141\n",
            "Epoch 16/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2056 - accuracy: 0.9220 - val_loss: 0.2554 - val_accuracy: 0.9144\n",
            "Epoch 17/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2049 - accuracy: 0.9226 - val_loss: 0.2532 - val_accuracy: 0.9141\n",
            "Epoch 18/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2043 - accuracy: 0.9226 - val_loss: 0.2542 - val_accuracy: 0.9134\n",
            "Epoch 19/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2031 - accuracy: 0.9230 - val_loss: 0.2601 - val_accuracy: 0.9107\n",
            "Epoch 20/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2026 - accuracy: 0.9235 - val_loss: 0.2614 - val_accuracy: 0.9139\n",
            "Epoch 21/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2020 - accuracy: 0.9234 - val_loss: 0.2571 - val_accuracy: 0.9136\n",
            "Epoch 22/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2013 - accuracy: 0.9239 - val_loss: 0.2592 - val_accuracy: 0.9141\n",
            "Epoch 23/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2005 - accuracy: 0.9244 - val_loss: 0.2654 - val_accuracy: 0.9126\n",
            "Epoch 24/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2004 - accuracy: 0.9243 - val_loss: 0.2695 - val_accuracy: 0.9120\n",
            "Epoch 25/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1997 - accuracy: 0.9246 - val_loss: 0.2758 - val_accuracy: 0.9143\n",
            "Epoch 26/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1995 - accuracy: 0.9244 - val_loss: 0.2720 - val_accuracy: 0.9137\n",
            "Epoch 27/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1989 - accuracy: 0.9250 - val_loss: 0.2713 - val_accuracy: 0.9140\n",
            "Epoch 28/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1988 - accuracy: 0.9251 - val_loss: 0.2689 - val_accuracy: 0.9130\n",
            "Epoch 29/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1980 - accuracy: 0.9253 - val_loss: 0.2755 - val_accuracy: 0.9138\n",
            "Epoch 30/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1978 - accuracy: 0.9254 - val_loss: 0.2798 - val_accuracy: 0.9133\n",
            "Epoch 31/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1973 - accuracy: 0.9254 - val_loss: 0.2814 - val_accuracy: 0.9123\n",
            "Epoch 32/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1966 - accuracy: 0.9259 - val_loss: 0.2860 - val_accuracy: 0.9102\n",
            "Epoch 33/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1965 - accuracy: 0.9259 - val_loss: 0.2745 - val_accuracy: 0.9113\n",
            "Epoch 34/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1962 - accuracy: 0.9260 - val_loss: 0.2741 - val_accuracy: 0.9112\n",
            "Epoch 35/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1961 - accuracy: 0.9262 - val_loss: 0.2760 - val_accuracy: 0.9135\n",
            "Epoch 36/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1955 - accuracy: 0.9264 - val_loss: 0.2821 - val_accuracy: 0.9101\n",
            "Epoch 37/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1949 - accuracy: 0.9267 - val_loss: 0.2740 - val_accuracy: 0.9125\n",
            "Epoch 38/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1945 - accuracy: 0.9271 - val_loss: 0.2831 - val_accuracy: 0.9120\n",
            "Epoch 39/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1945 - accuracy: 0.9271 - val_loss: 0.2795 - val_accuracy: 0.9109\n",
            "Epoch 40/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1943 - accuracy: 0.9270 - val_loss: 0.2827 - val_accuracy: 0.9130\n",
            "Epoch 41/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1935 - accuracy: 0.9274 - val_loss: 0.3047 - val_accuracy: 0.9089\n",
            "Epoch 42/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1937 - accuracy: 0.9271 - val_loss: 0.2855 - val_accuracy: 0.9118\n",
            "Epoch 43/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1934 - accuracy: 0.9273 - val_loss: 0.2853 - val_accuracy: 0.9097\n",
            "Epoch 44/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1935 - accuracy: 0.9274 - val_loss: 0.2726 - val_accuracy: 0.9121\n",
            "Epoch 45/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1935 - accuracy: 0.9276 - val_loss: 0.2808 - val_accuracy: 0.9122\n",
            "Epoch 46/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1931 - accuracy: 0.9277 - val_loss: 0.2898 - val_accuracy: 0.9109\n",
            "Epoch 47/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1936 - accuracy: 0.9277 - val_loss: 0.2897 - val_accuracy: 0.9106\n",
            "Epoch 48/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1933 - accuracy: 0.9274 - val_loss: 0.2758 - val_accuracy: 0.9121\n",
            "Epoch 49/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1926 - accuracy: 0.9278 - val_loss: 0.2788 - val_accuracy: 0.9105\n",
            "Epoch 50/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1927 - accuracy: 0.9278 - val_loss: 0.2770 - val_accuracy: 0.9115\n",
            "Epoch 51/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1923 - accuracy: 0.9280 - val_loss: 0.2806 - val_accuracy: 0.9121\n",
            "Epoch 52/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1922 - accuracy: 0.9281 - val_loss: 0.2819 - val_accuracy: 0.9105\n",
            "Epoch 53/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1926 - accuracy: 0.9281 - val_loss: 0.2919 - val_accuracy: 0.9100\n",
            "Epoch 54/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1923 - accuracy: 0.9284 - val_loss: 0.2967 - val_accuracy: 0.9115\n",
            "Epoch 55/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1922 - accuracy: 0.9278 - val_loss: 0.2951 - val_accuracy: 0.9116\n",
            "Epoch 56/150\n",
            "6996/6996 [==============================] - 24s 3ms/step - loss: 0.1925 - accuracy: 0.9282 - val_loss: 0.2876 - val_accuracy: 0.9099\n",
            "Epoch 57/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1918 - accuracy: 0.9283 - val_loss: 0.2966 - val_accuracy: 0.9110\n",
            "Epoch 58/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1925 - accuracy: 0.9281 - val_loss: 0.2812 - val_accuracy: 0.9116\n",
            "Epoch 59/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1919 - accuracy: 0.9282 - val_loss: 0.2911 - val_accuracy: 0.9120\n",
            "Epoch 60/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1924 - accuracy: 0.9278 - val_loss: 0.2797 - val_accuracy: 0.9095\n",
            "Epoch 61/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1918 - accuracy: 0.9284 - val_loss: 0.2833 - val_accuracy: 0.9117\n",
            "Epoch 62/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1921 - accuracy: 0.9281 - val_loss: 0.2785 - val_accuracy: 0.9122\n",
            "Epoch 63/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1922 - accuracy: 0.9280 - val_loss: 0.2831 - val_accuracy: 0.9097\n",
            "Epoch 64/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1920 - accuracy: 0.9285 - val_loss: 0.2816 - val_accuracy: 0.9106\n",
            "Epoch 65/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1918 - accuracy: 0.9284 - val_loss: 0.2805 - val_accuracy: 0.9113\n",
            "Epoch 66/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1926 - accuracy: 0.9285 - val_loss: 0.2753 - val_accuracy: 0.9115\n",
            "Epoch 67/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1910 - accuracy: 0.9288 - val_loss: 0.2869 - val_accuracy: 0.9090\n",
            "Epoch 68/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1922 - accuracy: 0.9282 - val_loss: 0.2724 - val_accuracy: 0.9119\n",
            "Epoch 69/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1920 - accuracy: 0.9287 - val_loss: 0.2824 - val_accuracy: 0.9123\n",
            "Epoch 70/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1924 - accuracy: 0.9283 - val_loss: 0.2728 - val_accuracy: 0.9119\n",
            "Epoch 71/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1926 - accuracy: 0.9285 - val_loss: 0.2785 - val_accuracy: 0.9113\n",
            "Epoch 72/150\n",
            "6996/6996 [==============================] - 24s 3ms/step - loss: 0.1929 - accuracy: 0.9286 - val_loss: 0.2829 - val_accuracy: 0.9100\n",
            "Epoch 73/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1926 - accuracy: 0.9285 - val_loss: 0.2723 - val_accuracy: 0.9126\n",
            "Epoch 74/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1919 - accuracy: 0.9289 - val_loss: 0.2872 - val_accuracy: 0.9093\n",
            "Epoch 75/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1927 - accuracy: 0.9287 - val_loss: 0.2705 - val_accuracy: 0.9126\n",
            "Epoch 76/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1933 - accuracy: 0.9284 - val_loss: 0.2739 - val_accuracy: 0.9129\n",
            "Epoch 77/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1926 - accuracy: 0.9282 - val_loss: 0.2771 - val_accuracy: 0.9106\n",
            "Epoch 78/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1924 - accuracy: 0.9284 - val_loss: 0.2757 - val_accuracy: 0.9118\n",
            "Epoch 79/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1926 - accuracy: 0.9285 - val_loss: 0.2760 - val_accuracy: 0.9116\n",
            "Epoch 80/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1932 - accuracy: 0.9282 - val_loss: 0.2738 - val_accuracy: 0.9105\n",
            "Epoch 81/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1932 - accuracy: 0.9284 - val_loss: 0.2807 - val_accuracy: 0.9105\n",
            "Epoch 82/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1937 - accuracy: 0.9281 - val_loss: 0.2873 - val_accuracy: 0.9092\n",
            "Epoch 83/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1927 - accuracy: 0.9285 - val_loss: 0.2749 - val_accuracy: 0.9109\n",
            "Epoch 84/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1927 - accuracy: 0.9289 - val_loss: 0.2700 - val_accuracy: 0.9112\n",
            "Epoch 85/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1936 - accuracy: 0.9288 - val_loss: 0.2710 - val_accuracy: 0.9102\n",
            "Epoch 86/150\n",
            "6996/6996 [==============================] - 24s 3ms/step - loss: 0.1940 - accuracy: 0.9282 - val_loss: 0.2800 - val_accuracy: 0.9098\n",
            "Epoch 87/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1935 - accuracy: 0.9287 - val_loss: 0.2774 - val_accuracy: 0.9091\n",
            "Epoch 88/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1938 - accuracy: 0.9282 - val_loss: 0.2688 - val_accuracy: 0.9105\n",
            "Epoch 89/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1940 - accuracy: 0.9285 - val_loss: 0.2793 - val_accuracy: 0.9107\n",
            "Epoch 90/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1940 - accuracy: 0.9284 - val_loss: 0.2697 - val_accuracy: 0.9106\n",
            "Epoch 91/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1945 - accuracy: 0.9278 - val_loss: 0.2835 - val_accuracy: 0.9088\n",
            "Epoch 92/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1949 - accuracy: 0.9283 - val_loss: 0.2788 - val_accuracy: 0.9110\n",
            "Epoch 93/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1942 - accuracy: 0.9282 - val_loss: 0.2711 - val_accuracy: 0.9107\n",
            "Epoch 94/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1945 - accuracy: 0.9284 - val_loss: 0.2701 - val_accuracy: 0.9105\n",
            "Epoch 95/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1950 - accuracy: 0.9280 - val_loss: 0.2653 - val_accuracy: 0.9113\n",
            "Epoch 96/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1953 - accuracy: 0.9284 - val_loss: 0.2727 - val_accuracy: 0.9112\n",
            "Epoch 97/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1956 - accuracy: 0.9280 - val_loss: 0.2709 - val_accuracy: 0.9115\n",
            "Epoch 98/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1959 - accuracy: 0.9279 - val_loss: 0.2687 - val_accuracy: 0.9094\n",
            "Epoch 99/150\n",
            "6996/6996 [==============================] - 24s 3ms/step - loss: 0.1965 - accuracy: 0.9277 - val_loss: 0.2662 - val_accuracy: 0.9110\n",
            "Epoch 100/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1966 - accuracy: 0.9278 - val_loss: 0.2599 - val_accuracy: 0.9125\n",
            "Epoch 101/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1970 - accuracy: 0.9280 - val_loss: 0.2628 - val_accuracy: 0.9111\n",
            "Epoch 102/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1965 - accuracy: 0.9279 - val_loss: 0.2696 - val_accuracy: 0.9104\n",
            "Epoch 103/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1966 - accuracy: 0.9278 - val_loss: 0.2732 - val_accuracy: 0.9088\n",
            "Epoch 104/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1967 - accuracy: 0.9277 - val_loss: 0.2706 - val_accuracy: 0.9089\n",
            "Epoch 105/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.1973 - accuracy: 0.9279 - val_loss: 0.2676 - val_accuracy: 0.9097\n",
            "Epoch 106/150\n",
            "6996/6996 [==============================] - 24s 3ms/step - loss: 0.1977 - accuracy: 0.9274 - val_loss: 0.2709 - val_accuracy: 0.9092\n",
            "Epoch 107/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1980 - accuracy: 0.9275 - val_loss: 0.2727 - val_accuracy: 0.9112\n",
            "Epoch 108/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1980 - accuracy: 0.9276 - val_loss: 0.2684 - val_accuracy: 0.9105\n",
            "Epoch 109/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1983 - accuracy: 0.9273 - val_loss: 0.2694 - val_accuracy: 0.9114\n",
            "Epoch 110/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1982 - accuracy: 0.9274 - val_loss: 0.2633 - val_accuracy: 0.9110\n",
            "Epoch 111/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1985 - accuracy: 0.9271 - val_loss: 0.2665 - val_accuracy: 0.9115\n",
            "Epoch 112/150\n",
            "6996/6996 [==============================] - 28s 4ms/step - loss: 0.1981 - accuracy: 0.9272 - val_loss: 0.2692 - val_accuracy: 0.9098\n",
            "Epoch 113/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1990 - accuracy: 0.9273 - val_loss: 0.2588 - val_accuracy: 0.9113\n",
            "Epoch 114/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1987 - accuracy: 0.9275 - val_loss: 0.2634 - val_accuracy: 0.9132\n",
            "Epoch 115/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1999 - accuracy: 0.9268 - val_loss: 0.2592 - val_accuracy: 0.9107\n",
            "Epoch 116/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.1996 - accuracy: 0.9269 - val_loss: 0.2590 - val_accuracy: 0.9115\n",
            "Epoch 117/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.1999 - accuracy: 0.9268 - val_loss: 0.2586 - val_accuracy: 0.9103\n",
            "Epoch 118/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2007 - accuracy: 0.9266 - val_loss: 0.2599 - val_accuracy: 0.9132\n",
            "Epoch 119/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2006 - accuracy: 0.9268 - val_loss: 0.2633 - val_accuracy: 0.9095\n",
            "Epoch 120/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2006 - accuracy: 0.9269 - val_loss: 0.2614 - val_accuracy: 0.9115\n",
            "Epoch 121/150\n",
            "6996/6996 [==============================] - 26s 4ms/step - loss: 0.2012 - accuracy: 0.9264 - val_loss: 0.2587 - val_accuracy: 0.9114\n",
            "Epoch 122/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2005 - accuracy: 0.9265 - val_loss: 0.2558 - val_accuracy: 0.9116\n",
            "Epoch 123/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2008 - accuracy: 0.9265 - val_loss: 0.2586 - val_accuracy: 0.9112\n",
            "Epoch 124/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2016 - accuracy: 0.9263 - val_loss: 0.2620 - val_accuracy: 0.9117\n",
            "Epoch 125/150\n",
            "6996/6996 [==============================] - 24s 3ms/step - loss: 0.2021 - accuracy: 0.9263 - val_loss: 0.2584 - val_accuracy: 0.9102\n",
            "Epoch 126/150\n",
            "6996/6996 [==============================] - 24s 3ms/step - loss: 0.2020 - accuracy: 0.9262 - val_loss: 0.2581 - val_accuracy: 0.9112\n",
            "Epoch 127/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2029 - accuracy: 0.9262 - val_loss: 0.2565 - val_accuracy: 0.9100\n",
            "Epoch 128/150\n",
            "6996/6996 [==============================] - 24s 3ms/step - loss: 0.2027 - accuracy: 0.9260 - val_loss: 0.2554 - val_accuracy: 0.9107\n",
            "Epoch 129/150\n",
            "6996/6996 [==============================] - 24s 3ms/step - loss: 0.2028 - accuracy: 0.9261 - val_loss: 0.2554 - val_accuracy: 0.9111\n",
            "Epoch 130/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2028 - accuracy: 0.9260 - val_loss: 0.2511 - val_accuracy: 0.9128\n",
            "Epoch 131/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2042 - accuracy: 0.9255 - val_loss: 0.2551 - val_accuracy: 0.9107\n",
            "Epoch 132/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2037 - accuracy: 0.9260 - val_loss: 0.2547 - val_accuracy: 0.9118\n",
            "Epoch 133/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2039 - accuracy: 0.9254 - val_loss: 0.2592 - val_accuracy: 0.9094\n",
            "Epoch 134/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2037 - accuracy: 0.9259 - val_loss: 0.2499 - val_accuracy: 0.9120\n",
            "Epoch 135/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2042 - accuracy: 0.9258 - val_loss: 0.2518 - val_accuracy: 0.9115\n",
            "Epoch 136/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2035 - accuracy: 0.9257 - val_loss: 0.2530 - val_accuracy: 0.9120\n",
            "Epoch 137/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2043 - accuracy: 0.9254 - val_loss: 0.2552 - val_accuracy: 0.9122\n",
            "Epoch 138/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2047 - accuracy: 0.9254 - val_loss: 0.2584 - val_accuracy: 0.9103\n",
            "Epoch 139/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2056 - accuracy: 0.9254 - val_loss: 0.2523 - val_accuracy: 0.9095\n",
            "Epoch 140/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2061 - accuracy: 0.9249 - val_loss: 0.2494 - val_accuracy: 0.9116\n",
            "Epoch 141/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2056 - accuracy: 0.9250 - val_loss: 0.2497 - val_accuracy: 0.9119\n",
            "Epoch 142/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2059 - accuracy: 0.9252 - val_loss: 0.2532 - val_accuracy: 0.9100\n",
            "Epoch 143/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2048 - accuracy: 0.9256 - val_loss: 0.2566 - val_accuracy: 0.9125\n",
            "Epoch 144/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2053 - accuracy: 0.9251 - val_loss: 0.2493 - val_accuracy: 0.9123\n",
            "Epoch 145/150\n",
            "6996/6996 [==============================] - 22s 3ms/step - loss: 0.2063 - accuracy: 0.9246 - val_loss: 0.2499 - val_accuracy: 0.9133\n",
            "Epoch 146/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2058 - accuracy: 0.9251 - val_loss: 0.2545 - val_accuracy: 0.9110\n",
            "Epoch 147/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2070 - accuracy: 0.9246 - val_loss: 0.2503 - val_accuracy: 0.9106\n",
            "Epoch 148/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2076 - accuracy: 0.9241 - val_loss: 0.2534 - val_accuracy: 0.9121\n",
            "Epoch 149/150\n",
            "6996/6996 [==============================] - 23s 3ms/step - loss: 0.2072 - accuracy: 0.9241 - val_loss: 0.2524 - val_accuracy: 0.9119\n",
            "Epoch 150/150\n",
            "6996/6996 [==============================] - 21s 3ms/step - loss: 0.2075 - accuracy: 0.9245 - val_loss: 0.2465 - val_accuracy: 0.9130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predNN1 = modelNN1.predict(x_test1)"
      ],
      "metadata": {
        "id": "YqYEuXvr5ZNC"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predNN1 = pd.DataFrame(predNN1)\n",
        "y_predNN1 = predNN1.idxmax(axis=1)\n",
        "\n",
        "\n",
        "y_trueNN1 = np.asarray(y_test1)\n",
        "y_trueNN1 = pd.DataFrame(y_trueNN1)\n",
        "y_trueNN1 = y_trueNN1.idxmax(axis=1)"
      ],
      "metadata": {
        "id": "cJZ4lZhK5oEk"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NNScore1 = accuracy_score(y_trueNN1,y_predNN1)"
      ],
      "metadata": {
        "id": "3o8AUkQl5ynB"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(NNScore1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwWjQivp517d",
        "outputId": "05329168-90ee-4a3a-85f4-12419b2a6c52"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9129863767602331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('--------- Confusion matrix -> NN-----------')\n",
        "print(confusion_matrix(y_trueNN1,y_predNN1))\n",
        "print('--------- Classification Report matrix -> NN-----------')\n",
        "print(classification_report(y_trueNN1,y_predNN1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWfRjcVk55W7",
        "outputId": "56bd15d8-9a8a-45b1-fd12-9532574436be"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------- Confusion matrix -> NN-----------\n",
            "[[86803  1050]\n",
            " [ 7298   788]]\n",
            "--------- Classification Report matrix -> NN-----------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.99      0.95     87853\n",
            "           1       0.43      0.10      0.16      8086\n",
            "\n",
            "    accuracy                           0.91     95939\n",
            "   macro avg       0.68      0.54      0.56     95939\n",
            "weighted avg       0.88      0.91      0.89     95939\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25, 10), dpi=60)\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('Accuracy')\n",
        "plt.plot(history1.history[\"accuracy\"], label=\"Train_acc\")\n",
        "plt.plot(history1.history[\"val_accuracy\"], label=\"Validate_acc\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('Loss')\n",
        "plt.plot(history1.history['loss'], label=\"Train_loss\")\n",
        "plt.plot(history1.history['val_loss'], label=\"Validate_loss\")"
      ],
      "metadata": {
        "id": "1h5RITI84gxW",
        "outputId": "31dc63ca-ff2c-4ef6-b873-6f0fb9617434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5e8cc88810>]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gridsearch for KNN"
      ],
      "metadata": {
        "id": "UA6glnEA6OWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import  GridSearchCV\n",
        "import os"
      ],
      "metadata": {
        "id": "j051F-YH7Hsj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define KNN parameter**"
      ],
      "metadata": {
        "id": "3mnZp9Ib6xDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K_list = [3,5,15,25,35,45,55]\n",
        "KNN_params = dict(n_neighbors=K_list)\n",
        "n_cpu = os.cpu_count()"
      ],
      "metadata": {
        "id": "kkgkJWMb6mV9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**split dataset for gridsearch**"
      ],
      "metadata": {
        "id": "nvbdG8m_DsXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_gs,x_test_gs,y_train_gs,y_test_gs = train_test_split(x_train2,y_train2,test_size=0.5,random_state=23)"
      ],
      "metadata": {
        "id": "FfdiaEHaDrKy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train_gs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGRA1ieDFb67",
        "outputId": "790041ca-173f-40ad-c6ea-f7bcd23b4259"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "204695"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid = GridSearchCV( estimator=KNeighborsClassifier(p=2),\n",
        "                              n_jobs=n_cpu-1,\n",
        "                              verbose=10,\n",
        "                              scoring='accuracy',\n",
        "                              cv=2,\n",
        "                              param_grid=KNN_params)"
      ],
      "metadata": {
        "id": "y3GIMNVN6mqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result = grid.fit(x_train_gs,y_train_gs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lVjuKKG7ano",
        "outputId": "5d307977-f1ec-4c34-c417-ff52a45f032e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 7 candidates, totalling 14 fits\n",
            "[CV 1/2; 1/7] START n_neighbors=3...............................................\n",
            "[CV 1/2; 1/7] END ................n_neighbors=3;, score=0.800 total time= 2.5min\n",
            "[CV 2/2; 1/7] START n_neighbors=3...............................................\n",
            "[CV 2/2; 1/7] END ................n_neighbors=3;, score=0.798 total time= 2.5min\n",
            "[CV 1/2; 2/7] START n_neighbors=5...............................................\n",
            "[CV 1/2; 2/7] END ................n_neighbors=5;, score=0.780 total time= 3.1min\n",
            "[CV 2/2; 2/7] START n_neighbors=5...............................................\n",
            "[CV 2/2; 2/7] END ................n_neighbors=5;, score=0.778 total time= 3.0min\n",
            "[CV 1/2; 3/7] START n_neighbors=15..............................................\n",
            "[CV 1/2; 3/7] END ...............n_neighbors=15;, score=0.768 total time= 3.1min\n",
            "[CV 2/2; 3/7] START n_neighbors=15..............................................\n",
            "[CV 2/2; 3/7] END ...............n_neighbors=15;, score=0.765 total time= 2.9min\n",
            "[CV 1/2; 4/7] START n_neighbors=25..............................................\n",
            "[CV 1/2; 4/7] END ...............n_neighbors=25;, score=0.766 total time= 3.1min\n",
            "[CV 2/2; 4/7] START n_neighbors=25..............................................\n",
            "[CV 2/2; 4/7] END ...............n_neighbors=25;, score=0.764 total time= 3.0min\n",
            "[CV 1/2; 5/7] START n_neighbors=35..............................................\n",
            "[CV 1/2; 5/7] END ...............n_neighbors=35;, score=0.765 total time= 3.1min\n",
            "[CV 2/2; 5/7] START n_neighbors=35..............................................\n",
            "[CV 2/2; 5/7] END ...............n_neighbors=35;, score=0.764 total time= 3.0min\n",
            "[CV 1/2; 6/7] START n_neighbors=45..............................................\n",
            "[CV 1/2; 6/7] END ...............n_neighbors=45;, score=0.762 total time= 3.1min\n",
            "[CV 2/2; 6/7] START n_neighbors=45..............................................\n",
            "[CV 2/2; 6/7] END ...............n_neighbors=45;, score=0.763 total time= 3.0min\n",
            "[CV 1/2; 7/7] START n_neighbors=55..............................................\n",
            "[CV 1/2; 7/7] END ...............n_neighbors=55;, score=0.763 total time= 3.1min\n",
            "[CV 2/2; 7/7] START n_neighbors=55..............................................\n",
            "[CV 2/2; 7/7] END ...............n_neighbors=55;, score=0.762 total time= 3.0min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid_result.best_params_)\n",
        "print(grid_result.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVMWUrVGDd8z",
        "outputId": "5e4845cd-3d2d-40b7-f1be-79aa06b19c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_neighbors': 3}\n",
            "0.7989691913878165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result2 = grid.fit(x_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPPIfs7tX2Pw",
        "outputId": "16c45a84-05c0-4b88-c0ab-4d47ba644255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 7 candidates, totalling 14 fits\n",
            "[CV 1/2; 1/7] START n_neighbors=3...............................................\n",
            "[CV 1/2; 1/7] END ................n_neighbors=3;, score=0.720 total time=   9.6s\n",
            "[CV 2/2; 1/7] START n_neighbors=3...............................................\n",
            "[CV 2/2; 1/7] END ................n_neighbors=3;, score=0.719 total time=   6.5s\n",
            "[CV 1/2; 2/7] START n_neighbors=5...............................................\n",
            "[CV 1/2; 2/7] END ................n_neighbors=5;, score=0.736 total time=   8.8s\n",
            "[CV 2/2; 2/7] START n_neighbors=5...............................................\n",
            "[CV 2/2; 2/7] END ................n_neighbors=5;, score=0.732 total time=   7.1s\n",
            "[CV 1/2; 3/7] START n_neighbors=15..............................................\n",
            "[CV 1/2; 3/7] END ...............n_neighbors=15;, score=0.752 total time=   8.9s\n",
            "[CV 2/2; 3/7] START n_neighbors=15..............................................\n",
            "[CV 2/2; 3/7] END ...............n_neighbors=15;, score=0.747 total time=   7.1s\n",
            "[CV 1/2; 4/7] START n_neighbors=25..............................................\n",
            "[CV 1/2; 4/7] END ...............n_neighbors=25;, score=0.756 total time=   8.9s\n",
            "[CV 2/2; 4/7] START n_neighbors=25..............................................\n",
            "[CV 2/2; 4/7] END ...............n_neighbors=25;, score=0.753 total time=   7.1s\n",
            "[CV 1/2; 5/7] START n_neighbors=35..............................................\n",
            "[CV 1/2; 5/7] END ...............n_neighbors=35;, score=0.758 total time=   8.9s\n",
            "[CV 2/2; 5/7] START n_neighbors=35..............................................\n",
            "[CV 2/2; 5/7] END ...............n_neighbors=35;, score=0.753 total time=   7.1s\n",
            "[CV 1/2; 6/7] START n_neighbors=45..............................................\n",
            "[CV 1/2; 6/7] END ...............n_neighbors=45;, score=0.756 total time=   8.9s\n",
            "[CV 2/2; 6/7] START n_neighbors=45..............................................\n",
            "[CV 2/2; 6/7] END ...............n_neighbors=45;, score=0.753 total time=   7.6s\n",
            "[CV 1/2; 7/7] START n_neighbors=55..............................................\n",
            "[CV 1/2; 7/7] END ...............n_neighbors=55;, score=0.758 total time=   9.0s\n",
            "[CV 2/2; 7/7] START n_neighbors=55..............................................\n",
            "[CV 2/2; 7/7] END ...............n_neighbors=55;, score=0.753 total time=   7.2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid_result.best_params_)\n",
        "print(grid_result.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENvPU7lxX874",
        "outputId": "ad206f4b-c52f-47ec-f197-0afd985309f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_neighbors': 35}\n",
            "0.7555973070299045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gridsearch for KNN"
      ],
      "metadata": {
        "id": "1GkKKiQqZOhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "metadata": {
        "id": "4eoxXtOFZ1Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(optimizer='adam'):\n",
        "  modelNN = Sequential()\n",
        "  modelNN.add(Dense(128, input_dim=37, activation='relu'))\n",
        "  modelNN.add(Dense(128, activation='sigmoid'))\n",
        "  modelNN.add(Dense(128, activation='sigmoid'))\n",
        "  modelNN.add(Dropout(0.5))\n",
        "  modelNN.add(Dense(2, activation='softmax'))\n",
        "  modelNN.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  return modelNN"
      ],
      "metadata": {
        "id": "XRq2qIIaZR6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gs = KerasClassifier(build_fn=create_model,verbose=1)\n",
        "EPList = [50,100,150]\n",
        "BSList = [32,64,128]\n",
        "OPlist = ['Adam']\n",
        "param_grid = dict(optimizer=OPlist,epochs=EPList,batch_size=BSList)\n",
        "grid = GridSearchCV(estimator=model_gs, param_grid=param_grid,  cv=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOOzP6unZ3el",
        "outputId": "bbc907df-6449-41d5-de4b-4a0bc333019d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_resultNN = grid.fit(x_train_gs, y_train_gs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r45hIfayZ81U",
        "outputId": "ebce8c6e-c533-431f-de62-1a3e9902e619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.5064 - accuracy: 0.7574\n",
            "Epoch 2/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4916 - accuracy: 0.7671\n",
            "Epoch 3/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4887 - accuracy: 0.7680\n",
            "Epoch 4/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4867 - accuracy: 0.7700\n",
            "Epoch 5/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4838 - accuracy: 0.7706\n",
            "Epoch 6/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4814 - accuracy: 0.7707\n",
            "Epoch 7/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4792 - accuracy: 0.7730\n",
            "Epoch 8/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4761 - accuracy: 0.7734\n",
            "Epoch 9/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4735 - accuracy: 0.7745\n",
            "Epoch 10/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4696 - accuracy: 0.7762\n",
            "Epoch 11/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4659 - accuracy: 0.7769\n",
            "Epoch 12/50\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4621 - accuracy: 0.7788\n",
            "Epoch 13/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4571 - accuracy: 0.7806\n",
            "Epoch 14/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4527 - accuracy: 0.7823\n",
            "Epoch 15/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4473 - accuracy: 0.7852\n",
            "Epoch 16/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4419 - accuracy: 0.7873\n",
            "Epoch 17/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4366 - accuracy: 0.7908\n",
            "Epoch 18/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4306 - accuracy: 0.7932\n",
            "Epoch 19/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4252 - accuracy: 0.7961\n",
            "Epoch 20/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4190 - accuracy: 0.7991\n",
            "Epoch 21/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4132 - accuracy: 0.8030\n",
            "Epoch 22/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4075 - accuracy: 0.8049\n",
            "Epoch 23/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4018 - accuracy: 0.8078\n",
            "Epoch 24/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3965 - accuracy: 0.8093\n",
            "Epoch 25/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3911 - accuracy: 0.8129\n",
            "Epoch 26/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3865 - accuracy: 0.8150\n",
            "Epoch 27/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3815 - accuracy: 0.8179\n",
            "Epoch 28/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3758 - accuracy: 0.8203\n",
            "Epoch 29/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3720 - accuracy: 0.8224\n",
            "Epoch 30/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3666 - accuracy: 0.8249\n",
            "Epoch 31/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3625 - accuracy: 0.8263\n",
            "Epoch 32/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3580 - accuracy: 0.8290\n",
            "Epoch 33/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3548 - accuracy: 0.8295\n",
            "Epoch 34/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3514 - accuracy: 0.8323\n",
            "Epoch 35/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3473 - accuracy: 0.8335\n",
            "Epoch 36/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3446 - accuracy: 0.8349\n",
            "Epoch 37/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3408 - accuracy: 0.8365\n",
            "Epoch 38/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3387 - accuracy: 0.8384\n",
            "Epoch 39/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3341 - accuracy: 0.8405\n",
            "Epoch 40/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3314 - accuracy: 0.8403\n",
            "Epoch 41/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3291 - accuracy: 0.8419\n",
            "Epoch 42/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3261 - accuracy: 0.8440\n",
            "Epoch 43/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3239 - accuracy: 0.8436\n",
            "Epoch 44/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3225 - accuracy: 0.8456\n",
            "Epoch 45/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3187 - accuracy: 0.8468\n",
            "Epoch 46/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3172 - accuracy: 0.8481\n",
            "Epoch 47/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3142 - accuracy: 0.8489\n",
            "Epoch 48/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3112 - accuracy: 0.8494\n",
            "Epoch 49/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3102 - accuracy: 0.8507\n",
            "Epoch 50/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3083 - accuracy: 0.8517\n",
            "3199/3199 [==============================] - 4s 1ms/step - loss: 0.6314 - accuracy: 0.7995\n",
            "Epoch 1/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.5046 - accuracy: 0.7580\n",
            "Epoch 2/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4900 - accuracy: 0.7687\n",
            "Epoch 3/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4866 - accuracy: 0.7689\n",
            "Epoch 4/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4844 - accuracy: 0.7696\n",
            "Epoch 5/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4817 - accuracy: 0.7717\n",
            "Epoch 6/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4797 - accuracy: 0.7713\n",
            "Epoch 7/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4776 - accuracy: 0.7726\n",
            "Epoch 8/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4754 - accuracy: 0.7737\n",
            "Epoch 9/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4725 - accuracy: 0.7743\n",
            "Epoch 10/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4696 - accuracy: 0.7764\n",
            "Epoch 11/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4658 - accuracy: 0.7770\n",
            "Epoch 12/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4628 - accuracy: 0.7788\n",
            "Epoch 13/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4585 - accuracy: 0.7799\n",
            "Epoch 14/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4546 - accuracy: 0.7819\n",
            "Epoch 15/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4484 - accuracy: 0.7835\n",
            "Epoch 16/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4437 - accuracy: 0.7867\n",
            "Epoch 17/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4383 - accuracy: 0.7892\n",
            "Epoch 18/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4326 - accuracy: 0.7915\n",
            "Epoch 19/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4263 - accuracy: 0.7941\n",
            "Epoch 20/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4207 - accuracy: 0.7982\n",
            "Epoch 21/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4153 - accuracy: 0.8008\n",
            "Epoch 22/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4086 - accuracy: 0.8036\n",
            "Epoch 23/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4034 - accuracy: 0.8061\n",
            "Epoch 24/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3982 - accuracy: 0.8086\n",
            "Epoch 25/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3924 - accuracy: 0.8116\n",
            "Epoch 26/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3869 - accuracy: 0.8147\n",
            "Epoch 27/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3820 - accuracy: 0.8170\n",
            "Epoch 28/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3770 - accuracy: 0.8196\n",
            "Epoch 29/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3723 - accuracy: 0.8220\n",
            "Epoch 30/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3680 - accuracy: 0.8244\n",
            "Epoch 31/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3644 - accuracy: 0.8262\n",
            "Epoch 32/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3594 - accuracy: 0.8274\n",
            "Epoch 33/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3565 - accuracy: 0.8299\n",
            "Epoch 34/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3531 - accuracy: 0.8316\n",
            "Epoch 35/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3485 - accuracy: 0.8334\n",
            "Epoch 36/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3454 - accuracy: 0.8356\n",
            "Epoch 37/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3426 - accuracy: 0.8362\n",
            "Epoch 38/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3392 - accuracy: 0.8379\n",
            "Epoch 39/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3351 - accuracy: 0.8403\n",
            "Epoch 40/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3333 - accuracy: 0.8405\n",
            "Epoch 41/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3304 - accuracy: 0.8424\n",
            "Epoch 42/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3279 - accuracy: 0.8430\n",
            "Epoch 43/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3251 - accuracy: 0.8453\n",
            "Epoch 44/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3231 - accuracy: 0.8458\n",
            "Epoch 45/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3207 - accuracy: 0.8462\n",
            "Epoch 46/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3168 - accuracy: 0.8483\n",
            "Epoch 47/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3161 - accuracy: 0.8484\n",
            "Epoch 48/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3139 - accuracy: 0.8498\n",
            "Epoch 49/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3103 - accuracy: 0.8517\n",
            "Epoch 50/50\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3109 - accuracy: 0.8515\n",
            "3199/3199 [==============================] - 5s 1ms/step - loss: 0.6096 - accuracy: 0.7996\n",
            "Epoch 1/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.5063 - accuracy: 0.7579\n",
            "Epoch 2/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4911 - accuracy: 0.7670\n",
            "Epoch 3/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4877 - accuracy: 0.7687\n",
            "Epoch 4/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4859 - accuracy: 0.7702\n",
            "Epoch 5/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4843 - accuracy: 0.7707\n",
            "Epoch 6/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4815 - accuracy: 0.7717\n",
            "Epoch 7/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4793 - accuracy: 0.7724\n",
            "Epoch 8/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4770 - accuracy: 0.7725\n",
            "Epoch 9/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4745 - accuracy: 0.7741\n",
            "Epoch 10/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4712 - accuracy: 0.7752\n",
            "Epoch 11/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4681 - accuracy: 0.7772\n",
            "Epoch 12/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4637 - accuracy: 0.7782\n",
            "Epoch 13/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4599 - accuracy: 0.7811\n",
            "Epoch 14/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4542 - accuracy: 0.7820\n",
            "Epoch 15/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4496 - accuracy: 0.7849\n",
            "Epoch 16/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4441 - accuracy: 0.7873\n",
            "Epoch 17/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4387 - accuracy: 0.7893\n",
            "Epoch 18/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4324 - accuracy: 0.7923\n",
            "Epoch 19/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4267 - accuracy: 0.7943\n",
            "Epoch 20/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4213 - accuracy: 0.7973\n",
            "Epoch 21/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4151 - accuracy: 0.8000\n",
            "Epoch 22/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4098 - accuracy: 0.8028\n",
            "Epoch 23/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4041 - accuracy: 0.8050\n",
            "Epoch 24/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3997 - accuracy: 0.8080\n",
            "Epoch 25/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3941 - accuracy: 0.8106\n",
            "Epoch 26/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3891 - accuracy: 0.8117\n",
            "Epoch 27/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3838 - accuracy: 0.8144\n",
            "Epoch 28/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3807 - accuracy: 0.8162\n",
            "Epoch 29/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3758 - accuracy: 0.8188\n",
            "Epoch 30/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3724 - accuracy: 0.8200\n",
            "Epoch 31/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3683 - accuracy: 0.8222\n",
            "Epoch 32/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3637 - accuracy: 0.8244\n",
            "Epoch 33/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3605 - accuracy: 0.8250\n",
            "Epoch 34/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3569 - accuracy: 0.8271\n",
            "Epoch 35/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3519 - accuracy: 0.8304\n",
            "Epoch 36/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3497 - accuracy: 0.8307\n",
            "Epoch 37/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3475 - accuracy: 0.8320\n",
            "Epoch 38/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3431 - accuracy: 0.8328\n",
            "Epoch 39/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3413 - accuracy: 0.8353\n",
            "Epoch 40/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3374 - accuracy: 0.8368\n",
            "Epoch 41/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3349 - accuracy: 0.8379\n",
            "Epoch 42/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3318 - accuracy: 0.8387\n",
            "Epoch 43/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3292 - accuracy: 0.8404\n",
            "Epoch 44/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3280 - accuracy: 0.8410\n",
            "Epoch 45/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3238 - accuracy: 0.8429\n",
            "Epoch 46/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3228 - accuracy: 0.8426\n",
            "Epoch 47/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3197 - accuracy: 0.8453\n",
            "Epoch 48/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3183 - accuracy: 0.8466\n",
            "Epoch 49/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3163 - accuracy: 0.8475\n",
            "Epoch 50/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3159 - accuracy: 0.8477\n",
            "Epoch 51/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3111 - accuracy: 0.8494\n",
            "Epoch 52/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3101 - accuracy: 0.8504\n",
            "Epoch 53/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3076 - accuracy: 0.8509\n",
            "Epoch 54/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3067 - accuracy: 0.8522\n",
            "Epoch 55/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3038 - accuracy: 0.8532\n",
            "Epoch 56/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3027 - accuracy: 0.8542\n",
            "Epoch 57/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2999 - accuracy: 0.8549\n",
            "Epoch 58/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2986 - accuracy: 0.8565\n",
            "Epoch 59/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2973 - accuracy: 0.8564\n",
            "Epoch 60/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2948 - accuracy: 0.8570\n",
            "Epoch 61/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2940 - accuracy: 0.8579\n",
            "Epoch 62/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2929 - accuracy: 0.8589\n",
            "Epoch 63/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2919 - accuracy: 0.8594\n",
            "Epoch 64/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2912 - accuracy: 0.8602\n",
            "Epoch 65/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2906 - accuracy: 0.8606\n",
            "Epoch 66/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2873 - accuracy: 0.8609\n",
            "Epoch 67/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2855 - accuracy: 0.8614\n",
            "Epoch 68/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2850 - accuracy: 0.8621\n",
            "Epoch 69/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2836 - accuracy: 0.8633\n",
            "Epoch 70/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2838 - accuracy: 0.8631\n",
            "Epoch 71/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2796 - accuracy: 0.8652\n",
            "Epoch 72/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2792 - accuracy: 0.8651\n",
            "Epoch 73/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2780 - accuracy: 0.8658\n",
            "Epoch 74/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2780 - accuracy: 0.8666\n",
            "Epoch 75/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2750 - accuracy: 0.8676\n",
            "Epoch 76/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2760 - accuracy: 0.8669\n",
            "Epoch 77/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2744 - accuracy: 0.8675\n",
            "Epoch 78/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2719 - accuracy: 0.8688\n",
            "Epoch 79/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2708 - accuracy: 0.8688\n",
            "Epoch 80/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2715 - accuracy: 0.8685\n",
            "Epoch 81/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2700 - accuracy: 0.8696\n",
            "Epoch 82/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2694 - accuracy: 0.8698\n",
            "Epoch 83/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2675 - accuracy: 0.8713\n",
            "Epoch 84/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2654 - accuracy: 0.8721\n",
            "Epoch 85/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2652 - accuracy: 0.8718\n",
            "Epoch 86/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2659 - accuracy: 0.8721\n",
            "Epoch 87/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2636 - accuracy: 0.8731\n",
            "Epoch 88/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2612 - accuracy: 0.8738\n",
            "Epoch 89/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2628 - accuracy: 0.8733\n",
            "Epoch 90/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2629 - accuracy: 0.8738\n",
            "Epoch 91/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2604 - accuracy: 0.8746\n",
            "Epoch 92/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2592 - accuracy: 0.8751\n",
            "Epoch 93/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2597 - accuracy: 0.8752\n",
            "Epoch 94/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2577 - accuracy: 0.8761\n",
            "Epoch 95/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2562 - accuracy: 0.8755\n",
            "Epoch 96/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2575 - accuracy: 0.8763\n",
            "Epoch 97/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2581 - accuracy: 0.8761\n",
            "Epoch 98/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2533 - accuracy: 0.8777\n",
            "Epoch 99/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2546 - accuracy: 0.8767\n",
            "Epoch 100/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2539 - accuracy: 0.8769\n",
            "3199/3199 [==============================] - 5s 1ms/step - loss: 0.8426 - accuracy: 0.8083\n",
            "Epoch 1/100\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.5048 - accuracy: 0.7578\n",
            "Epoch 2/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4896 - accuracy: 0.7685\n",
            "Epoch 3/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4866 - accuracy: 0.7702\n",
            "Epoch 4/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4844 - accuracy: 0.7718\n",
            "Epoch 5/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4818 - accuracy: 0.7721\n",
            "Epoch 6/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4799 - accuracy: 0.7735\n",
            "Epoch 7/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4779 - accuracy: 0.7734\n",
            "Epoch 8/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4753 - accuracy: 0.7747\n",
            "Epoch 9/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4723 - accuracy: 0.7752\n",
            "Epoch 10/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4697 - accuracy: 0.7770\n",
            "Epoch 11/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4667 - accuracy: 0.7785\n",
            "Epoch 12/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4622 - accuracy: 0.7804\n",
            "Epoch 13/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4585 - accuracy: 0.7818\n",
            "Epoch 14/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4544 - accuracy: 0.7834\n",
            "Epoch 15/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4490 - accuracy: 0.7864\n",
            "Epoch 16/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4440 - accuracy: 0.7889\n",
            "Epoch 17/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4380 - accuracy: 0.7907\n",
            "Epoch 18/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4327 - accuracy: 0.7939\n",
            "Epoch 19/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4269 - accuracy: 0.7963\n",
            "Epoch 20/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4215 - accuracy: 0.7984\n",
            "Epoch 21/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4163 - accuracy: 0.8005\n",
            "Epoch 22/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4108 - accuracy: 0.8035\n",
            "Epoch 23/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4052 - accuracy: 0.8063\n",
            "Epoch 24/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4006 - accuracy: 0.8088\n",
            "Epoch 25/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3960 - accuracy: 0.8107\n",
            "Epoch 26/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3907 - accuracy: 0.8130\n",
            "Epoch 27/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3856 - accuracy: 0.8153\n",
            "Epoch 28/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3804 - accuracy: 0.8171\n",
            "Epoch 29/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3772 - accuracy: 0.8188\n",
            "Epoch 30/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3732 - accuracy: 0.8212\n",
            "Epoch 31/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3688 - accuracy: 0.8227\n",
            "Epoch 32/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3645 - accuracy: 0.8240\n",
            "Epoch 33/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3626 - accuracy: 0.8248\n",
            "Epoch 34/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3580 - accuracy: 0.8281\n",
            "Epoch 35/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3547 - accuracy: 0.8289\n",
            "Epoch 36/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3516 - accuracy: 0.8299\n",
            "Epoch 37/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3477 - accuracy: 0.8316\n",
            "Epoch 38/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3455 - accuracy: 0.8330\n",
            "Epoch 39/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3418 - accuracy: 0.8347\n",
            "Epoch 40/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3397 - accuracy: 0.8361\n",
            "Epoch 41/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3375 - accuracy: 0.8372\n",
            "Epoch 42/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3340 - accuracy: 0.8388\n",
            "Epoch 43/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3334 - accuracy: 0.8385\n",
            "Epoch 44/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3289 - accuracy: 0.8408\n",
            "Epoch 45/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3275 - accuracy: 0.8422\n",
            "Epoch 46/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3245 - accuracy: 0.8427\n",
            "Epoch 47/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3219 - accuracy: 0.8435\n",
            "Epoch 48/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3214 - accuracy: 0.8444\n",
            "Epoch 49/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3188 - accuracy: 0.8467\n",
            "Epoch 50/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3172 - accuracy: 0.8463\n",
            "Epoch 51/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3153 - accuracy: 0.8479\n",
            "Epoch 52/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3116 - accuracy: 0.8476\n",
            "Epoch 53/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3116 - accuracy: 0.8484\n",
            "Epoch 54/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3088 - accuracy: 0.8501\n",
            "Epoch 55/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3067 - accuracy: 0.8505\n",
            "Epoch 56/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3049 - accuracy: 0.8520\n",
            "Epoch 57/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3045 - accuracy: 0.8518\n",
            "Epoch 58/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3042 - accuracy: 0.8520\n",
            "Epoch 59/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2979 - accuracy: 0.8552\n",
            "Epoch 60/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3004 - accuracy: 0.8547\n",
            "Epoch 61/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2971 - accuracy: 0.8552\n",
            "Epoch 62/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2968 - accuracy: 0.8553\n",
            "Epoch 63/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2965 - accuracy: 0.8558\n",
            "Epoch 64/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2928 - accuracy: 0.8576\n",
            "Epoch 65/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2940 - accuracy: 0.8581\n",
            "Epoch 66/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2899 - accuracy: 0.8588\n",
            "Epoch 67/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2891 - accuracy: 0.8583\n",
            "Epoch 68/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2896 - accuracy: 0.8594\n",
            "Epoch 69/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2854 - accuracy: 0.8608\n",
            "Epoch 70/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2870 - accuracy: 0.8609\n",
            "Epoch 71/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2854 - accuracy: 0.8609\n",
            "Epoch 72/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2839 - accuracy: 0.8618\n",
            "Epoch 73/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2830 - accuracy: 0.8622\n",
            "Epoch 74/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2805 - accuracy: 0.8636\n",
            "Epoch 75/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2811 - accuracy: 0.8633\n",
            "Epoch 76/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2797 - accuracy: 0.8647\n",
            "Epoch 77/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2766 - accuracy: 0.8654\n",
            "Epoch 78/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2778 - accuracy: 0.8662\n",
            "Epoch 79/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2777 - accuracy: 0.8654\n",
            "Epoch 80/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2751 - accuracy: 0.8664\n",
            "Epoch 81/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2724 - accuracy: 0.8668\n",
            "Epoch 82/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2719 - accuracy: 0.8683\n",
            "Epoch 83/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2730 - accuracy: 0.8678\n",
            "Epoch 84/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2715 - accuracy: 0.8686\n",
            "Epoch 85/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2719 - accuracy: 0.8687\n",
            "Epoch 86/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2699 - accuracy: 0.8692\n",
            "Epoch 87/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2683 - accuracy: 0.8703\n",
            "Epoch 88/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2690 - accuracy: 0.8690\n",
            "Epoch 89/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2653 - accuracy: 0.8711\n",
            "Epoch 90/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2677 - accuracy: 0.8706\n",
            "Epoch 91/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2623 - accuracy: 0.8734\n",
            "Epoch 92/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2666 - accuracy: 0.8710\n",
            "Epoch 93/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2627 - accuracy: 0.8727\n",
            "Epoch 94/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2621 - accuracy: 0.8722\n",
            "Epoch 95/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2619 - accuracy: 0.8726\n",
            "Epoch 96/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2638 - accuracy: 0.8723\n",
            "Epoch 97/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2612 - accuracy: 0.8729\n",
            "Epoch 98/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2581 - accuracy: 0.8736\n",
            "Epoch 99/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2577 - accuracy: 0.8744\n",
            "Epoch 100/100\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2586 - accuracy: 0.8744\n",
            "3199/3199 [==============================] - 5s 1ms/step - loss: 0.8518 - accuracy: 0.8074\n",
            "Epoch 1/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.5067 - accuracy: 0.7579\n",
            "Epoch 2/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4918 - accuracy: 0.7662\n",
            "Epoch 3/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4889 - accuracy: 0.7685\n",
            "Epoch 4/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4862 - accuracy: 0.7683\n",
            "Epoch 5/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4835 - accuracy: 0.7715\n",
            "Epoch 6/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4813 - accuracy: 0.7713\n",
            "Epoch 7/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4797 - accuracy: 0.7722\n",
            "Epoch 8/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4767 - accuracy: 0.7734\n",
            "Epoch 9/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4738 - accuracy: 0.7738\n",
            "Epoch 10/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4707 - accuracy: 0.7752\n",
            "Epoch 11/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4672 - accuracy: 0.7771\n",
            "Epoch 12/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4636 - accuracy: 0.7779\n",
            "Epoch 13/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4587 - accuracy: 0.7801\n",
            "Epoch 14/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4547 - accuracy: 0.7812\n",
            "Epoch 15/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4499 - accuracy: 0.7826\n",
            "Epoch 16/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4450 - accuracy: 0.7852\n",
            "Epoch 17/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4388 - accuracy: 0.7878\n",
            "Epoch 18/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4333 - accuracy: 0.7905\n",
            "Epoch 19/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4282 - accuracy: 0.7933\n",
            "Epoch 20/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4224 - accuracy: 0.7957\n",
            "Epoch 21/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4170 - accuracy: 0.7995\n",
            "Epoch 22/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4104 - accuracy: 0.8027\n",
            "Epoch 23/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4051 - accuracy: 0.8050\n",
            "Epoch 24/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3992 - accuracy: 0.8088\n",
            "Epoch 25/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3928 - accuracy: 0.8121\n",
            "Epoch 26/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3882 - accuracy: 0.8134\n",
            "Epoch 27/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3828 - accuracy: 0.8169\n",
            "Epoch 28/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3780 - accuracy: 0.8200\n",
            "Epoch 29/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3733 - accuracy: 0.8211\n",
            "Epoch 30/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3681 - accuracy: 0.8242\n",
            "Epoch 31/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3644 - accuracy: 0.8269\n",
            "Epoch 32/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3598 - accuracy: 0.8283\n",
            "Epoch 33/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3552 - accuracy: 0.8298\n",
            "Epoch 34/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3515 - accuracy: 0.8314\n",
            "Epoch 35/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3490 - accuracy: 0.8340\n",
            "Epoch 36/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3450 - accuracy: 0.8350\n",
            "Epoch 37/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3426 - accuracy: 0.8364\n",
            "Epoch 38/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3386 - accuracy: 0.8381\n",
            "Epoch 39/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3358 - accuracy: 0.8389\n",
            "Epoch 40/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3325 - accuracy: 0.8406\n",
            "Epoch 41/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3308 - accuracy: 0.8428\n",
            "Epoch 42/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3280 - accuracy: 0.8431\n",
            "Epoch 43/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3243 - accuracy: 0.8447\n",
            "Epoch 44/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3217 - accuracy: 0.8462\n",
            "Epoch 45/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3190 - accuracy: 0.8476\n",
            "Epoch 46/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3166 - accuracy: 0.8484\n",
            "Epoch 47/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3142 - accuracy: 0.8500\n",
            "Epoch 48/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3130 - accuracy: 0.8504\n",
            "Epoch 49/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3108 - accuracy: 0.8508\n",
            "Epoch 50/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3075 - accuracy: 0.8527\n",
            "Epoch 51/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3072 - accuracy: 0.8528\n",
            "Epoch 52/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3055 - accuracy: 0.8530\n",
            "Epoch 53/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3021 - accuracy: 0.8557\n",
            "Epoch 54/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3003 - accuracy: 0.8575\n",
            "Epoch 55/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2983 - accuracy: 0.8582\n",
            "Epoch 56/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2976 - accuracy: 0.8576\n",
            "Epoch 57/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2959 - accuracy: 0.8597\n",
            "Epoch 58/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2934 - accuracy: 0.8595\n",
            "Epoch 59/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2920 - accuracy: 0.8609\n",
            "Epoch 60/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2910 - accuracy: 0.8610\n",
            "Epoch 61/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2898 - accuracy: 0.8620\n",
            "Epoch 62/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2888 - accuracy: 0.8620\n",
            "Epoch 63/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2859 - accuracy: 0.8636\n",
            "Epoch 64/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2849 - accuracy: 0.8639\n",
            "Epoch 65/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2837 - accuracy: 0.8650\n",
            "Epoch 66/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2829 - accuracy: 0.8646\n",
            "Epoch 67/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2811 - accuracy: 0.8657\n",
            "Epoch 68/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2802 - accuracy: 0.8666\n",
            "Epoch 69/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2786 - accuracy: 0.8675\n",
            "Epoch 70/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2770 - accuracy: 0.8675\n",
            "Epoch 71/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2781 - accuracy: 0.8675\n",
            "Epoch 72/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2737 - accuracy: 0.8700\n",
            "Epoch 73/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2726 - accuracy: 0.8694\n",
            "Epoch 74/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2731 - accuracy: 0.8701\n",
            "Epoch 75/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2720 - accuracy: 0.8705\n",
            "Epoch 76/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2687 - accuracy: 0.8716\n",
            "Epoch 77/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2711 - accuracy: 0.8701\n",
            "Epoch 78/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2689 - accuracy: 0.8720\n",
            "Epoch 79/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2675 - accuracy: 0.8724\n",
            "Epoch 80/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2648 - accuracy: 0.8736\n",
            "Epoch 81/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2647 - accuracy: 0.8735\n",
            "Epoch 82/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2650 - accuracy: 0.8729\n",
            "Epoch 83/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2646 - accuracy: 0.8745\n",
            "Epoch 84/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2623 - accuracy: 0.8754\n",
            "Epoch 85/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2606 - accuracy: 0.8755\n",
            "Epoch 86/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2618 - accuracy: 0.8751\n",
            "Epoch 87/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2598 - accuracy: 0.8762\n",
            "Epoch 88/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2588 - accuracy: 0.8773\n",
            "Epoch 89/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2569 - accuracy: 0.8777\n",
            "Epoch 90/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2573 - accuracy: 0.8775\n",
            "Epoch 91/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2570 - accuracy: 0.8779\n",
            "Epoch 92/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2557 - accuracy: 0.8787\n",
            "Epoch 93/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2549 - accuracy: 0.8789\n",
            "Epoch 94/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2538 - accuracy: 0.8786\n",
            "Epoch 95/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2536 - accuracy: 0.8788\n",
            "Epoch 96/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2525 - accuracy: 0.8798\n",
            "Epoch 97/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2528 - accuracy: 0.8800\n",
            "Epoch 98/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2504 - accuracy: 0.8802\n",
            "Epoch 99/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2510 - accuracy: 0.8810\n",
            "Epoch 100/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2510 - accuracy: 0.8807\n",
            "Epoch 101/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2490 - accuracy: 0.8820\n",
            "Epoch 102/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2467 - accuracy: 0.8818\n",
            "Epoch 103/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2498 - accuracy: 0.8814\n",
            "Epoch 104/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2456 - accuracy: 0.8830\n",
            "Epoch 105/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2478 - accuracy: 0.8828\n",
            "Epoch 106/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2453 - accuracy: 0.8833\n",
            "Epoch 107/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2458 - accuracy: 0.8839\n",
            "Epoch 108/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2441 - accuracy: 0.8846\n",
            "Epoch 109/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2445 - accuracy: 0.8843\n",
            "Epoch 110/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2425 - accuracy: 0.8842\n",
            "Epoch 111/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2410 - accuracy: 0.8846\n",
            "Epoch 112/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2413 - accuracy: 0.8845\n",
            "Epoch 113/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2391 - accuracy: 0.8859\n",
            "Epoch 114/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2426 - accuracy: 0.8849\n",
            "Epoch 115/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2398 - accuracy: 0.8859\n",
            "Epoch 116/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2403 - accuracy: 0.8858\n",
            "Epoch 117/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2370 - accuracy: 0.8879\n",
            "Epoch 118/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2371 - accuracy: 0.8872\n",
            "Epoch 119/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2398 - accuracy: 0.8870\n",
            "Epoch 120/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2400 - accuracy: 0.8871\n",
            "Epoch 121/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2385 - accuracy: 0.8862\n",
            "Epoch 122/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2376 - accuracy: 0.8878\n",
            "Epoch 123/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2351 - accuracy: 0.8874\n",
            "Epoch 124/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2363 - accuracy: 0.8891\n",
            "Epoch 125/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2355 - accuracy: 0.8882\n",
            "Epoch 126/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2352 - accuracy: 0.8887\n",
            "Epoch 127/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2358 - accuracy: 0.8889\n",
            "Epoch 128/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2325 - accuracy: 0.8888\n",
            "Epoch 129/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2321 - accuracy: 0.8901\n",
            "Epoch 130/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2325 - accuracy: 0.8903\n",
            "Epoch 131/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2298 - accuracy: 0.8905\n",
            "Epoch 132/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2328 - accuracy: 0.8895\n",
            "Epoch 133/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2299 - accuracy: 0.8905\n",
            "Epoch 134/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2327 - accuracy: 0.8902\n",
            "Epoch 135/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2289 - accuracy: 0.8906\n",
            "Epoch 136/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2282 - accuracy: 0.8909\n",
            "Epoch 137/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2292 - accuracy: 0.8918\n",
            "Epoch 138/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2289 - accuracy: 0.8916\n",
            "Epoch 139/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2274 - accuracy: 0.8923\n",
            "Epoch 140/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2289 - accuracy: 0.8917\n",
            "Epoch 141/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2259 - accuracy: 0.8919\n",
            "Epoch 142/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2297 - accuracy: 0.8918\n",
            "Epoch 143/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2270 - accuracy: 0.8919\n",
            "Epoch 144/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2261 - accuracy: 0.8923\n",
            "Epoch 145/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2277 - accuracy: 0.8923\n",
            "Epoch 146/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2249 - accuracy: 0.8932\n",
            "Epoch 147/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2262 - accuracy: 0.8930\n",
            "Epoch 148/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2241 - accuracy: 0.8940\n",
            "Epoch 149/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2257 - accuracy: 0.8939\n",
            "Epoch 150/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2245 - accuracy: 0.8929\n",
            "3199/3199 [==============================] - 5s 1ms/step - loss: 0.9336 - accuracy: 0.8172\n",
            "Epoch 1/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.5042 - accuracy: 0.7579\n",
            "Epoch 2/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4901 - accuracy: 0.7684\n",
            "Epoch 3/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4864 - accuracy: 0.7695\n",
            "Epoch 4/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4844 - accuracy: 0.7705\n",
            "Epoch 5/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4821 - accuracy: 0.7715\n",
            "Epoch 6/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4798 - accuracy: 0.7726\n",
            "Epoch 7/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4776 - accuracy: 0.7725\n",
            "Epoch 8/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4753 - accuracy: 0.7737\n",
            "Epoch 9/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4721 - accuracy: 0.7745\n",
            "Epoch 10/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4698 - accuracy: 0.7752\n",
            "Epoch 11/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4660 - accuracy: 0.7771\n",
            "Epoch 12/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4621 - accuracy: 0.7781\n",
            "Epoch 13/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4583 - accuracy: 0.7801\n",
            "Epoch 14/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4538 - accuracy: 0.7816\n",
            "Epoch 15/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4484 - accuracy: 0.7842\n",
            "Epoch 16/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4427 - accuracy: 0.7862\n",
            "Epoch 17/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.4376 - accuracy: 0.7891\n",
            "Epoch 18/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4319 - accuracy: 0.7920\n",
            "Epoch 19/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4259 - accuracy: 0.7948\n",
            "Epoch 20/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4203 - accuracy: 0.7977\n",
            "Epoch 21/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4145 - accuracy: 0.7997\n",
            "Epoch 22/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4093 - accuracy: 0.8030\n",
            "Epoch 23/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.4035 - accuracy: 0.8056\n",
            "Epoch 24/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3974 - accuracy: 0.8083\n",
            "Epoch 25/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3928 - accuracy: 0.8101\n",
            "Epoch 26/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3864 - accuracy: 0.8138\n",
            "Epoch 27/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3819 - accuracy: 0.8161\n",
            "Epoch 28/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3770 - accuracy: 0.8194\n",
            "Epoch 29/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3732 - accuracy: 0.8210\n",
            "Epoch 30/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3697 - accuracy: 0.8228\n",
            "Epoch 31/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3641 - accuracy: 0.8249\n",
            "Epoch 32/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3601 - accuracy: 0.8265\n",
            "Epoch 33/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3560 - accuracy: 0.8283\n",
            "Epoch 34/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3532 - accuracy: 0.8305\n",
            "Epoch 35/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3500 - accuracy: 0.8326\n",
            "Epoch 36/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3459 - accuracy: 0.8341\n",
            "Epoch 37/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3422 - accuracy: 0.8355\n",
            "Epoch 38/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3401 - accuracy: 0.8370\n",
            "Epoch 39/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3360 - accuracy: 0.8367\n",
            "Epoch 40/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3345 - accuracy: 0.8381\n",
            "Epoch 41/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3302 - accuracy: 0.8412\n",
            "Epoch 42/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3275 - accuracy: 0.8422\n",
            "Epoch 43/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3261 - accuracy: 0.8427\n",
            "Epoch 44/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3229 - accuracy: 0.8445\n",
            "Epoch 45/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3216 - accuracy: 0.8462\n",
            "Epoch 46/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3174 - accuracy: 0.8469\n",
            "Epoch 47/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3166 - accuracy: 0.8491\n",
            "Epoch 48/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3135 - accuracy: 0.8498\n",
            "Epoch 49/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3120 - accuracy: 0.8501\n",
            "Epoch 50/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.3096 - accuracy: 0.8512\n",
            "Epoch 51/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3074 - accuracy: 0.8524\n",
            "Epoch 52/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3042 - accuracy: 0.8529\n",
            "Epoch 53/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3047 - accuracy: 0.8535\n",
            "Epoch 54/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3024 - accuracy: 0.8545\n",
            "Epoch 55/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.3005 - accuracy: 0.8557\n",
            "Epoch 56/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2989 - accuracy: 0.8564\n",
            "Epoch 57/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2948 - accuracy: 0.8587\n",
            "Epoch 58/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2967 - accuracy: 0.8577\n",
            "Epoch 59/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2933 - accuracy: 0.8586\n",
            "Epoch 60/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2918 - accuracy: 0.8606\n",
            "Epoch 61/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2903 - accuracy: 0.8601\n",
            "Epoch 62/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2885 - accuracy: 0.8618\n",
            "Epoch 63/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2856 - accuracy: 0.8627\n",
            "Epoch 64/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2866 - accuracy: 0.8626\n",
            "Epoch 65/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2836 - accuracy: 0.8642\n",
            "Epoch 66/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2827 - accuracy: 0.8648\n",
            "Epoch 67/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2815 - accuracy: 0.8647\n",
            "Epoch 68/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2818 - accuracy: 0.8657\n",
            "Epoch 69/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2799 - accuracy: 0.8662\n",
            "Epoch 70/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2767 - accuracy: 0.8665\n",
            "Epoch 71/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2774 - accuracy: 0.8661\n",
            "Epoch 72/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2756 - accuracy: 0.8682\n",
            "Epoch 73/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2742 - accuracy: 0.8688\n",
            "Epoch 74/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2727 - accuracy: 0.8699\n",
            "Epoch 75/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2731 - accuracy: 0.8693\n",
            "Epoch 76/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2723 - accuracy: 0.8705\n",
            "Epoch 77/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2703 - accuracy: 0.8704\n",
            "Epoch 78/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2695 - accuracy: 0.8712\n",
            "Epoch 79/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2669 - accuracy: 0.8723\n",
            "Epoch 80/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2662 - accuracy: 0.8734\n",
            "Epoch 81/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2666 - accuracy: 0.8724\n",
            "Epoch 82/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2628 - accuracy: 0.8729\n",
            "Epoch 83/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2645 - accuracy: 0.8738\n",
            "Epoch 84/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2614 - accuracy: 0.8749\n",
            "Epoch 85/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2641 - accuracy: 0.8739\n",
            "Epoch 86/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2608 - accuracy: 0.8751\n",
            "Epoch 87/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2609 - accuracy: 0.8755\n",
            "Epoch 88/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2590 - accuracy: 0.8759\n",
            "Epoch 89/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2583 - accuracy: 0.8762\n",
            "Epoch 90/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2583 - accuracy: 0.8765\n",
            "Epoch 91/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2559 - accuracy: 0.8771\n",
            "Epoch 92/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2568 - accuracy: 0.8769\n",
            "Epoch 93/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2539 - accuracy: 0.8781\n",
            "Epoch 94/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2557 - accuracy: 0.8775\n",
            "Epoch 95/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2532 - accuracy: 0.8793\n",
            "Epoch 96/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2539 - accuracy: 0.8794\n",
            "Epoch 97/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2519 - accuracy: 0.8791\n",
            "Epoch 98/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2529 - accuracy: 0.8793\n",
            "Epoch 99/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2509 - accuracy: 0.8805\n",
            "Epoch 100/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2490 - accuracy: 0.8806\n",
            "Epoch 101/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2490 - accuracy: 0.8815\n",
            "Epoch 102/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2480 - accuracy: 0.8808\n",
            "Epoch 103/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2480 - accuracy: 0.8816\n",
            "Epoch 104/150\n",
            "3199/3199 [==============================] - 7s 2ms/step - loss: 0.2477 - accuracy: 0.8818\n",
            "Epoch 105/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2477 - accuracy: 0.8821\n",
            "Epoch 106/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2446 - accuracy: 0.8824\n",
            "Epoch 107/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2457 - accuracy: 0.8821\n",
            "Epoch 108/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2438 - accuracy: 0.8832\n",
            "Epoch 109/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2447 - accuracy: 0.8834\n",
            "Epoch 110/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2444 - accuracy: 0.8840\n",
            "Epoch 111/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2424 - accuracy: 0.8838\n",
            "Epoch 112/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2400 - accuracy: 0.8854\n",
            "Epoch 113/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2405 - accuracy: 0.8852\n",
            "Epoch 114/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2408 - accuracy: 0.8848\n",
            "Epoch 115/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2423 - accuracy: 0.8844\n",
            "Epoch 116/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2377 - accuracy: 0.8864\n",
            "Epoch 117/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2408 - accuracy: 0.8848\n",
            "Epoch 118/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2371 - accuracy: 0.8863\n",
            "Epoch 119/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2385 - accuracy: 0.8856\n",
            "Epoch 120/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2358 - accuracy: 0.8874\n",
            "Epoch 121/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2378 - accuracy: 0.8877\n",
            "Epoch 122/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2358 - accuracy: 0.8878\n",
            "Epoch 123/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2366 - accuracy: 0.8872\n",
            "Epoch 124/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2353 - accuracy: 0.8875\n",
            "Epoch 125/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2361 - accuracy: 0.8870\n",
            "Epoch 126/150\n",
            "3199/3199 [==============================] - 8s 3ms/step - loss: 0.2345 - accuracy: 0.8885\n",
            "Epoch 127/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2323 - accuracy: 0.8891\n",
            "Epoch 128/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2328 - accuracy: 0.8891\n",
            "Epoch 129/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2326 - accuracy: 0.8888\n",
            "Epoch 130/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2302 - accuracy: 0.8902\n",
            "Epoch 131/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2318 - accuracy: 0.8896\n",
            "Epoch 132/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2307 - accuracy: 0.8906\n",
            "Epoch 133/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2297 - accuracy: 0.8902\n",
            "Epoch 134/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2305 - accuracy: 0.8906\n",
            "Epoch 135/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2290 - accuracy: 0.8910\n",
            "Epoch 136/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2292 - accuracy: 0.8905\n",
            "Epoch 137/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2287 - accuracy: 0.8902\n",
            "Epoch 138/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2284 - accuracy: 0.8916\n",
            "Epoch 139/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2288 - accuracy: 0.8912\n",
            "Epoch 140/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2280 - accuracy: 0.8913\n",
            "Epoch 141/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2258 - accuracy: 0.8921\n",
            "Epoch 142/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2259 - accuracy: 0.8924\n",
            "Epoch 143/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2277 - accuracy: 0.8917\n",
            "Epoch 144/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2279 - accuracy: 0.8916\n",
            "Epoch 145/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2245 - accuracy: 0.8926\n",
            "Epoch 146/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2266 - accuracy: 0.8920\n",
            "Epoch 147/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2252 - accuracy: 0.8932\n",
            "Epoch 148/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2246 - accuracy: 0.8937\n",
            "Epoch 149/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2246 - accuracy: 0.8928\n",
            "Epoch 150/150\n",
            "3199/3199 [==============================] - 8s 2ms/step - loss: 0.2230 - accuracy: 0.8934\n",
            "3199/3199 [==============================] - 5s 2ms/step - loss: 0.9453 - accuracy: 0.8154\n",
            "Epoch 1/50\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.5100 - accuracy: 0.7537\n",
            "Epoch 2/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4905 - accuracy: 0.7678\n",
            "Epoch 3/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4880 - accuracy: 0.7686\n",
            "Epoch 4/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4857 - accuracy: 0.7700\n",
            "Epoch 5/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4837 - accuracy: 0.7708\n",
            "Epoch 6/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4811 - accuracy: 0.7716\n",
            "Epoch 7/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4803 - accuracy: 0.7731\n",
            "Epoch 8/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4783 - accuracy: 0.7722\n",
            "Epoch 9/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4762 - accuracy: 0.7730\n",
            "Epoch 10/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4744 - accuracy: 0.7740\n",
            "Epoch 11/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4726 - accuracy: 0.7750\n",
            "Epoch 12/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4700 - accuracy: 0.7762\n",
            "Epoch 13/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4673 - accuracy: 0.7769\n",
            "Epoch 14/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4647 - accuracy: 0.7785\n",
            "Epoch 15/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4617 - accuracy: 0.7795\n",
            "Epoch 16/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4584 - accuracy: 0.7807\n",
            "Epoch 17/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4550 - accuracy: 0.7830\n",
            "Epoch 18/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4519 - accuracy: 0.7832\n",
            "Epoch 19/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4481 - accuracy: 0.7852\n",
            "Epoch 20/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4443 - accuracy: 0.7877\n",
            "Epoch 21/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4396 - accuracy: 0.7885\n",
            "Epoch 22/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4357 - accuracy: 0.7909\n",
            "Epoch 23/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4318 - accuracy: 0.7931\n",
            "Epoch 24/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4277 - accuracy: 0.7948\n",
            "Epoch 25/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4231 - accuracy: 0.7965\n",
            "Epoch 26/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4179 - accuracy: 0.7995\n",
            "Epoch 27/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4140 - accuracy: 0.8003\n",
            "Epoch 28/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4096 - accuracy: 0.8019\n",
            "Epoch 29/50\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4052 - accuracy: 0.8054\n",
            "Epoch 30/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3999 - accuracy: 0.8077\n",
            "Epoch 31/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3964 - accuracy: 0.8087\n",
            "Epoch 32/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3923 - accuracy: 0.8120\n",
            "Epoch 33/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3878 - accuracy: 0.8132\n",
            "Epoch 34/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3845 - accuracy: 0.8145\n",
            "Epoch 35/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3809 - accuracy: 0.8168\n",
            "Epoch 36/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3764 - accuracy: 0.8198\n",
            "Epoch 37/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3722 - accuracy: 0.8210\n",
            "Epoch 38/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3690 - accuracy: 0.8223\n",
            "Epoch 39/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3653 - accuracy: 0.8235\n",
            "Epoch 40/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3629 - accuracy: 0.8257\n",
            "Epoch 41/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3584 - accuracy: 0.8286\n",
            "Epoch 42/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3554 - accuracy: 0.8294\n",
            "Epoch 43/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3538 - accuracy: 0.8296\n",
            "Epoch 44/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3490 - accuracy: 0.8310\n",
            "Epoch 45/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3472 - accuracy: 0.8324\n",
            "Epoch 46/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3451 - accuracy: 0.8339\n",
            "Epoch 47/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3415 - accuracy: 0.8360\n",
            "Epoch 48/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3392 - accuracy: 0.8369\n",
            "Epoch 49/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3365 - accuracy: 0.8384\n",
            "Epoch 50/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3355 - accuracy: 0.8387\n",
            "1600/1600 [==============================] - 3s 2ms/step - loss: 0.5582 - accuracy: 0.7927\n",
            "Epoch 1/50\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.5067 - accuracy: 0.7559\n",
            "Epoch 2/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4888 - accuracy: 0.7692\n",
            "Epoch 3/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4865 - accuracy: 0.7695\n",
            "Epoch 4/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4841 - accuracy: 0.7709\n",
            "Epoch 5/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4827 - accuracy: 0.7710\n",
            "Epoch 6/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4802 - accuracy: 0.7720\n",
            "Epoch 7/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4788 - accuracy: 0.7732\n",
            "Epoch 8/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4771 - accuracy: 0.7740\n",
            "Epoch 9/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4752 - accuracy: 0.7737\n",
            "Epoch 10/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4736 - accuracy: 0.7757\n",
            "Epoch 11/50\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4719 - accuracy: 0.7764\n",
            "Epoch 12/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4695 - accuracy: 0.7768\n",
            "Epoch 13/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4669 - accuracy: 0.7769\n",
            "Epoch 14/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4651 - accuracy: 0.7779\n",
            "Epoch 15/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4625 - accuracy: 0.7790\n",
            "Epoch 16/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4590 - accuracy: 0.7803\n",
            "Epoch 17/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4563 - accuracy: 0.7817\n",
            "Epoch 18/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4523 - accuracy: 0.7836\n",
            "Epoch 19/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4496 - accuracy: 0.7841\n",
            "Epoch 20/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4458 - accuracy: 0.7859\n",
            "Epoch 21/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4418 - accuracy: 0.7888\n",
            "Epoch 22/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4370 - accuracy: 0.7900\n",
            "Epoch 23/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4340 - accuracy: 0.7921\n",
            "Epoch 24/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4292 - accuracy: 0.7948\n",
            "Epoch 25/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4249 - accuracy: 0.7965\n",
            "Epoch 26/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4203 - accuracy: 0.7990\n",
            "Epoch 27/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4154 - accuracy: 0.8017\n",
            "Epoch 28/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4113 - accuracy: 0.8023\n",
            "Epoch 29/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4071 - accuracy: 0.8048\n",
            "Epoch 30/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4022 - accuracy: 0.8068\n",
            "Epoch 31/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3985 - accuracy: 0.8088\n",
            "Epoch 32/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3929 - accuracy: 0.8116\n",
            "Epoch 33/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3893 - accuracy: 0.8140\n",
            "Epoch 34/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3855 - accuracy: 0.8152\n",
            "Epoch 35/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3811 - accuracy: 0.8174\n",
            "Epoch 36/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3779 - accuracy: 0.8189\n",
            "Epoch 37/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3749 - accuracy: 0.8206\n",
            "Epoch 38/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3699 - accuracy: 0.8216\n",
            "Epoch 39/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3670 - accuracy: 0.8246\n",
            "Epoch 40/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3628 - accuracy: 0.8264\n",
            "Epoch 41/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3598 - accuracy: 0.8272\n",
            "Epoch 42/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3575 - accuracy: 0.8285\n",
            "Epoch 43/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3533 - accuracy: 0.8294\n",
            "Epoch 44/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3509 - accuracy: 0.8307\n",
            "Epoch 45/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3472 - accuracy: 0.8329\n",
            "Epoch 46/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3445 - accuracy: 0.8347\n",
            "Epoch 47/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3414 - accuracy: 0.8359\n",
            "Epoch 48/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3396 - accuracy: 0.8372\n",
            "Epoch 49/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3376 - accuracy: 0.8371\n",
            "Epoch 50/50\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3337 - accuracy: 0.8387\n",
            "1600/1600 [==============================] - 3s 2ms/step - loss: 0.5423 - accuracy: 0.7958\n",
            "Epoch 1/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.5088 - accuracy: 0.7546\n",
            "Epoch 2/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4908 - accuracy: 0.7668\n",
            "Epoch 3/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4879 - accuracy: 0.7693\n",
            "Epoch 4/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4861 - accuracy: 0.7699\n",
            "Epoch 5/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4837 - accuracy: 0.7707\n",
            "Epoch 6/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4821 - accuracy: 0.7711\n",
            "Epoch 7/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4806 - accuracy: 0.7719\n",
            "Epoch 8/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4789 - accuracy: 0.7730\n",
            "Epoch 9/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4767 - accuracy: 0.7729\n",
            "Epoch 10/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4750 - accuracy: 0.7740\n",
            "Epoch 11/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4730 - accuracy: 0.7743\n",
            "Epoch 12/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4705 - accuracy: 0.7755\n",
            "Epoch 13/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4689 - accuracy: 0.7763\n",
            "Epoch 14/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4659 - accuracy: 0.7776\n",
            "Epoch 15/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4632 - accuracy: 0.7786\n",
            "Epoch 16/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4599 - accuracy: 0.7797\n",
            "Epoch 17/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4570 - accuracy: 0.7809\n",
            "Epoch 18/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4533 - accuracy: 0.7817\n",
            "Epoch 19/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4502 - accuracy: 0.7841\n",
            "Epoch 20/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4458 - accuracy: 0.7857\n",
            "Epoch 21/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4415 - accuracy: 0.7882\n",
            "Epoch 22/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4373 - accuracy: 0.7897\n",
            "Epoch 23/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4328 - accuracy: 0.7919\n",
            "Epoch 24/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4282 - accuracy: 0.7949\n",
            "Epoch 25/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4235 - accuracy: 0.7976\n",
            "Epoch 26/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4194 - accuracy: 0.7993\n",
            "Epoch 27/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4143 - accuracy: 0.8014\n",
            "Epoch 28/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4100 - accuracy: 0.8042\n",
            "Epoch 29/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4051 - accuracy: 0.8061\n",
            "Epoch 30/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4014 - accuracy: 0.8069\n",
            "Epoch 31/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3964 - accuracy: 0.8093\n",
            "Epoch 32/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3916 - accuracy: 0.8126\n",
            "Epoch 33/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3876 - accuracy: 0.8137\n",
            "Epoch 34/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3844 - accuracy: 0.8153\n",
            "Epoch 35/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3793 - accuracy: 0.8189\n",
            "Epoch 36/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3754 - accuracy: 0.8202\n",
            "Epoch 37/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3718 - accuracy: 0.8218\n",
            "Epoch 38/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3679 - accuracy: 0.8239\n",
            "Epoch 39/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3637 - accuracy: 0.8253\n",
            "Epoch 40/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3602 - accuracy: 0.8281\n",
            "Epoch 41/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3573 - accuracy: 0.8278\n",
            "Epoch 42/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3534 - accuracy: 0.8294\n",
            "Epoch 43/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3511 - accuracy: 0.8321\n",
            "Epoch 44/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3479 - accuracy: 0.8325\n",
            "Epoch 45/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3440 - accuracy: 0.8347\n",
            "Epoch 46/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3419 - accuracy: 0.8355\n",
            "Epoch 47/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3395 - accuracy: 0.8367\n",
            "Epoch 48/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3350 - accuracy: 0.8388\n",
            "Epoch 49/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3328 - accuracy: 0.8398\n",
            "Epoch 50/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3311 - accuracy: 0.8411\n",
            "Epoch 51/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3277 - accuracy: 0.8422\n",
            "Epoch 52/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3253 - accuracy: 0.8428\n",
            "Epoch 53/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3222 - accuracy: 0.8442\n",
            "Epoch 54/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3209 - accuracy: 0.8449\n",
            "Epoch 55/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3188 - accuracy: 0.8454\n",
            "Epoch 56/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3172 - accuracy: 0.8469\n",
            "Epoch 57/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3133 - accuracy: 0.8488\n",
            "Epoch 58/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3123 - accuracy: 0.8488\n",
            "Epoch 59/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3116 - accuracy: 0.8495\n",
            "Epoch 60/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3086 - accuracy: 0.8505\n",
            "Epoch 61/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3067 - accuracy: 0.8524\n",
            "Epoch 62/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3031 - accuracy: 0.8527\n",
            "Epoch 63/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3036 - accuracy: 0.8531\n",
            "Epoch 64/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3004 - accuracy: 0.8551\n",
            "Epoch 65/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2998 - accuracy: 0.8554\n",
            "Epoch 66/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2985 - accuracy: 0.8560\n",
            "Epoch 67/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2978 - accuracy: 0.8570\n",
            "Epoch 68/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2926 - accuracy: 0.8592\n",
            "Epoch 69/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2941 - accuracy: 0.8573\n",
            "Epoch 70/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2901 - accuracy: 0.8597\n",
            "Epoch 71/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2911 - accuracy: 0.8592\n",
            "Epoch 72/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2894 - accuracy: 0.8600\n",
            "Epoch 73/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2865 - accuracy: 0.8604\n",
            "Epoch 74/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2845 - accuracy: 0.8624\n",
            "Epoch 75/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2853 - accuracy: 0.8617\n",
            "Epoch 76/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2832 - accuracy: 0.8628\n",
            "Epoch 77/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2804 - accuracy: 0.8632\n",
            "Epoch 78/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2822 - accuracy: 0.8631\n",
            "Epoch 79/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2802 - accuracy: 0.8635\n",
            "Epoch 80/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2766 - accuracy: 0.8661\n",
            "Epoch 81/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2772 - accuracy: 0.8662\n",
            "Epoch 82/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2757 - accuracy: 0.8672\n",
            "Epoch 83/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2738 - accuracy: 0.8677\n",
            "Epoch 84/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2748 - accuracy: 0.8674\n",
            "Epoch 85/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2723 - accuracy: 0.8687\n",
            "Epoch 86/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2700 - accuracy: 0.8680\n",
            "Epoch 87/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2715 - accuracy: 0.8692\n",
            "Epoch 88/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2663 - accuracy: 0.8708\n",
            "Epoch 89/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2690 - accuracy: 0.8707\n",
            "Epoch 90/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2677 - accuracy: 0.8702\n",
            "Epoch 91/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2654 - accuracy: 0.8715\n",
            "Epoch 92/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2636 - accuracy: 0.8725\n",
            "Epoch 93/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2650 - accuracy: 0.8717\n",
            "Epoch 94/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2621 - accuracy: 0.8734\n",
            "Epoch 95/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2611 - accuracy: 0.8729\n",
            "Epoch 96/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2611 - accuracy: 0.8741\n",
            "Epoch 97/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2619 - accuracy: 0.8739\n",
            "Epoch 98/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2584 - accuracy: 0.8751\n",
            "Epoch 99/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2586 - accuracy: 0.8748\n",
            "Epoch 100/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2565 - accuracy: 0.8760\n",
            "1600/1600 [==============================] - 3s 2ms/step - loss: 0.8508 - accuracy: 0.8054\n",
            "Epoch 1/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.5079 - accuracy: 0.7553\n",
            "Epoch 2/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4892 - accuracy: 0.7677\n",
            "Epoch 3/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4864 - accuracy: 0.7696\n",
            "Epoch 4/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4838 - accuracy: 0.7705\n",
            "Epoch 5/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4815 - accuracy: 0.7707\n",
            "Epoch 6/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4801 - accuracy: 0.7715\n",
            "Epoch 7/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4779 - accuracy: 0.7733\n",
            "Epoch 8/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4771 - accuracy: 0.7736\n",
            "Epoch 9/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4755 - accuracy: 0.7732\n",
            "Epoch 10/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4735 - accuracy: 0.7740\n",
            "Epoch 11/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4713 - accuracy: 0.7751\n",
            "Epoch 12/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4693 - accuracy: 0.7756\n",
            "Epoch 13/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4670 - accuracy: 0.7765\n",
            "Epoch 14/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4643 - accuracy: 0.7773\n",
            "Epoch 15/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4626 - accuracy: 0.7785\n",
            "Epoch 16/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4596 - accuracy: 0.7796\n",
            "Epoch 17/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4567 - accuracy: 0.7819\n",
            "Epoch 18/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4527 - accuracy: 0.7832\n",
            "Epoch 19/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4490 - accuracy: 0.7846\n",
            "Epoch 20/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4450 - accuracy: 0.7880\n",
            "Epoch 21/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4409 - accuracy: 0.7903\n",
            "Epoch 22/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4372 - accuracy: 0.7909\n",
            "Epoch 23/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4318 - accuracy: 0.7943\n",
            "Epoch 24/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4275 - accuracy: 0.7956\n",
            "Epoch 25/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4227 - accuracy: 0.7980\n",
            "Epoch 26/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4178 - accuracy: 0.8007\n",
            "Epoch 27/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4137 - accuracy: 0.8025\n",
            "Epoch 28/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4094 - accuracy: 0.8040\n",
            "Epoch 29/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4049 - accuracy: 0.8069\n",
            "Epoch 30/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4002 - accuracy: 0.8083\n",
            "Epoch 31/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3951 - accuracy: 0.8119\n",
            "Epoch 32/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3909 - accuracy: 0.8128\n",
            "Epoch 33/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3865 - accuracy: 0.8147\n",
            "Epoch 34/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3826 - accuracy: 0.8178\n",
            "Epoch 35/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3780 - accuracy: 0.8189\n",
            "Epoch 36/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3742 - accuracy: 0.8217\n",
            "Epoch 37/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3704 - accuracy: 0.8219\n",
            "Epoch 38/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3656 - accuracy: 0.8249\n",
            "Epoch 39/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3637 - accuracy: 0.8257\n",
            "Epoch 40/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3589 - accuracy: 0.8287\n",
            "Epoch 41/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3557 - accuracy: 0.8292\n",
            "Epoch 42/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3533 - accuracy: 0.8301\n",
            "Epoch 43/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3500 - accuracy: 0.8321\n",
            "Epoch 44/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3461 - accuracy: 0.8346\n",
            "Epoch 45/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3435 - accuracy: 0.8356\n",
            "Epoch 46/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3412 - accuracy: 0.8358\n",
            "Epoch 47/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3376 - accuracy: 0.8373\n",
            "Epoch 48/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3352 - accuracy: 0.8389\n",
            "Epoch 49/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3330 - accuracy: 0.8397\n",
            "Epoch 50/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3301 - accuracy: 0.8412\n",
            "Epoch 51/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3273 - accuracy: 0.8437\n",
            "Epoch 52/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3250 - accuracy: 0.8442\n",
            "Epoch 53/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3231 - accuracy: 0.8456\n",
            "Epoch 54/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3208 - accuracy: 0.8457\n",
            "Epoch 55/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3177 - accuracy: 0.8477\n",
            "Epoch 56/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3163 - accuracy: 0.8486\n",
            "Epoch 57/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3144 - accuracy: 0.8490\n",
            "Epoch 58/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3129 - accuracy: 0.8500\n",
            "Epoch 59/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3096 - accuracy: 0.8504\n",
            "Epoch 60/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3088 - accuracy: 0.8520\n",
            "Epoch 61/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3066 - accuracy: 0.8524\n",
            "Epoch 62/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3044 - accuracy: 0.8538\n",
            "Epoch 63/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3034 - accuracy: 0.8542\n",
            "Epoch 64/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3005 - accuracy: 0.8552\n",
            "Epoch 65/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2981 - accuracy: 0.8555\n",
            "Epoch 66/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2986 - accuracy: 0.8566\n",
            "Epoch 67/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2957 - accuracy: 0.8588\n",
            "Epoch 68/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2936 - accuracy: 0.8592\n",
            "Epoch 69/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2926 - accuracy: 0.8591\n",
            "Epoch 70/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2910 - accuracy: 0.8614\n",
            "Epoch 71/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2891 - accuracy: 0.8608\n",
            "Epoch 72/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2869 - accuracy: 0.8623\n",
            "Epoch 73/100\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.2869 - accuracy: 0.8627\n",
            "Epoch 74/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2857 - accuracy: 0.8633\n",
            "Epoch 75/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2843 - accuracy: 0.8628\n",
            "Epoch 76/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2822 - accuracy: 0.8644\n",
            "Epoch 77/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2799 - accuracy: 0.8651\n",
            "Epoch 78/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2791 - accuracy: 0.8658\n",
            "Epoch 79/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2771 - accuracy: 0.8672\n",
            "Epoch 80/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2782 - accuracy: 0.8670\n",
            "Epoch 81/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2743 - accuracy: 0.8683\n",
            "Epoch 82/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2721 - accuracy: 0.8691\n",
            "Epoch 83/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2737 - accuracy: 0.8684\n",
            "Epoch 84/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2707 - accuracy: 0.8695\n",
            "Epoch 85/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2711 - accuracy: 0.8706\n",
            "Epoch 86/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2688 - accuracy: 0.8711\n",
            "Epoch 87/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2693 - accuracy: 0.8706\n",
            "Epoch 88/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2684 - accuracy: 0.8713\n",
            "Epoch 89/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2653 - accuracy: 0.8724\n",
            "Epoch 90/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2656 - accuracy: 0.8729\n",
            "Epoch 91/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2629 - accuracy: 0.8741\n",
            "Epoch 92/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2636 - accuracy: 0.8732\n",
            "Epoch 93/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2624 - accuracy: 0.8749\n",
            "Epoch 94/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2603 - accuracy: 0.8749\n",
            "Epoch 95/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2599 - accuracy: 0.8745\n",
            "Epoch 96/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2580 - accuracy: 0.8756\n",
            "Epoch 97/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2582 - accuracy: 0.8765\n",
            "Epoch 98/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2573 - accuracy: 0.8766\n",
            "Epoch 99/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2559 - accuracy: 0.8772\n",
            "Epoch 100/100\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2543 - accuracy: 0.8796\n",
            "1600/1600 [==============================] - 3s 2ms/step - loss: 0.8109 - accuracy: 0.8084\n",
            "Epoch 1/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.5109 - accuracy: 0.7534\n",
            "Epoch 2/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4905 - accuracy: 0.7676\n",
            "Epoch 3/150\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4884 - accuracy: 0.7690\n",
            "Epoch 4/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4857 - accuracy: 0.7695\n",
            "Epoch 5/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4840 - accuracy: 0.7705\n",
            "Epoch 6/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4819 - accuracy: 0.7715\n",
            "Epoch 7/150\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4806 - accuracy: 0.7720\n",
            "Epoch 8/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4785 - accuracy: 0.7725\n",
            "Epoch 9/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4765 - accuracy: 0.7737\n",
            "Epoch 10/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4752 - accuracy: 0.7744\n",
            "Epoch 11/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4728 - accuracy: 0.7749\n",
            "Epoch 12/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4711 - accuracy: 0.7756\n",
            "Epoch 13/150\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4683 - accuracy: 0.7771\n",
            "Epoch 14/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4654 - accuracy: 0.7772\n",
            "Epoch 15/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4622 - accuracy: 0.7784\n",
            "Epoch 16/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4598 - accuracy: 0.7802\n",
            "Epoch 17/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4565 - accuracy: 0.7819\n",
            "Epoch 18/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4528 - accuracy: 0.7829\n",
            "Epoch 19/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4497 - accuracy: 0.7849\n",
            "Epoch 20/150\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4464 - accuracy: 0.7859\n",
            "Epoch 21/150\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4425 - accuracy: 0.7875\n",
            "Epoch 22/150\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.4382 - accuracy: 0.7892\n",
            "Epoch 23/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4343 - accuracy: 0.7914\n",
            "Epoch 24/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4312 - accuracy: 0.7926\n",
            "Epoch 25/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4264 - accuracy: 0.7951\n",
            "Epoch 26/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4217 - accuracy: 0.7976\n",
            "Epoch 27/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4180 - accuracy: 0.7992\n",
            "Epoch 28/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4130 - accuracy: 0.8013\n",
            "Epoch 29/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4088 - accuracy: 0.8031\n",
            "Epoch 30/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4054 - accuracy: 0.8059\n",
            "Epoch 31/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4005 - accuracy: 0.8073\n",
            "Epoch 32/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3966 - accuracy: 0.8086\n",
            "Epoch 33/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3923 - accuracy: 0.8104\n",
            "Epoch 34/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3887 - accuracy: 0.8124\n",
            "Epoch 35/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3839 - accuracy: 0.8147\n",
            "Epoch 36/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3804 - accuracy: 0.8153\n",
            "Epoch 37/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3763 - accuracy: 0.8181\n",
            "Epoch 38/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3738 - accuracy: 0.8195\n",
            "Epoch 39/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3685 - accuracy: 0.8211\n",
            "Epoch 40/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3655 - accuracy: 0.8224\n",
            "Epoch 41/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3635 - accuracy: 0.8231\n",
            "Epoch 42/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3581 - accuracy: 0.8254\n",
            "Epoch 43/150\n",
            "1600/1600 [==============================] - 4s 3ms/step - loss: 0.3558 - accuracy: 0.8266\n",
            "Epoch 44/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3542 - accuracy: 0.8270\n",
            "Epoch 45/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3498 - accuracy: 0.8295\n",
            "Epoch 46/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3473 - accuracy: 0.8312\n",
            "Epoch 47/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3446 - accuracy: 0.8326\n",
            "Epoch 48/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3413 - accuracy: 0.8333\n",
            "Epoch 49/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3383 - accuracy: 0.8354\n",
            "Epoch 50/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3382 - accuracy: 0.8351\n",
            "Epoch 51/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3337 - accuracy: 0.8380\n",
            "Epoch 52/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3300 - accuracy: 0.8382\n",
            "Epoch 53/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3288 - accuracy: 0.8390\n",
            "Epoch 54/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3281 - accuracy: 0.8399\n",
            "Epoch 55/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3250 - accuracy: 0.8415\n",
            "Epoch 56/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3221 - accuracy: 0.8425\n",
            "Epoch 57/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3196 - accuracy: 0.8431\n",
            "Epoch 58/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3181 - accuracy: 0.8447\n",
            "Epoch 59/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3170 - accuracy: 0.8453\n",
            "Epoch 60/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3133 - accuracy: 0.8464\n",
            "Epoch 61/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3115 - accuracy: 0.8479\n",
            "Epoch 62/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3102 - accuracy: 0.8480\n",
            "Epoch 63/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3083 - accuracy: 0.8495\n",
            "Epoch 64/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3064 - accuracy: 0.8495\n",
            "Epoch 65/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3036 - accuracy: 0.8516\n",
            "Epoch 66/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3035 - accuracy: 0.8508\n",
            "Epoch 67/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3002 - accuracy: 0.8525\n",
            "Epoch 68/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2994 - accuracy: 0.8523\n",
            "Epoch 69/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2974 - accuracy: 0.8536\n",
            "Epoch 70/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2952 - accuracy: 0.8558\n",
            "Epoch 71/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2950 - accuracy: 0.8548\n",
            "Epoch 72/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2938 - accuracy: 0.8553\n",
            "Epoch 73/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2896 - accuracy: 0.8570\n",
            "Epoch 74/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2901 - accuracy: 0.8579\n",
            "Epoch 75/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2874 - accuracy: 0.8589\n",
            "Epoch 76/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2863 - accuracy: 0.8599\n",
            "Epoch 77/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2850 - accuracy: 0.8594\n",
            "Epoch 78/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2859 - accuracy: 0.8596\n",
            "Epoch 79/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2853 - accuracy: 0.8605\n",
            "Epoch 80/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2816 - accuracy: 0.8623\n",
            "Epoch 81/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2788 - accuracy: 0.8626\n",
            "Epoch 82/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2805 - accuracy: 0.8616\n",
            "Epoch 83/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2785 - accuracy: 0.8631\n",
            "Epoch 84/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2761 - accuracy: 0.8630\n",
            "Epoch 85/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2772 - accuracy: 0.8646\n",
            "Epoch 86/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2757 - accuracy: 0.8639\n",
            "Epoch 87/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2721 - accuracy: 0.8655\n",
            "Epoch 88/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2712 - accuracy: 0.8661\n",
            "Epoch 89/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2707 - accuracy: 0.8666\n",
            "Epoch 90/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2722 - accuracy: 0.8663\n",
            "Epoch 91/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2702 - accuracy: 0.8679\n",
            "Epoch 92/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2683 - accuracy: 0.8682\n",
            "Epoch 93/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2659 - accuracy: 0.8695\n",
            "Epoch 94/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2655 - accuracy: 0.8683\n",
            "Epoch 95/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2648 - accuracy: 0.8698\n",
            "Epoch 96/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2640 - accuracy: 0.8705\n",
            "Epoch 97/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2634 - accuracy: 0.8708\n",
            "Epoch 98/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2626 - accuracy: 0.8704\n",
            "Epoch 99/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2614 - accuracy: 0.8707\n",
            "Epoch 100/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2593 - accuracy: 0.8711\n",
            "Epoch 101/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2585 - accuracy: 0.8722\n",
            "Epoch 102/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2591 - accuracy: 0.8725\n",
            "Epoch 103/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2565 - accuracy: 0.8746\n",
            "Epoch 104/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2578 - accuracy: 0.8723\n",
            "Epoch 105/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2535 - accuracy: 0.8742\n",
            "Epoch 106/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2533 - accuracy: 0.8756\n",
            "Epoch 107/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2552 - accuracy: 0.8747\n",
            "Epoch 108/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2541 - accuracy: 0.8742\n",
            "Epoch 109/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2518 - accuracy: 0.8747\n",
            "Epoch 110/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2540 - accuracy: 0.8735\n",
            "Epoch 111/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2493 - accuracy: 0.8770\n",
            "Epoch 112/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2506 - accuracy: 0.8764\n",
            "Epoch 113/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2514 - accuracy: 0.8761\n",
            "Epoch 114/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2482 - accuracy: 0.8775\n",
            "Epoch 115/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2483 - accuracy: 0.8775\n",
            "Epoch 116/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2474 - accuracy: 0.8776\n",
            "Epoch 117/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2454 - accuracy: 0.8785\n",
            "Epoch 118/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2463 - accuracy: 0.8790\n",
            "Epoch 119/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2416 - accuracy: 0.8800\n",
            "Epoch 120/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2448 - accuracy: 0.8789\n",
            "Epoch 121/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2467 - accuracy: 0.8787\n",
            "Epoch 122/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2435 - accuracy: 0.8796\n",
            "Epoch 123/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2420 - accuracy: 0.8803\n",
            "Epoch 124/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2425 - accuracy: 0.8814\n",
            "Epoch 125/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2420 - accuracy: 0.8808\n",
            "Epoch 126/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2380 - accuracy: 0.8823\n",
            "Epoch 127/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2421 - accuracy: 0.8798\n",
            "Epoch 128/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2392 - accuracy: 0.8813\n",
            "Epoch 129/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2383 - accuracy: 0.8814\n",
            "Epoch 130/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2392 - accuracy: 0.8824\n",
            "Epoch 131/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2365 - accuracy: 0.8828\n",
            "Epoch 132/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2336 - accuracy: 0.8839\n",
            "Epoch 133/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2364 - accuracy: 0.8836\n",
            "Epoch 134/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2354 - accuracy: 0.8838\n",
            "Epoch 135/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2370 - accuracy: 0.8830\n",
            "Epoch 136/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2350 - accuracy: 0.8835\n",
            "Epoch 137/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2320 - accuracy: 0.8855\n",
            "Epoch 138/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2339 - accuracy: 0.8844\n",
            "Epoch 139/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2302 - accuracy: 0.8851\n",
            "Epoch 140/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2324 - accuracy: 0.8846\n",
            "Epoch 141/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2335 - accuracy: 0.8841\n",
            "Epoch 142/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2316 - accuracy: 0.8856\n",
            "Epoch 143/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2290 - accuracy: 0.8870\n",
            "Epoch 144/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2331 - accuracy: 0.8855\n",
            "Epoch 145/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2313 - accuracy: 0.8858\n",
            "Epoch 146/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2288 - accuracy: 0.8863\n",
            "Epoch 147/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2304 - accuracy: 0.8867\n",
            "Epoch 148/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2261 - accuracy: 0.8879\n",
            "Epoch 149/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2288 - accuracy: 0.8863\n",
            "Epoch 150/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2262 - accuracy: 0.8885\n",
            "1600/1600 [==============================] - 3s 2ms/step - loss: 1.0742 - accuracy: 0.8111\n",
            "Epoch 1/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.5080 - accuracy: 0.7555\n",
            "Epoch 2/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4887 - accuracy: 0.7687\n",
            "Epoch 3/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4862 - accuracy: 0.7702\n",
            "Epoch 4/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4840 - accuracy: 0.7710\n",
            "Epoch 5/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4817 - accuracy: 0.7715\n",
            "Epoch 6/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4798 - accuracy: 0.7723\n",
            "Epoch 7/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4782 - accuracy: 0.7725\n",
            "Epoch 8/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4764 - accuracy: 0.7736\n",
            "Epoch 9/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4755 - accuracy: 0.7750\n",
            "Epoch 10/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4733 - accuracy: 0.7748\n",
            "Epoch 11/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4711 - accuracy: 0.7755\n",
            "Epoch 12/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4693 - accuracy: 0.7762\n",
            "Epoch 13/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4667 - accuracy: 0.7775\n",
            "Epoch 14/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4651 - accuracy: 0.7776\n",
            "Epoch 15/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4620 - accuracy: 0.7784\n",
            "Epoch 16/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4596 - accuracy: 0.7798\n",
            "Epoch 17/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4559 - accuracy: 0.7811\n",
            "Epoch 18/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4524 - accuracy: 0.7829\n",
            "Epoch 19/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4493 - accuracy: 0.7844\n",
            "Epoch 20/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4461 - accuracy: 0.7857\n",
            "Epoch 21/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4432 - accuracy: 0.7868\n",
            "Epoch 22/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4389 - accuracy: 0.7889\n",
            "Epoch 23/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4351 - accuracy: 0.7911\n",
            "Epoch 24/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4312 - accuracy: 0.7924\n",
            "Epoch 25/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4264 - accuracy: 0.7951\n",
            "Epoch 26/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4226 - accuracy: 0.7964\n",
            "Epoch 27/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4181 - accuracy: 0.7991\n",
            "Epoch 28/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4140 - accuracy: 0.8017\n",
            "Epoch 29/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4097 - accuracy: 0.8024\n",
            "Epoch 30/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4052 - accuracy: 0.8052\n",
            "Epoch 31/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.4012 - accuracy: 0.8071\n",
            "Epoch 32/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3967 - accuracy: 0.8090\n",
            "Epoch 33/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3926 - accuracy: 0.8109\n",
            "Epoch 34/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3885 - accuracy: 0.8133\n",
            "Epoch 35/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3840 - accuracy: 0.8148\n",
            "Epoch 36/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3800 - accuracy: 0.8165\n",
            "Epoch 37/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3759 - accuracy: 0.8184\n",
            "Epoch 38/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3725 - accuracy: 0.8208\n",
            "Epoch 39/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3690 - accuracy: 0.8231\n",
            "Epoch 40/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3653 - accuracy: 0.8240\n",
            "Epoch 41/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3616 - accuracy: 0.8262\n",
            "Epoch 42/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3578 - accuracy: 0.8280\n",
            "Epoch 43/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3562 - accuracy: 0.8277\n",
            "Epoch 44/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3529 - accuracy: 0.8298\n",
            "Epoch 45/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3484 - accuracy: 0.8322\n",
            "Epoch 46/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3465 - accuracy: 0.8323\n",
            "Epoch 47/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3443 - accuracy: 0.8328\n",
            "Epoch 48/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3406 - accuracy: 0.8355\n",
            "Epoch 49/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3380 - accuracy: 0.8364\n",
            "Epoch 50/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3364 - accuracy: 0.8375\n",
            "Epoch 51/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3339 - accuracy: 0.8374\n",
            "Epoch 52/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3310 - accuracy: 0.8399\n",
            "Epoch 53/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3279 - accuracy: 0.8406\n",
            "Epoch 54/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3265 - accuracy: 0.8412\n",
            "Epoch 55/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3238 - accuracy: 0.8428\n",
            "Epoch 56/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3214 - accuracy: 0.8431\n",
            "Epoch 57/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3207 - accuracy: 0.8434\n",
            "Epoch 58/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3183 - accuracy: 0.8447\n",
            "Epoch 59/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3175 - accuracy: 0.8450\n",
            "Epoch 60/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3150 - accuracy: 0.8465\n",
            "Epoch 61/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3118 - accuracy: 0.8481\n",
            "Epoch 62/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3105 - accuracy: 0.8479\n",
            "Epoch 63/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3080 - accuracy: 0.8505\n",
            "Epoch 64/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3067 - accuracy: 0.8501\n",
            "Epoch 65/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3053 - accuracy: 0.8504\n",
            "Epoch 66/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3029 - accuracy: 0.8527\n",
            "Epoch 67/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3009 - accuracy: 0.8527\n",
            "Epoch 68/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.3011 - accuracy: 0.8528\n",
            "Epoch 69/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2976 - accuracy: 0.8537\n",
            "Epoch 70/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2968 - accuracy: 0.8550\n",
            "Epoch 71/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2954 - accuracy: 0.8554\n",
            "Epoch 72/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2941 - accuracy: 0.8559\n",
            "Epoch 73/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2935 - accuracy: 0.8567\n",
            "Epoch 74/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2909 - accuracy: 0.8576\n",
            "Epoch 75/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2883 - accuracy: 0.8590\n",
            "Epoch 76/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2888 - accuracy: 0.8586\n",
            "Epoch 77/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2871 - accuracy: 0.8591\n",
            "Epoch 78/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2863 - accuracy: 0.8597\n",
            "Epoch 79/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2837 - accuracy: 0.8606\n",
            "Epoch 80/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2844 - accuracy: 0.8605\n",
            "Epoch 81/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2821 - accuracy: 0.8614\n",
            "Epoch 82/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2802 - accuracy: 0.8617\n",
            "Epoch 83/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2807 - accuracy: 0.8619\n",
            "Epoch 84/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2782 - accuracy: 0.8630\n",
            "Epoch 85/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2790 - accuracy: 0.8628\n",
            "Epoch 86/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2764 - accuracy: 0.8640\n",
            "Epoch 87/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2741 - accuracy: 0.8644\n",
            "Epoch 88/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2741 - accuracy: 0.8643\n",
            "Epoch 89/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2731 - accuracy: 0.8652\n",
            "Epoch 90/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2729 - accuracy: 0.8654\n",
            "Epoch 91/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2712 - accuracy: 0.8663\n",
            "Epoch 92/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2700 - accuracy: 0.8673\n",
            "Epoch 93/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2694 - accuracy: 0.8678\n",
            "Epoch 94/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2677 - accuracy: 0.8683\n",
            "Epoch 95/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2654 - accuracy: 0.8683\n",
            "Epoch 96/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2667 - accuracy: 0.8684\n",
            "Epoch 97/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2647 - accuracy: 0.8693\n",
            "Epoch 98/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2635 - accuracy: 0.8692\n",
            "Epoch 99/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2636 - accuracy: 0.8704\n",
            "Epoch 100/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2634 - accuracy: 0.8698\n",
            "Epoch 101/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2613 - accuracy: 0.8700\n",
            "Epoch 102/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2626 - accuracy: 0.8701\n",
            "Epoch 103/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2583 - accuracy: 0.8721\n",
            "Epoch 104/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2600 - accuracy: 0.8709\n",
            "Epoch 105/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2575 - accuracy: 0.8721\n",
            "Epoch 106/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2559 - accuracy: 0.8725\n",
            "Epoch 107/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2584 - accuracy: 0.8725\n",
            "Epoch 108/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2546 - accuracy: 0.8741\n",
            "Epoch 109/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2559 - accuracy: 0.8737\n",
            "Epoch 110/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2545 - accuracy: 0.8727\n",
            "Epoch 111/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2515 - accuracy: 0.8738\n",
            "Epoch 112/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2542 - accuracy: 0.8735\n",
            "Epoch 113/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2527 - accuracy: 0.8748\n",
            "Epoch 114/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2515 - accuracy: 0.8757\n",
            "Epoch 115/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2499 - accuracy: 0.8753\n",
            "Epoch 116/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2504 - accuracy: 0.8756\n",
            "Epoch 117/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2502 - accuracy: 0.8760\n",
            "Epoch 118/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2487 - accuracy: 0.8759\n",
            "Epoch 119/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2468 - accuracy: 0.8773\n",
            "Epoch 120/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2482 - accuracy: 0.8768\n",
            "Epoch 121/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2462 - accuracy: 0.8781\n",
            "Epoch 122/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2471 - accuracy: 0.8776\n",
            "Epoch 123/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2463 - accuracy: 0.8772\n",
            "Epoch 124/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2451 - accuracy: 0.8770\n",
            "Epoch 125/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2435 - accuracy: 0.8786\n",
            "Epoch 126/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2454 - accuracy: 0.8783\n",
            "Epoch 127/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2443 - accuracy: 0.8784\n",
            "Epoch 128/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2422 - accuracy: 0.8798\n",
            "Epoch 129/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2411 - accuracy: 0.8800\n",
            "Epoch 130/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2407 - accuracy: 0.8800\n",
            "Epoch 131/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2415 - accuracy: 0.8794\n",
            "Epoch 132/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2402 - accuracy: 0.8798\n",
            "Epoch 133/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2367 - accuracy: 0.8816\n",
            "Epoch 134/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2386 - accuracy: 0.8810\n",
            "Epoch 135/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2410 - accuracy: 0.8803\n",
            "Epoch 136/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2386 - accuracy: 0.8818\n",
            "Epoch 137/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2363 - accuracy: 0.8821\n",
            "Epoch 138/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2351 - accuracy: 0.8823\n",
            "Epoch 139/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2364 - accuracy: 0.8819\n",
            "Epoch 140/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2344 - accuracy: 0.8831\n",
            "Epoch 141/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2369 - accuracy: 0.8823\n",
            "Epoch 142/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2331 - accuracy: 0.8829\n",
            "Epoch 143/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2389 - accuracy: 0.8817\n",
            "Epoch 144/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2325 - accuracy: 0.8841\n",
            "Epoch 145/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2326 - accuracy: 0.8835\n",
            "Epoch 146/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2328 - accuracy: 0.8838\n",
            "Epoch 147/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2299 - accuracy: 0.8848\n",
            "Epoch 148/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2294 - accuracy: 0.8849\n",
            "Epoch 149/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2328 - accuracy: 0.8841\n",
            "Epoch 150/150\n",
            "1600/1600 [==============================] - 5s 3ms/step - loss: 0.2282 - accuracy: 0.8867\n",
            "1600/1600 [==============================] - 3s 2ms/step - loss: 1.0415 - accuracy: 0.8119\n",
            "Epoch 1/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.5148 - accuracy: 0.7500\n",
            "Epoch 2/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4910 - accuracy: 0.7674\n",
            "Epoch 3/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4878 - accuracy: 0.7694\n",
            "Epoch 4/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4853 - accuracy: 0.7703\n",
            "Epoch 5/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4841 - accuracy: 0.7713\n",
            "Epoch 6/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4827 - accuracy: 0.7719\n",
            "Epoch 7/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4819 - accuracy: 0.7714\n",
            "Epoch 8/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4807 - accuracy: 0.7716\n",
            "Epoch 9/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4789 - accuracy: 0.7722\n",
            "Epoch 10/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4778 - accuracy: 0.7730\n",
            "Epoch 11/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4764 - accuracy: 0.7741\n",
            "Epoch 12/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4751 - accuracy: 0.7737\n",
            "Epoch 13/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4736 - accuracy: 0.7754\n",
            "Epoch 14/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4725 - accuracy: 0.7750\n",
            "Epoch 15/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4704 - accuracy: 0.7764\n",
            "Epoch 16/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4685 - accuracy: 0.7772\n",
            "Epoch 17/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4670 - accuracy: 0.7778\n",
            "Epoch 18/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4651 - accuracy: 0.7784\n",
            "Epoch 19/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4632 - accuracy: 0.7802\n",
            "Epoch 20/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4610 - accuracy: 0.7801\n",
            "Epoch 21/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4590 - accuracy: 0.7803\n",
            "Epoch 22/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4571 - accuracy: 0.7812\n",
            "Epoch 23/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4551 - accuracy: 0.7819\n",
            "Epoch 24/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4520 - accuracy: 0.7833\n",
            "Epoch 25/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4497 - accuracy: 0.7842\n",
            "Epoch 26/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4458 - accuracy: 0.7860\n",
            "Epoch 27/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4437 - accuracy: 0.7875\n",
            "Epoch 28/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4408 - accuracy: 0.7886\n",
            "Epoch 29/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4377 - accuracy: 0.7900\n",
            "Epoch 30/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4351 - accuracy: 0.7913\n",
            "Epoch 31/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4312 - accuracy: 0.7920\n",
            "Epoch 32/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4284 - accuracy: 0.7941\n",
            "Epoch 33/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4256 - accuracy: 0.7953\n",
            "Epoch 34/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4227 - accuracy: 0.7968\n",
            "Epoch 35/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4192 - accuracy: 0.7994\n",
            "Epoch 36/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4164 - accuracy: 0.8009\n",
            "Epoch 37/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4130 - accuracy: 0.8018\n",
            "Epoch 38/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4092 - accuracy: 0.8033\n",
            "Epoch 39/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4065 - accuracy: 0.8056\n",
            "Epoch 40/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4037 - accuracy: 0.8070\n",
            "Epoch 41/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3996 - accuracy: 0.8088\n",
            "Epoch 42/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3966 - accuracy: 0.8104\n",
            "Epoch 43/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3936 - accuracy: 0.8112\n",
            "Epoch 44/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3904 - accuracy: 0.8126\n",
            "Epoch 45/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3870 - accuracy: 0.8141\n",
            "Epoch 46/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3833 - accuracy: 0.8157\n",
            "Epoch 47/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3808 - accuracy: 0.8180\n",
            "Epoch 48/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3764 - accuracy: 0.8196\n",
            "Epoch 49/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3746 - accuracy: 0.8216\n",
            "Epoch 50/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3709 - accuracy: 0.8231\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.5016 - accuracy: 0.7891\n",
            "Epoch 1/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.5184 - accuracy: 0.7480\n",
            "Epoch 2/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4898 - accuracy: 0.7686\n",
            "Epoch 3/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4861 - accuracy: 0.7697\n",
            "Epoch 4/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4838 - accuracy: 0.7705\n",
            "Epoch 5/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4822 - accuracy: 0.7719\n",
            "Epoch 6/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4812 - accuracy: 0.7709\n",
            "Epoch 7/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4801 - accuracy: 0.7721\n",
            "Epoch 8/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4783 - accuracy: 0.7724\n",
            "Epoch 9/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4771 - accuracy: 0.7730\n",
            "Epoch 10/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4756 - accuracy: 0.7732\n",
            "Epoch 11/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4749 - accuracy: 0.7743\n",
            "Epoch 12/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4732 - accuracy: 0.7743\n",
            "Epoch 13/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4722 - accuracy: 0.7747\n",
            "Epoch 14/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4710 - accuracy: 0.7758\n",
            "Epoch 15/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4697 - accuracy: 0.7755\n",
            "Epoch 16/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4680 - accuracy: 0.7766\n",
            "Epoch 17/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4659 - accuracy: 0.7774\n",
            "Epoch 18/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4651 - accuracy: 0.7772\n",
            "Epoch 19/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4632 - accuracy: 0.7789\n",
            "Epoch 20/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4612 - accuracy: 0.7789\n",
            "Epoch 21/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4594 - accuracy: 0.7803\n",
            "Epoch 22/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4573 - accuracy: 0.7807\n",
            "Epoch 23/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4554 - accuracy: 0.7820\n",
            "Epoch 24/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4533 - accuracy: 0.7833\n",
            "Epoch 25/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4502 - accuracy: 0.7836\n",
            "Epoch 26/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4493 - accuracy: 0.7844\n",
            "Epoch 27/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4466 - accuracy: 0.7855\n",
            "Epoch 28/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4433 - accuracy: 0.7868\n",
            "Epoch 29/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4415 - accuracy: 0.7878\n",
            "Epoch 30/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4387 - accuracy: 0.7894\n",
            "Epoch 31/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4360 - accuracy: 0.7906\n",
            "Epoch 32/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4333 - accuracy: 0.7918\n",
            "Epoch 33/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4307 - accuracy: 0.7935\n",
            "Epoch 34/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4269 - accuracy: 0.7947\n",
            "Epoch 35/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4243 - accuracy: 0.7967\n",
            "Epoch 36/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4214 - accuracy: 0.7980\n",
            "Epoch 37/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4171 - accuracy: 0.8002\n",
            "Epoch 38/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4142 - accuracy: 0.8019\n",
            "Epoch 39/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4108 - accuracy: 0.8037\n",
            "Epoch 40/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4076 - accuracy: 0.8060\n",
            "Epoch 41/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4044 - accuracy: 0.8065\n",
            "Epoch 42/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4016 - accuracy: 0.8082\n",
            "Epoch 43/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3981 - accuracy: 0.8104\n",
            "Epoch 44/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3950 - accuracy: 0.8114\n",
            "Epoch 45/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3913 - accuracy: 0.8132\n",
            "Epoch 46/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3895 - accuracy: 0.8144\n",
            "Epoch 47/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3852 - accuracy: 0.8165\n",
            "Epoch 48/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3818 - accuracy: 0.8188\n",
            "Epoch 49/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3796 - accuracy: 0.8186\n",
            "Epoch 50/50\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3757 - accuracy: 0.8207\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.4943 - accuracy: 0.7873\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.5218 - accuracy: 0.7456\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4923 - accuracy: 0.7663\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4879 - accuracy: 0.7696\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4860 - accuracy: 0.7692\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4849 - accuracy: 0.7702\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4826 - accuracy: 0.7717\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4813 - accuracy: 0.7718\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4796 - accuracy: 0.7722\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4782 - accuracy: 0.7720\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4769 - accuracy: 0.7738\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4759 - accuracy: 0.7730\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4742 - accuracy: 0.7753\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4724 - accuracy: 0.7752\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4710 - accuracy: 0.7754\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4694 - accuracy: 0.7767\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4673 - accuracy: 0.7775\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4661 - accuracy: 0.7778\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4641 - accuracy: 0.7783\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4617 - accuracy: 0.7796\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4600 - accuracy: 0.7802\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4579 - accuracy: 0.7813\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4553 - accuracy: 0.7826\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4537 - accuracy: 0.7840\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4511 - accuracy: 0.7848\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4498 - accuracy: 0.7848\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4460 - accuracy: 0.7869\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4438 - accuracy: 0.7870\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4416 - accuracy: 0.7886\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4396 - accuracy: 0.7902\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4361 - accuracy: 0.7920\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4333 - accuracy: 0.7942\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4305 - accuracy: 0.7953\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4276 - accuracy: 0.7962\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4248 - accuracy: 0.7968\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4211 - accuracy: 0.7998\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4177 - accuracy: 0.8011\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4148 - accuracy: 0.8032\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4120 - accuracy: 0.8047\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4090 - accuracy: 0.8060\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4054 - accuracy: 0.8072\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4021 - accuracy: 0.8101\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4003 - accuracy: 0.8093\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3954 - accuracy: 0.8131\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3918 - accuracy: 0.8146\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3889 - accuracy: 0.8157\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3866 - accuracy: 0.8170\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3828 - accuracy: 0.8186\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3799 - accuracy: 0.8206\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3764 - accuracy: 0.8217\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3728 - accuracy: 0.8233\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3701 - accuracy: 0.8249\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3684 - accuracy: 0.8264\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3648 - accuracy: 0.8281\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3622 - accuracy: 0.8290\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3599 - accuracy: 0.8294\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3566 - accuracy: 0.8316\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3543 - accuracy: 0.8323\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3514 - accuracy: 0.8331\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3494 - accuracy: 0.8342\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3464 - accuracy: 0.8366\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3442 - accuracy: 0.8380\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3425 - accuracy: 0.8381\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3396 - accuracy: 0.8398\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3372 - accuracy: 0.8399\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3354 - accuracy: 0.8411\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3330 - accuracy: 0.8421\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3319 - accuracy: 0.8433\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3292 - accuracy: 0.8440\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3264 - accuracy: 0.8455\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3254 - accuracy: 0.8463\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3242 - accuracy: 0.8470\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3216 - accuracy: 0.8477\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3196 - accuracy: 0.8483\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3185 - accuracy: 0.8489\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3153 - accuracy: 0.8509\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3131 - accuracy: 0.8513\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3126 - accuracy: 0.8515\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3099 - accuracy: 0.8536\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3090 - accuracy: 0.8531\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3087 - accuracy: 0.8537\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3054 - accuracy: 0.8548\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3055 - accuracy: 0.8549\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3021 - accuracy: 0.8568\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3011 - accuracy: 0.8562\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2996 - accuracy: 0.8583\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2981 - accuracy: 0.8581\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2955 - accuracy: 0.8595\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2947 - accuracy: 0.8600\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2940 - accuracy: 0.8604\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2930 - accuracy: 0.8607\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2901 - accuracy: 0.8621\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2903 - accuracy: 0.8628\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2890 - accuracy: 0.8637\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2873 - accuracy: 0.8636\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2861 - accuracy: 0.8643\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2861 - accuracy: 0.8637\n",
            "Epoch 97/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2833 - accuracy: 0.8655\n",
            "Epoch 98/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2809 - accuracy: 0.8668\n",
            "Epoch 99/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2794 - accuracy: 0.8671\n",
            "Epoch 100/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2805 - accuracy: 0.8675\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.7543 - accuracy: 0.8049\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.5180 - accuracy: 0.7479\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4890 - accuracy: 0.7682\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4857 - accuracy: 0.7700\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4840 - accuracy: 0.7714\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4823 - accuracy: 0.7705\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4804 - accuracy: 0.7722\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4788 - accuracy: 0.7726\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4778 - accuracy: 0.7732\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4763 - accuracy: 0.7738\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4748 - accuracy: 0.7733\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4736 - accuracy: 0.7742\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4719 - accuracy: 0.7750\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4707 - accuracy: 0.7761\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4691 - accuracy: 0.7763\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4684 - accuracy: 0.7766\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4660 - accuracy: 0.7781\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4644 - accuracy: 0.7787\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4629 - accuracy: 0.7791\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4602 - accuracy: 0.7807\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4583 - accuracy: 0.7818\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4564 - accuracy: 0.7824\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4541 - accuracy: 0.7832\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4516 - accuracy: 0.7849\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4497 - accuracy: 0.7855\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4469 - accuracy: 0.7863\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4440 - accuracy: 0.7878\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4412 - accuracy: 0.7896\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4389 - accuracy: 0.7907\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4361 - accuracy: 0.7920\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4326 - accuracy: 0.7924\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4297 - accuracy: 0.7956\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4278 - accuracy: 0.7960\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4242 - accuracy: 0.7972\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4207 - accuracy: 0.7993\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4171 - accuracy: 0.8013\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4147 - accuracy: 0.8025\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4108 - accuracy: 0.8050\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4080 - accuracy: 0.8053\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4041 - accuracy: 0.8067\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4022 - accuracy: 0.8079\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3990 - accuracy: 0.8106\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3950 - accuracy: 0.8121\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3914 - accuracy: 0.8136\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3875 - accuracy: 0.8153\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3857 - accuracy: 0.8172\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3823 - accuracy: 0.8179\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3789 - accuracy: 0.8195\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3761 - accuracy: 0.8217\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3729 - accuracy: 0.8226\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3705 - accuracy: 0.8239\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3676 - accuracy: 0.8248\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3648 - accuracy: 0.8251\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3618 - accuracy: 0.8280\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3599 - accuracy: 0.8289\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3567 - accuracy: 0.8299\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3543 - accuracy: 0.8309\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3518 - accuracy: 0.8327\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3489 - accuracy: 0.8333\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3464 - accuracy: 0.8350\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3450 - accuracy: 0.8357\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3422 - accuracy: 0.8358\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3388 - accuracy: 0.8380\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3381 - accuracy: 0.8381\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3342 - accuracy: 0.8397\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3322 - accuracy: 0.8402\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3302 - accuracy: 0.8419\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3287 - accuracy: 0.8432\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3260 - accuracy: 0.8436\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3248 - accuracy: 0.8449\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3221 - accuracy: 0.8464\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3198 - accuracy: 0.8470\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3186 - accuracy: 0.8476\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3177 - accuracy: 0.8479\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3148 - accuracy: 0.8498\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3129 - accuracy: 0.8502\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3112 - accuracy: 0.8498\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3097 - accuracy: 0.8520\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3072 - accuracy: 0.8529\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3057 - accuracy: 0.8540\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3046 - accuracy: 0.8538\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3032 - accuracy: 0.8550\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3006 - accuracy: 0.8558\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2991 - accuracy: 0.8556\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2975 - accuracy: 0.8583\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2964 - accuracy: 0.8582\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2942 - accuracy: 0.8586\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2928 - accuracy: 0.8596\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2933 - accuracy: 0.8589\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2913 - accuracy: 0.8600\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2886 - accuracy: 0.8618\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2878 - accuracy: 0.8614\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2870 - accuracy: 0.8629\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2847 - accuracy: 0.8625\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2846 - accuracy: 0.8630\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2831 - accuracy: 0.8639\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2824 - accuracy: 0.8640\n",
            "Epoch 97/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2793 - accuracy: 0.8649\n",
            "Epoch 98/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2790 - accuracy: 0.8661\n",
            "Epoch 99/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2783 - accuracy: 0.8666\n",
            "Epoch 100/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2771 - accuracy: 0.8668\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.7446 - accuracy: 0.8063\n",
            "Epoch 1/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.5162 - accuracy: 0.7489\n",
            "Epoch 2/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4909 - accuracy: 0.7663\n",
            "Epoch 3/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4876 - accuracy: 0.7692\n",
            "Epoch 4/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4857 - accuracy: 0.7691\n",
            "Epoch 5/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4844 - accuracy: 0.7701\n",
            "Epoch 6/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4825 - accuracy: 0.7707\n",
            "Epoch 7/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4816 - accuracy: 0.7719\n",
            "Epoch 8/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4800 - accuracy: 0.7721\n",
            "Epoch 9/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4788 - accuracy: 0.7724\n",
            "Epoch 10/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4769 - accuracy: 0.7736\n",
            "Epoch 11/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4757 - accuracy: 0.7738\n",
            "Epoch 12/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4747 - accuracy: 0.7741\n",
            "Epoch 13/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4732 - accuracy: 0.7750\n",
            "Epoch 14/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4717 - accuracy: 0.7755\n",
            "Epoch 15/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4702 - accuracy: 0.7755\n",
            "Epoch 16/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4685 - accuracy: 0.7772\n",
            "Epoch 17/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4673 - accuracy: 0.7781\n",
            "Epoch 18/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4654 - accuracy: 0.7773\n",
            "Epoch 19/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4626 - accuracy: 0.7798\n",
            "Epoch 20/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4604 - accuracy: 0.7800\n",
            "Epoch 21/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4585 - accuracy: 0.7806\n",
            "Epoch 22/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4560 - accuracy: 0.7818\n",
            "Epoch 23/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4542 - accuracy: 0.7818\n",
            "Epoch 24/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4519 - accuracy: 0.7836\n",
            "Epoch 25/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4487 - accuracy: 0.7843\n",
            "Epoch 26/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4459 - accuracy: 0.7861\n",
            "Epoch 27/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4435 - accuracy: 0.7873\n",
            "Epoch 28/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4407 - accuracy: 0.7886\n",
            "Epoch 29/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4368 - accuracy: 0.7897\n",
            "Epoch 30/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4345 - accuracy: 0.7915\n",
            "Epoch 31/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4313 - accuracy: 0.7929\n",
            "Epoch 32/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4281 - accuracy: 0.7943\n",
            "Epoch 33/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4249 - accuracy: 0.7955\n",
            "Epoch 34/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4211 - accuracy: 0.7975\n",
            "Epoch 35/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4179 - accuracy: 0.7987\n",
            "Epoch 36/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4144 - accuracy: 0.8006\n",
            "Epoch 37/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4109 - accuracy: 0.8028\n",
            "Epoch 38/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4073 - accuracy: 0.8044\n",
            "Epoch 39/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4042 - accuracy: 0.8071\n",
            "Epoch 40/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4003 - accuracy: 0.8083\n",
            "Epoch 41/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3967 - accuracy: 0.8106\n",
            "Epoch 42/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3940 - accuracy: 0.8120\n",
            "Epoch 43/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3897 - accuracy: 0.8140\n",
            "Epoch 44/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3871 - accuracy: 0.8152\n",
            "Epoch 45/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3831 - accuracy: 0.8176\n",
            "Epoch 46/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3811 - accuracy: 0.8183\n",
            "Epoch 47/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3758 - accuracy: 0.8207\n",
            "Epoch 48/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3730 - accuracy: 0.8214\n",
            "Epoch 49/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3706 - accuracy: 0.8243\n",
            "Epoch 50/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3673 - accuracy: 0.8250\n",
            "Epoch 51/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3644 - accuracy: 0.8270\n",
            "Epoch 52/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3620 - accuracy: 0.8274\n",
            "Epoch 53/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3582 - accuracy: 0.8294\n",
            "Epoch 54/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3547 - accuracy: 0.8317\n",
            "Epoch 55/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3533 - accuracy: 0.8323\n",
            "Epoch 56/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3491 - accuracy: 0.8343\n",
            "Epoch 57/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3470 - accuracy: 0.8353\n",
            "Epoch 58/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3454 - accuracy: 0.8355\n",
            "Epoch 59/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3419 - accuracy: 0.8377\n",
            "Epoch 60/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3399 - accuracy: 0.8388\n",
            "Epoch 61/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3363 - accuracy: 0.8395\n",
            "Epoch 62/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3339 - accuracy: 0.8415\n",
            "Epoch 63/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3314 - accuracy: 0.8435\n",
            "Epoch 64/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3298 - accuracy: 0.8435\n",
            "Epoch 65/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3272 - accuracy: 0.8457\n",
            "Epoch 66/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3242 - accuracy: 0.8462\n",
            "Epoch 67/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3221 - accuracy: 0.8470\n",
            "Epoch 68/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3200 - accuracy: 0.8482\n",
            "Epoch 69/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3185 - accuracy: 0.8490\n",
            "Epoch 70/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3169 - accuracy: 0.8506\n",
            "Epoch 71/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3138 - accuracy: 0.8523\n",
            "Epoch 72/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3128 - accuracy: 0.8515\n",
            "Epoch 73/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3106 - accuracy: 0.8533\n",
            "Epoch 74/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3098 - accuracy: 0.8534\n",
            "Epoch 75/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3078 - accuracy: 0.8534\n",
            "Epoch 76/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3055 - accuracy: 0.8547\n",
            "Epoch 77/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3036 - accuracy: 0.8561\n",
            "Epoch 78/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3025 - accuracy: 0.8561\n",
            "Epoch 79/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3017 - accuracy: 0.8569\n",
            "Epoch 80/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2988 - accuracy: 0.8582\n",
            "Epoch 81/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2976 - accuracy: 0.8574\n",
            "Epoch 82/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2962 - accuracy: 0.8592\n",
            "Epoch 83/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2947 - accuracy: 0.8598\n",
            "Epoch 84/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2933 - accuracy: 0.8611\n",
            "Epoch 85/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2927 - accuracy: 0.8619\n",
            "Epoch 86/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2910 - accuracy: 0.8614\n",
            "Epoch 87/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2900 - accuracy: 0.8623\n",
            "Epoch 88/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2864 - accuracy: 0.8634\n",
            "Epoch 89/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2871 - accuracy: 0.8638\n",
            "Epoch 90/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2857 - accuracy: 0.8647\n",
            "Epoch 91/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2826 - accuracy: 0.8649\n",
            "Epoch 92/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2818 - accuracy: 0.8667\n",
            "Epoch 93/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2819 - accuracy: 0.8661\n",
            "Epoch 94/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2805 - accuracy: 0.8673\n",
            "Epoch 95/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2783 - accuracy: 0.8680\n",
            "Epoch 96/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2784 - accuracy: 0.8680\n",
            "Epoch 97/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2759 - accuracy: 0.8685\n",
            "Epoch 98/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2765 - accuracy: 0.8690\n",
            "Epoch 99/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2747 - accuracy: 0.8703\n",
            "Epoch 100/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2728 - accuracy: 0.8697\n",
            "Epoch 101/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2708 - accuracy: 0.8710\n",
            "Epoch 102/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2687 - accuracy: 0.8728\n",
            "Epoch 103/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2711 - accuracy: 0.8717\n",
            "Epoch 104/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2688 - accuracy: 0.8711\n",
            "Epoch 105/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2671 - accuracy: 0.8734\n",
            "Epoch 106/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2643 - accuracy: 0.8742\n",
            "Epoch 107/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2653 - accuracy: 0.8736\n",
            "Epoch 108/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2629 - accuracy: 0.8756\n",
            "Epoch 109/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2648 - accuracy: 0.8745\n",
            "Epoch 110/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2631 - accuracy: 0.8749\n",
            "Epoch 111/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2616 - accuracy: 0.8763\n",
            "Epoch 112/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2591 - accuracy: 0.8766\n",
            "Epoch 113/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2579 - accuracy: 0.8773\n",
            "Epoch 114/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2606 - accuracy: 0.8765\n",
            "Epoch 115/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2556 - accuracy: 0.8794\n",
            "Epoch 116/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2562 - accuracy: 0.8789\n",
            "Epoch 117/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2546 - accuracy: 0.8790\n",
            "Epoch 118/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2565 - accuracy: 0.8784\n",
            "Epoch 119/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2540 - accuracy: 0.8794\n",
            "Epoch 120/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2523 - accuracy: 0.8809\n",
            "Epoch 121/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2530 - accuracy: 0.8803\n",
            "Epoch 122/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2494 - accuracy: 0.8815\n",
            "Epoch 123/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2514 - accuracy: 0.8817\n",
            "Epoch 124/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2509 - accuracy: 0.8810\n",
            "Epoch 125/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2493 - accuracy: 0.8827\n",
            "Epoch 126/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2467 - accuracy: 0.8826\n",
            "Epoch 127/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2481 - accuracy: 0.8823\n",
            "Epoch 128/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2462 - accuracy: 0.8832\n",
            "Epoch 129/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2444 - accuracy: 0.8835\n",
            "Epoch 130/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2454 - accuracy: 0.8831\n",
            "Epoch 131/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2420 - accuracy: 0.8857\n",
            "Epoch 132/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2409 - accuracy: 0.8849\n",
            "Epoch 133/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2450 - accuracy: 0.8845\n",
            "Epoch 134/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2404 - accuracy: 0.8861\n",
            "Epoch 135/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2423 - accuracy: 0.8854\n",
            "Epoch 136/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2409 - accuracy: 0.8855\n",
            "Epoch 137/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2401 - accuracy: 0.8857\n",
            "Epoch 138/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2368 - accuracy: 0.8880\n",
            "Epoch 139/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2367 - accuracy: 0.8874\n",
            "Epoch 140/150\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.2402 - accuracy: 0.8861\n",
            "Epoch 141/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2370 - accuracy: 0.8877\n",
            "Epoch 142/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2337 - accuracy: 0.8892\n",
            "Epoch 143/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2339 - accuracy: 0.8882\n",
            "Epoch 144/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2357 - accuracy: 0.8887\n",
            "Epoch 145/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2365 - accuracy: 0.8884\n",
            "Epoch 146/150\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2324 - accuracy: 0.8901\n",
            "Epoch 147/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2311 - accuracy: 0.8900\n",
            "Epoch 148/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2325 - accuracy: 0.8895\n",
            "Epoch 149/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2318 - accuracy: 0.8900\n",
            "Epoch 150/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2302 - accuracy: 0.8905\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.0733 - accuracy: 0.8100\n",
            "Epoch 1/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.5136 - accuracy: 0.7515\n",
            "Epoch 2/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4891 - accuracy: 0.7685\n",
            "Epoch 3/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4863 - accuracy: 0.7697\n",
            "Epoch 4/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4834 - accuracy: 0.7710\n",
            "Epoch 5/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4815 - accuracy: 0.7719\n",
            "Epoch 6/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4802 - accuracy: 0.7719\n",
            "Epoch 7/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4789 - accuracy: 0.7724\n",
            "Epoch 8/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4776 - accuracy: 0.7732\n",
            "Epoch 9/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4761 - accuracy: 0.7738\n",
            "Epoch 10/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4750 - accuracy: 0.7738\n",
            "Epoch 11/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4739 - accuracy: 0.7740\n",
            "Epoch 12/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4724 - accuracy: 0.7751\n",
            "Epoch 13/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4709 - accuracy: 0.7751\n",
            "Epoch 14/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4693 - accuracy: 0.7767\n",
            "Epoch 15/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4679 - accuracy: 0.7770\n",
            "Epoch 16/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4662 - accuracy: 0.7771\n",
            "Epoch 17/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4643 - accuracy: 0.7781\n",
            "Epoch 18/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4627 - accuracy: 0.7785\n",
            "Epoch 19/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4602 - accuracy: 0.7801\n",
            "Epoch 20/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4591 - accuracy: 0.7803\n",
            "Epoch 21/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4570 - accuracy: 0.7801\n",
            "Epoch 22/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4547 - accuracy: 0.7824\n",
            "Epoch 23/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4528 - accuracy: 0.7832\n",
            "Epoch 24/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4499 - accuracy: 0.7851\n",
            "Epoch 25/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4476 - accuracy: 0.7848\n",
            "Epoch 26/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4451 - accuracy: 0.7864\n",
            "Epoch 27/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4429 - accuracy: 0.7874\n",
            "Epoch 28/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4394 - accuracy: 0.7883\n",
            "Epoch 29/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4379 - accuracy: 0.7896\n",
            "Epoch 30/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4343 - accuracy: 0.7916\n",
            "Epoch 31/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4316 - accuracy: 0.7917\n",
            "Epoch 32/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4295 - accuracy: 0.7939\n",
            "Epoch 33/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4267 - accuracy: 0.7947\n",
            "Epoch 34/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4238 - accuracy: 0.7965\n",
            "Epoch 35/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4211 - accuracy: 0.7963\n",
            "Epoch 36/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4182 - accuracy: 0.7985\n",
            "Epoch 37/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4153 - accuracy: 0.8003\n",
            "Epoch 38/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4123 - accuracy: 0.8014\n",
            "Epoch 39/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4091 - accuracy: 0.8023\n",
            "Epoch 40/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4061 - accuracy: 0.8044\n",
            "Epoch 41/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.4033 - accuracy: 0.8055\n",
            "Epoch 42/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.4000 - accuracy: 0.8064\n",
            "Epoch 43/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3979 - accuracy: 0.8087\n",
            "Epoch 44/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3936 - accuracy: 0.8096\n",
            "Epoch 45/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3908 - accuracy: 0.8110\n",
            "Epoch 46/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3876 - accuracy: 0.8129\n",
            "Epoch 47/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3852 - accuracy: 0.8135\n",
            "Epoch 48/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3819 - accuracy: 0.8157\n",
            "Epoch 49/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3793 - accuracy: 0.8175\n",
            "Epoch 50/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3763 - accuracy: 0.8185\n",
            "Epoch 51/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3741 - accuracy: 0.8190\n",
            "Epoch 52/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3701 - accuracy: 0.8214\n",
            "Epoch 53/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3684 - accuracy: 0.8221\n",
            "Epoch 54/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3663 - accuracy: 0.8225\n",
            "Epoch 55/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3631 - accuracy: 0.8242\n",
            "Epoch 56/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3607 - accuracy: 0.8256\n",
            "Epoch 57/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3577 - accuracy: 0.8277\n",
            "Epoch 58/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3553 - accuracy: 0.8283\n",
            "Epoch 59/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3537 - accuracy: 0.8289\n",
            "Epoch 60/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3496 - accuracy: 0.8300\n",
            "Epoch 61/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3487 - accuracy: 0.8316\n",
            "Epoch 62/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3461 - accuracy: 0.8327\n",
            "Epoch 63/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.3428 - accuracy: 0.8335\n",
            "Epoch 64/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.3406 - accuracy: 0.8345\n",
            "Epoch 65/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.3391 - accuracy: 0.8361\n",
            "Epoch 66/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3364 - accuracy: 0.8375\n",
            "Epoch 67/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.3349 - accuracy: 0.8373\n",
            "Epoch 68/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.3326 - accuracy: 0.8381\n",
            "Epoch 69/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3303 - accuracy: 0.8386\n",
            "Epoch 70/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3286 - accuracy: 0.8401\n",
            "Epoch 71/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3271 - accuracy: 0.8417\n",
            "Epoch 72/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3246 - accuracy: 0.8424\n",
            "Epoch 73/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3219 - accuracy: 0.8428\n",
            "Epoch 74/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3216 - accuracy: 0.8438\n",
            "Epoch 75/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3191 - accuracy: 0.8440\n",
            "Epoch 76/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.3182 - accuracy: 0.8452\n",
            "Epoch 77/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3173 - accuracy: 0.8461\n",
            "Epoch 78/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3143 - accuracy: 0.8466\n",
            "Epoch 79/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3121 - accuracy: 0.8474\n",
            "Epoch 80/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3102 - accuracy: 0.8485\n",
            "Epoch 81/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3090 - accuracy: 0.8492\n",
            "Epoch 82/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.3069 - accuracy: 0.8504\n",
            "Epoch 83/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3052 - accuracy: 0.8509\n",
            "Epoch 84/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.3049 - accuracy: 0.8508\n",
            "Epoch 85/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3043 - accuracy: 0.8508\n",
            "Epoch 86/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3028 - accuracy: 0.8512\n",
            "Epoch 87/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.3007 - accuracy: 0.8524\n",
            "Epoch 88/150\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2998 - accuracy: 0.8537\n",
            "Epoch 89/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2969 - accuracy: 0.8538\n",
            "Epoch 90/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2960 - accuracy: 0.8545\n",
            "Epoch 91/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2945 - accuracy: 0.8554\n",
            "Epoch 92/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2945 - accuracy: 0.8551\n",
            "Epoch 93/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2935 - accuracy: 0.8561\n",
            "Epoch 94/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2921 - accuracy: 0.8566\n",
            "Epoch 95/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2900 - accuracy: 0.8573\n",
            "Epoch 96/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2883 - accuracy: 0.8581\n",
            "Epoch 97/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2880 - accuracy: 0.8575\n",
            "Epoch 98/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2851 - accuracy: 0.8592\n",
            "Epoch 99/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2884 - accuracy: 0.8583\n",
            "Epoch 100/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2847 - accuracy: 0.8590\n",
            "Epoch 101/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2849 - accuracy: 0.8593\n",
            "Epoch 102/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2828 - accuracy: 0.8602\n",
            "Epoch 103/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2804 - accuracy: 0.8615\n",
            "Epoch 104/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2817 - accuracy: 0.8603\n",
            "Epoch 105/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2794 - accuracy: 0.8617\n",
            "Epoch 106/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2783 - accuracy: 0.8627\n",
            "Epoch 107/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2778 - accuracy: 0.8625\n",
            "Epoch 108/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2777 - accuracy: 0.8633\n",
            "Epoch 109/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2761 - accuracy: 0.8634\n",
            "Epoch 110/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2749 - accuracy: 0.8642\n",
            "Epoch 111/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2727 - accuracy: 0.8646\n",
            "Epoch 112/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2752 - accuracy: 0.8642\n",
            "Epoch 113/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2720 - accuracy: 0.8655\n",
            "Epoch 114/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2719 - accuracy: 0.8656\n",
            "Epoch 115/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2715 - accuracy: 0.8667\n",
            "Epoch 116/150\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2698 - accuracy: 0.8665\n",
            "Epoch 117/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2685 - accuracy: 0.8674\n",
            "Epoch 118/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2677 - accuracy: 0.8672\n",
            "Epoch 119/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2664 - accuracy: 0.8672\n",
            "Epoch 120/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2629 - accuracy: 0.8689\n",
            "Epoch 121/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2656 - accuracy: 0.8682\n",
            "Epoch 122/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2646 - accuracy: 0.8685\n",
            "Epoch 123/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2631 - accuracy: 0.8691\n",
            "Epoch 124/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2619 - accuracy: 0.8700\n",
            "Epoch 125/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2639 - accuracy: 0.8692\n",
            "Epoch 126/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2632 - accuracy: 0.8703\n",
            "Epoch 127/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2596 - accuracy: 0.8715\n",
            "Epoch 128/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2603 - accuracy: 0.8702\n",
            "Epoch 129/150\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2574 - accuracy: 0.8717\n",
            "Epoch 130/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2611 - accuracy: 0.8705\n",
            "Epoch 131/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2576 - accuracy: 0.8713\n",
            "Epoch 132/150\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2560 - accuracy: 0.8727\n",
            "Epoch 133/150\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2565 - accuracy: 0.8730\n",
            "Epoch 134/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2588 - accuracy: 0.8733\n",
            "Epoch 135/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2565 - accuracy: 0.8734\n",
            "Epoch 136/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2533 - accuracy: 0.8742\n",
            "Epoch 137/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2509 - accuracy: 0.8747\n",
            "Epoch 138/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2542 - accuracy: 0.8736\n",
            "Epoch 139/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2548 - accuracy: 0.8733\n",
            "Epoch 140/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2521 - accuracy: 0.8752\n",
            "Epoch 141/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2512 - accuracy: 0.8754\n",
            "Epoch 142/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2511 - accuracy: 0.8749\n",
            "Epoch 143/150\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.2496 - accuracy: 0.8749\n",
            "Epoch 144/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2498 - accuracy: 0.8754\n",
            "Epoch 145/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2494 - accuracy: 0.8759\n",
            "Epoch 146/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2475 - accuracy: 0.8766\n",
            "Epoch 147/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2474 - accuracy: 0.8765\n",
            "Epoch 148/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2429 - accuracy: 0.8787\n",
            "Epoch 149/150\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2475 - accuracy: 0.8764\n",
            "Epoch 150/150\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.2440 - accuracy: 0.8781\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.9597 - accuracy: 0.8091\n",
            "Epoch 1/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.4988 - accuracy: 0.7620\n",
            "Epoch 2/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.4884 - accuracy: 0.7685\n",
            "Epoch 3/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.4856 - accuracy: 0.7700\n",
            "Epoch 4/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.4819 - accuracy: 0.7710\n",
            "Epoch 5/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.4790 - accuracy: 0.7716\n",
            "Epoch 6/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.4748 - accuracy: 0.7729\n",
            "Epoch 7/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.4696 - accuracy: 0.7755\n",
            "Epoch 8/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.4641 - accuracy: 0.7770\n",
            "Epoch 9/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.4575 - accuracy: 0.7801\n",
            "Epoch 10/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.4497 - accuracy: 0.7844\n",
            "Epoch 11/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.4418 - accuracy: 0.7891\n",
            "Epoch 12/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.4335 - accuracy: 0.7928\n",
            "Epoch 13/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.4260 - accuracy: 0.7966\n",
            "Epoch 14/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.4182 - accuracy: 0.8013\n",
            "Epoch 15/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.4111 - accuracy: 0.8045\n",
            "Epoch 16/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.4050 - accuracy: 0.8089\n",
            "Epoch 17/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3992 - accuracy: 0.8111\n",
            "Epoch 18/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3932 - accuracy: 0.8139\n",
            "Epoch 19/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3884 - accuracy: 0.8173\n",
            "Epoch 20/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3835 - accuracy: 0.8194\n",
            "Epoch 21/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3796 - accuracy: 0.8220\n",
            "Epoch 22/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3745 - accuracy: 0.8235\n",
            "Epoch 23/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3707 - accuracy: 0.8260\n",
            "Epoch 24/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3670 - accuracy: 0.8282\n",
            "Epoch 25/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3634 - accuracy: 0.8305\n",
            "Epoch 26/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3604 - accuracy: 0.8318\n",
            "Epoch 27/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3574 - accuracy: 0.8327\n",
            "Epoch 28/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3538 - accuracy: 0.8353\n",
            "Epoch 29/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3517 - accuracy: 0.8361\n",
            "Epoch 30/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3493 - accuracy: 0.8370\n",
            "Epoch 31/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3458 - accuracy: 0.8394\n",
            "Epoch 32/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3450 - accuracy: 0.8397\n",
            "Epoch 33/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3426 - accuracy: 0.8407\n",
            "Epoch 34/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3397 - accuracy: 0.8424\n",
            "Epoch 35/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3375 - accuracy: 0.8432\n",
            "Epoch 36/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3354 - accuracy: 0.8441\n",
            "Epoch 37/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3339 - accuracy: 0.8451\n",
            "Epoch 38/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3331 - accuracy: 0.8460\n",
            "Epoch 39/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3304 - accuracy: 0.8467\n",
            "Epoch 40/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3294 - accuracy: 0.8475\n",
            "Epoch 41/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3274 - accuracy: 0.8485\n",
            "Epoch 42/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3252 - accuracy: 0.8497\n",
            "Epoch 43/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3245 - accuracy: 0.8502\n",
            "Epoch 44/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3231 - accuracy: 0.8511\n",
            "Epoch 45/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3219 - accuracy: 0.8520\n",
            "Epoch 46/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3204 - accuracy: 0.8523\n",
            "Epoch 47/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3189 - accuracy: 0.8524\n",
            "Epoch 48/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3182 - accuracy: 0.8539\n",
            "Epoch 49/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3162 - accuracy: 0.8545\n",
            "Epoch 50/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3155 - accuracy: 0.8553\n",
            "Epoch 51/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3134 - accuracy: 0.8558\n",
            "Epoch 52/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3131 - accuracy: 0.8556\n",
            "Epoch 53/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3122 - accuracy: 0.8559\n",
            "Epoch 54/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3108 - accuracy: 0.8574\n",
            "Epoch 55/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3098 - accuracy: 0.8583\n",
            "Epoch 56/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3082 - accuracy: 0.8586\n",
            "Epoch 57/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3085 - accuracy: 0.8590\n",
            "Epoch 58/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3067 - accuracy: 0.8598\n",
            "Epoch 59/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3056 - accuracy: 0.8603\n",
            "Epoch 60/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3046 - accuracy: 0.8599\n",
            "Epoch 61/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3042 - accuracy: 0.8606\n",
            "Epoch 62/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3035 - accuracy: 0.8616\n",
            "Epoch 63/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.3013 - accuracy: 0.8615\n",
            "Epoch 64/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3017 - accuracy: 0.8625\n",
            "Epoch 65/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.3012 - accuracy: 0.8623\n",
            "Epoch 66/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2999 - accuracy: 0.8632\n",
            "Epoch 67/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2994 - accuracy: 0.8632\n",
            "Epoch 68/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2973 - accuracy: 0.8642\n",
            "Epoch 69/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2987 - accuracy: 0.8634\n",
            "Epoch 70/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2975 - accuracy: 0.8640\n",
            "Epoch 71/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2963 - accuracy: 0.8648\n",
            "Epoch 72/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2966 - accuracy: 0.8653\n",
            "Epoch 73/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2959 - accuracy: 0.8645\n",
            "Epoch 74/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2941 - accuracy: 0.8658\n",
            "Epoch 75/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2938 - accuracy: 0.8655\n",
            "Epoch 76/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2926 - accuracy: 0.8662\n",
            "Epoch 77/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2934 - accuracy: 0.8664\n",
            "Epoch 78/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2928 - accuracy: 0.8663\n",
            "Epoch 79/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2911 - accuracy: 0.8677\n",
            "Epoch 80/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2913 - accuracy: 0.8676\n",
            "Epoch 81/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2899 - accuracy: 0.8675\n",
            "Epoch 82/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2906 - accuracy: 0.8680\n",
            "Epoch 83/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2896 - accuracy: 0.8680\n",
            "Epoch 84/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2878 - accuracy: 0.8685\n",
            "Epoch 85/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2881 - accuracy: 0.8688\n",
            "Epoch 86/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2880 - accuracy: 0.8685\n",
            "Epoch 87/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2863 - accuracy: 0.8693\n",
            "Epoch 88/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2856 - accuracy: 0.8697\n",
            "Epoch 89/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2866 - accuracy: 0.8695\n",
            "Epoch 90/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2854 - accuracy: 0.8696\n",
            "Epoch 91/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2851 - accuracy: 0.8703\n",
            "Epoch 92/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2840 - accuracy: 0.8704\n",
            "Epoch 93/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2850 - accuracy: 0.8704\n",
            "Epoch 94/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2834 - accuracy: 0.8709\n",
            "Epoch 95/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2827 - accuracy: 0.8710\n",
            "Epoch 96/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2815 - accuracy: 0.8721\n",
            "Epoch 97/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2822 - accuracy: 0.8711\n",
            "Epoch 98/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2832 - accuracy: 0.8716\n",
            "Epoch 99/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2811 - accuracy: 0.8728\n",
            "Epoch 100/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2808 - accuracy: 0.8723\n",
            "Epoch 101/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2815 - accuracy: 0.8727\n",
            "Epoch 102/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2805 - accuracy: 0.8728\n",
            "Epoch 103/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2786 - accuracy: 0.8728\n",
            "Epoch 104/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2789 - accuracy: 0.8735\n",
            "Epoch 105/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2786 - accuracy: 0.8733\n",
            "Epoch 106/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2775 - accuracy: 0.8732\n",
            "Epoch 107/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2768 - accuracy: 0.8744\n",
            "Epoch 108/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2778 - accuracy: 0.8738\n",
            "Epoch 109/150\n",
            "6397/6397 [==============================] - 20s 3ms/step - loss: 0.2780 - accuracy: 0.8744\n",
            "Epoch 110/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2762 - accuracy: 0.8748\n",
            "Epoch 111/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2767 - accuracy: 0.8746\n",
            "Epoch 112/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2767 - accuracy: 0.8744\n",
            "Epoch 113/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2754 - accuracy: 0.8747\n",
            "Epoch 114/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2756 - accuracy: 0.8753\n",
            "Epoch 115/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2767 - accuracy: 0.8746\n",
            "Epoch 116/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2746 - accuracy: 0.8753\n",
            "Epoch 117/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2735 - accuracy: 0.8763\n",
            "Epoch 118/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2736 - accuracy: 0.8756\n",
            "Epoch 119/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2738 - accuracy: 0.8750\n",
            "Epoch 120/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2734 - accuracy: 0.8762\n",
            "Epoch 121/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2739 - accuracy: 0.8763\n",
            "Epoch 122/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2725 - accuracy: 0.8767\n",
            "Epoch 123/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2725 - accuracy: 0.8759\n",
            "Epoch 124/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2715 - accuracy: 0.8769\n",
            "Epoch 125/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2717 - accuracy: 0.8768\n",
            "Epoch 126/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2717 - accuracy: 0.8769\n",
            "Epoch 127/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2704 - accuracy: 0.8770\n",
            "Epoch 128/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2712 - accuracy: 0.8774\n",
            "Epoch 129/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2710 - accuracy: 0.8775\n",
            "Epoch 130/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2702 - accuracy: 0.8775\n",
            "Epoch 131/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2710 - accuracy: 0.8776\n",
            "Epoch 132/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2696 - accuracy: 0.8782\n",
            "Epoch 133/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2694 - accuracy: 0.8783\n",
            "Epoch 134/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2689 - accuracy: 0.8778\n",
            "Epoch 135/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2686 - accuracy: 0.8782\n",
            "Epoch 136/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2688 - accuracy: 0.8781\n",
            "Epoch 137/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2684 - accuracy: 0.8789\n",
            "Epoch 138/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2692 - accuracy: 0.8780\n",
            "Epoch 139/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2693 - accuracy: 0.8786\n",
            "Epoch 140/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2677 - accuracy: 0.8788\n",
            "Epoch 141/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2666 - accuracy: 0.8794\n",
            "Epoch 142/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2678 - accuracy: 0.8784\n",
            "Epoch 143/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2666 - accuracy: 0.8789\n",
            "Epoch 144/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2677 - accuracy: 0.8789\n",
            "Epoch 145/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2659 - accuracy: 0.8797\n",
            "Epoch 146/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2665 - accuracy: 0.8792\n",
            "Epoch 147/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2661 - accuracy: 0.8792\n",
            "Epoch 148/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2657 - accuracy: 0.8794\n",
            "Epoch 149/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2649 - accuracy: 0.8800\n",
            "Epoch 150/150\n",
            "6397/6397 [==============================] - 21s 3ms/step - loss: 0.2663 - accuracy: 0.8796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid_resultNN.best_score_)\n",
        "print(grid_resultNN.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLW8I-CZLC5p",
        "outputId": "1a0334f3-9162-4c75-eab8-577993106f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8163071870803833\n",
            "{'batch_size': 32, 'epochs': 150, 'optimizer': 'Adam'}\n"
          ]
        }
      ]
    }
  ]
}